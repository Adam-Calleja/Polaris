[TICKET_KEY] HPCSSUP-98608
[SUMMARY] Enquiry about my account name

[QUERY]
May I ask whether I can use DeepMD software (GPU version) in Dawn? It requires compatible NVIDIA driver to be installed.

[REFERENCE_ANSWER]
If it can not run on Intel, then no, you will not be able to use it. 

[REFERENCE_CONTEXT]
[Dawn - Intel GPU (PVC) Nodes — CSD3 1.0 documentation](https://docs.hpc.cam.ac.uk/hpc/user-guide/pvc.html#hardware)

-----------------------------------------------------------

[TICKET_KEY] HPCSSUP-98519
[SUMMARY] Large Data Transfer using Rclone

[QUERY]
I’m currently assisting some of our users on the transfer of the files stored on /rcs/project/<USER_ID_1>/ over to our S3 compatible data store. We estimate there’s around 160 TB of data we wish to transfer.
Our tool of choice so far has been rclone which supports direct transfers from sftp/ssh to our S3 compatible object store. I’m somewhat uncertain as to how it will handle the TOPT codes for the full transfer. So far, after an initial rsync transfer where TOPT codes are requested, we are able to use rclone normally until the connection eventually times out.
Attempting to run rsync -av -h --progress <USER_ID_2>@rcs.uis.cam.ac.uk:rcs-ajt208-serverbackups/test_transfer_25112025.txt<USER_ID_2>@rcs.uis.cam.ac.uk:rcs-ajt208-serverbackups/test_transfer_25112025.txt<USER_ID_2>@rcs.uis.cam.ac.uk:rcs-ajt208-serverbackups/test_transfer_25112025.txt . is now returning
Connection closed by 128.232.227.186 port 22
rsync: connection unexpectedly closed (0 bytes received so far) [Receiver]
rsync error: unexplained error (code 255) at io.c(232) [Receiver=3.2.7]
Do you have any advice on how to proceed with this transfer or what tool to use to complete the 160TB data transfer?

[REFERENCE_ANSWER]
It would be my suggestion to to run your transfer in a tmux or screen window from one of the login nodes. 
In terms of speed there will likely only be a marginal difference between rsync and rclone but rsync with “--partial” flag can help when connection breaks as it can resume from last point. You should also be aware that they are copying data out of tape where retrieval takes time especially if there is lots of small files involved since the data has to be read then cached before it can be downloaded.

-----------------------------------------------------------

[TICKET_KEY] HPCSSUP-98501
[SUMMARY] Prototyping in login nodes

[QUERY]
I wanted to ask about the recommendations on prototyping in login nodes. I am having dependency troubles when running python scripts. I have inherited the packages from the global environment and sandboxed the packages I need into a virtual environment. Due to dependency issues, my scripts crash sometimes after queuing for multiple hours (thus wasting queue time).
I want to know if I can run small versions of my scripts in a virtual environment in the login node before batching it. That way, I can ensure that the code runs before queuing it.

[REFERENCE_ANSWER]
In general we suggest using interactive jobs for debugging. If this sounds fine then guidance for doing this can be found here https://docs.hpc.cam.ac.uk/hpc/user-guide/interactive.html#interactive-jobs-via-the-scheduler.

[REFERENCE_CONTEXT]
https://docs.hpc.cam.ac.uk/hpc/user-guide/interactive.html#interactive-jobs-via-the-scheduler

-----------------------------------------------------------

[TICKET_KEY] HPCSSUP-98497
[SUMMARY] File Permission Query 

[QUERY]
I wonder if I can get some advice. 
I am one of the data managers for the project <PROJECT_ID_1>, and need some advice on the best way to manage the file permissions. 
The space is used for a number of projects that our group actively work on, however when trying the manage the space and run commands such as du -sh /rds/project/<PROJECT_ID_1>/ I get a lot of permission denied for folders. 
In addition to this if new members of the group starts I cannot easily give them access to group data if the file was generated by a different member of the group and have to result in asking that user to run commands on my behalf to adjust the file permissions. 
Whats the best way to mitigate this issue ?

[REFERENCE_ANSWER]
Setting permissions on RDS projects normally follows the route suggested in https://docs.hpc.cam.ac.uk/storage/rds/permissions.html where there is a hierarchy of permissions. 
In general, we would expect the group to be either rds-*-managers or rds-*-users so that those in each respective group can still access the files. For new members joining, we would suggest again following the linked docs and assigning the appropriate permissions with a `setfacl` command. 
Alternatively, you can set the default permissions for users group to be e.g., `r-x` by default should this be required. Note also the distinction mentioned in the docs page, namely
`# The extra `d:` means set the default ACL which applies to any newly created items.`
That part will make sure that files under newly created folders will have default groups.

[REFERENCE_CONTEXT]
https://docs.hpc.cam.ac.uk/storage/rds/permissions.html

-----------------------------------------------------------

[TICKET_KEY] HPCSSUP-98449
[SUMMARY] HPC access costing

[QUERY]
Hello,
I hope this e-mail finds you well. I am applying for a small grant to do some training, development and analysis for a machine learning project. During this project I aim to train a few different ML algorithms on a test dataset and then use the optimal algorithm to make predictions. I would use the system for around 3 months. I was wondering if you could give me an estimate of the number of hours this type of work would use on the system and thus a rough cost for usage? Let me know if you need more information from my side. Thanks in advance.
Best wishes,
<NAME_1>
<NAME_1> | <ORGANISATION> | University of Cambridge, <LOCATION>
Email: <EMAIL_1>

[REFERENCE_ANSWER]
As an internal user you would receive an allocation of “free” compute hours. The details for these can be found here: https://docs.hpc.cam.ac.uk/hpc/user-guide/policies.html#service-level-3-free-usage. If you would like to use the higher “service level 2” (i.e., paid) tier then details can be found here: https://docs.hpc.cam.ac.uk/hpc/user-guide/policies.html#service-level-1-guaranteed-usage. The charges for this service can be found on this raven protected page: https://www.hpc.cam.ac.uk/charges
> How to buy CSD3 resources
> For Service Level 2, please ask your department to raise a purchase order (PO) to Information Services for the desired number and type of resource units. Please be sure to mention on the PO the name of the project, or the PI, owning the new resources, and email the PDF of the PO to purchases@hpc.cam.ac.uk.
My suggestion would be to fill out a self-application (which will be allowed since you’re a member of academic staff) and see how service level 3 works for you. In terms of service level 2: this is operated on a “pay as you go” basis so there is no set fee.

[REFERENCE_CONTEXT]
https://docs.hpc.cam.ac.uk/hpc/user-guide/policies.html#service-level-3-free-usage
https://docs.hpc.cam.ac.uk/hpc/user-guide/policies.html#service-level-1-guaranteed-usage
https://www.hpc.cam.ac.uk/charges

-----------------------------------------------------------

[TICKET_KEY] HPCSSUP-98447
[SUMMARY] Troubles with R studio

[QUERY]
I am having troubles with the R studio Repo today.
This as working yesterday but today is not working.
The repo is [http://srcp-r-repo/](http://srcp-r-repo/)
Specifically I am using a package called patchwork and am getting
ERROR: failed to lock directory ‘C:/Users/Emp.Blue.014/AppData/Local/R/win-library/4.3’ for modifying Try removing ‘C:/Users/Temp.Blue.014/AppData/Local/R/win-library/4.3/00Lock-patchwork’ warning in install.packages : installation of package ‘patchwork’ had non-zero exit status
As I said, this worked untill today but now no longer works

[REFERENCE_ANSWER]
Are you able to access that directory? If so I would suggest deleting (carefully)  `C:/Users/Temp.Blue.014/AppData/Local/R/win-library/4.3/00Lock-patchwork` or renaming it. 

If you cannot access that directory, I would suggest messaging the helpdesk team so that they can sort this out for you. 

-----------------------------------------------------------

[TICKET_KEY] HPCSSUP-98311
[SUMMARY] Compiling LAMMPS on Ampere

[QUERY]
I am trying to compile the newest release version of LAMMPS on Ampere with the GPU package. Following the instructions on https://docs.hpc.cam.ac.uk/hpc/software-packages/lammps.html leads to an error when running a benchmark:
Cuda driver error 1 in call at file '/home/<USER_ID_1>/git/lammps_amp/lib/gpu/geryon/nvd_kernel.h' in line 340.
Cuda driver error 1 in call at file '/home/<USER_ID_1>/git/lammps_amp/lib/gpu/geryon/nvd_kernel.h' in line 340.
Cuda driver error 1 in call at file '/home/<USER_ID_1>/git/lammps_amp/lib/gpu/geryon/nvd_kernel.h' in line 340.
Cuda driver error 1 in call at file '/home/<USER_ID_1>/git/lammps_amp/lib/gpu/geryon/nvd_kernel.h' in line 340.
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 1 in communicator MPI_COMM_WORLD
with errorcode -1.
NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
This is working without any issues when using version stable_29Aug2024_update2 as per the instructions. By any chance, do you happen to have any information on how to compile a more recent version of LAMMPS?

[REFERENCE_ANSWER]

I would suggest trying this again using the newest software stack:

```
module load rhel8/ampere/base
module load gcc/14.3.0/vlhhcp6m
module load cmake/3.31.10/gcc/7ddsybx7
module load cuda/12.8.1/gcc/kdeps6ab
module load openmpi/4.1.8/gcc/hemliivg 
```

-----------------------------------------------------------

[TICKET_KEY] HPCSSUP-98273
[SUMMARY] can't access hpc website

[QUERY]
I can't access the hpc login website:
https://login-web.hpc.cam.ac.uk/. The connection just hangs, I have tried several times, cleared all my cookies and then tried again (I'm using Firefox) but still no access. I get the following proxy error: Reason: Error reading from remote server
Is there an issue with the hpc website this morning or am I doing something wrong?

[REFERENCE_ANSWER]
There is no issue with your account. The problem is caused by the standard HPC web login URL occasionally hanging due to a proxy or browser session issue.

You can log in successfully by using the alternative login URL below, which bypasses the problematic redirect and takes you directly to the dashboard:

https://login-web.hpc.cam.ac.uk/nginx/stop?redir=/pun/sys/dashboard/

If the standard login page hangs, clearing your browser cache or switching browsers may also help, but the alternative link is safe to use and should continue to work. The main login URL should function normally again once the proxy issue clears.

-----------------------------------------------------------

[TICKET_KEY] HPCSSUP-98018
[SUMMARY] Restore ~/.bashrc from snapshot

[QUERY]
Hello,
I accidentally overwrote my ~/.bashrc file today.
How can I restore the previous version from filesystem snapshots if possible?

[REFERENCE_ANSWER]
You may be able to restore your previous ~/.bashrc from the filesystem snapshots, provided it was present long enough to be captured by an hourly, daily, or weekly snapshot.

Snapshots are accessible via a hidden .snapshot directory within each directory. Since .bashrc lives in your home directory, you should look inside the snapshots of your home directory.

Steps to restore your file:

1. Navigate to the snapshot directory in your home folder:
   cd ~/.snapshot

2. List the available snapshots (for example, hourly or daily):
   ls

3. Choose a snapshot taken before you overwrote .bashrc (e.g. an hourly snapshot from earlier today), and navigate into it:
   cd hourly_YYYY-MM-DD_HH\:MM

4. Check that the old version of .bashrc exists:
   ls -a

5. Copy the snapshot version back to your home directory:
   cp .bashrc ~/

[REFERENCE_CONTEXT]
https://docs.hpc.cam.ac.uk/hpc/user-guide/io_management.html#backups

-----------------------------------------------------------

[TICKET_KEY] HPCSSUP-96256
[SUMMARY] Pending Times

[QUERY]
Hi,
I submitted a job to run I believe on Tuesday at 3pm, with the following headers :
#!/bin/bash
#SBATCH -A <ACCOUNT_NUMBER>-SL2-CPU
#SBATCH -J <JOB_NAME>
#SBATCH -p icelake-himem
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --mem=64G
#SBATCH --time=24:00:00
#SBATCH -o <JOB_NAME>_%A.out
#SBATCH -e <JOB_NAME>_%A.err
It has been pending since then with the following NodeListReason : AssocGrpCPUMinutesLimit
Is there anything I can do about this and how long can I expect the job to wait?

[REFERENCE_ANSWER]
The job is pending because the project account you are submitting under has reached its CPU-minute allocation limit. The NodeListReason: AssocGrpCPUMinutesLimit message indicates that the account currently does not have enough remaining CPU credits to start new jobs.

You can check the remaining balance on your project account using:

```
mybalance
```

If the balance is exhausted (or very low), new jobs will remain pending until more credits become available. To increase the allocation, your project’s Principal Investigator will need to purchase additional SL2 credits by raising a purchase order. Information on charges and the process can be found on the Research Computing Services charging page.

If additional credits are not added, the job will continue to wait indefinitely and will not start. Reducing the requested resources (for example, fewer CPUs, shorter runtime, or a different partition) will not bypass the credit limit.

If you believe this is unexpected or your account should still have available credits, please let us know the account name and we can double-check the allocation.

-----------------------------------------------------------

[TICKET_KEY] HPCSSUP-96168
[SUMMARY] HPC Job Scheduling Error

[QUERY]
To whom it may concern,
I have submitted a job on the HPC, and it took almost 2 weeks to get scheduled. I was wondering if there were any issues with my setup. The job script I used is below.
#!/bin/bash
#SBATCH -J job_gpu_1
#SBATCH -o /home/<USER_ID_1>/logfiles/job_gpu_1.log
#SBATCH -A <ACCOUNT_NUMBER>-SL3-GPU
#SBATCH -p ampere
#SBATCH --gres=gpu:4
#SBATCH --time=12:00:00
echo "This job is running on: $(hostname)"
echo "Present working directory: $(pwd)"
echo "Job ID: $SLURM_JOB_ID"
echo "Job start time: $(date)"
module purge
echo "loading python"
module load python/3.11.0-icl
echo "loading cuda"
module load cuda/12.1
echo "activating venv"
source /rds/user/<USER_ID_1>/hpc-work/venvs/venv/bin/activate
echo "running file"
python -u /home/<USER_ID_1>/projects/part-ii-project/job.py

[REFERENCE_ANSWER]
Your job script and account configuration are correct, and there is no issue with how the job was submitted.

The long wait time is due to queue priority, not a problem with your setup. Your job is running at the non-paying (standard) service level on the GPU partition, while there is currently a high level of paying (charged) GPU usage, which is scheduled with higher priority.

Please note that paying GPU jobs can occupy resources for up to 36 hours, which can significantly reduce availability for non-paying jobs during busy periods. As a result, longer queue times—sometimes up to several weeks—are expected.

Your job’s priority will steadily increase the longer it remains in the queue, so cancelling and resubmitting the job would reset its priority and likely make the wait longer, not shorter. We therefore recommend leaving the job in the queue.

The job will start automatically once sufficient GPU resources become available. If you require faster turnaround in the future, you may wish to discuss using a paying service level with your project’s PI.

-----------------------------------------------------------

[TICKET_KEY] HPCSSUP-94957
[SUMMARY] SSH Terminal- can't log in

[QUERY]
Dear team,
I hope you are doing fine. I just wanted to reach out as I can’t login via the SSH terminal, but can login with log-in web. I am not sure why and wonder if you can help.
Kind regards,

[REFERENCE_ANSWER]
SSH access to CSD3 requires multi-factor authentication (MFA) in addition to your password or SSH key. The MFA system used by the HPC service requires a time-based one-time password (TOTP) code that is separate for SSH logins and for web logins. On the web interface (login-web.hpc.cam.ac.uk), you may already have set up a TOTP for that purpose; however, having a web TOTP does not automatically enable SSH access.  ￼

To enable SSH access, you must set up an SSH-specific MFA TOTP by connecting to the special MFA configuration host:

```
ssh <your-user-id>@multi.hpc.cam.ac.uk
```

When you do this, you will be prompted (if you do not yet have an SSH TOTP) to authenticate with your password and then presented with a QR code or setup secret. Scan the QR code with your chosen authenticator app (for example Google Authenticator or Microsoft Authenticator) to generate the six-digit TOTP codes that you will use for SSH login.  ￼

Be aware of a few key points:
	•	The SSH TOTP you create will appear in your authenticator app under a label such as “CSD3: SSH Login”; the TOTP created via the web interface appears separately (e.g., “CSD3: your username”).  ￼
	•	If you already have a TOTP for SSH, connecting to multi.hpc.cam.ac.uk will detect it and not generate a new one.  ￼
	•	Once the SSH TOTP is configured, you should be able to use your SSH client to connect as normal: e.g., ssh <your-user-id>@login-*.hpc.cam.ac.uk and enter the TOTP code when prompted as a second factor.  ￼

For full details on setting up MFA and troubleshooting, see the HPC MFA documentation: https://docs.hpc.cam.ac.uk/hpc/user-guide/mfa.html.  ￼

[REFERENCE_CONTEXT]
https://docs.hpc.cam.ac.uk/hpc/user-guide/mfa.html

-----------------------------------------------------------