<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-99134
[STATUS] RESOLVED
[CREATED] 2026-02-11T13:29:05.670+0000
[SUMMARY] Please find attached for processing our Purchase Order MA2-4362647

[INITIAL_DESCRIPTION]
Hello,
Please find attached for processing our PO MA2-4362647
We would be grateful if you would reply to this email with confirmation of receipt.
If required, the University's EORI number is 823 847 609 000.
Goods-In opening hours are Monday to Friday 8am to 4pm (Closed for UK Bank Holidays).
Kind Regards
Stephen Green-Malloy
Senior Stores Technician
[cid:image001.jpg@01DC9B59.E6530F70]


[CONVERSATION]
<MESSAGE id=0001 role=TICKET_CREATOR>
[FILE ATTACHMENT]
 (78 kB)
[FILE ATTACHMENT]
</MESSAGE>

<MESSAGE id=0002 role=HELPDESK_ASSIGNEE>
INFO:: --- GDEPOSIT BLOCK ---
resourcehours=5000
project=vendruscolo-sl2-gpu
gdeposit -z $resourcehours -p $project
INFO:: --- CUSTOMER RESPONSE ---
Dear Stephen,
We have credited the account `vendruscolo-sl2-gpu` with `5,000` hours and sent the PO to finance.
Best wishes,
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0003 role=HELPDESK_ASSIGNEE>
Dear Stephen,
We have credited the account `vendruscolo-sl2-gpu` with `5,000` hours and sent the PO to finance.
Best wishes,
Henry
HPC Support
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-98836
[STATUS] RESOLVED
[CREATED] 2026-02-05T13:24:02.355+0000
[SUMMARY] Missing Files After RDS Directory Change?

[INITIAL_DESCRIPTION]
Hello,
I am a user of CSD3 (ejs237, dp012) and recently noticed that I can no longer access my files at
/rds/user/ejs237/rds-dirac-dp012/ejs237/.
I was informed that the directory has been moved to
/rds/project/dirac_vol2/rds-dirac-dp012, but this location does not appear to be valid or accessible in my case.
Could you please let me know where my previous data have been moved?
Thank you very much for your help.
Best regards,
Eun-jin Shin


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hello Eun-jin,
You can fix the symlink by using the following commands:
cd ~/rds
rm rds-dirac-dp012
ln -s /rds/project/rds-1EqYKotbyrc rds-dirac-dp012
Please let me know if this works.
Best regards,
Elisabeth Reeve
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=TICKET_CREATOR>
Hello Elisabeth,
Thanks so much for your help. This works well.
Best wishes,
Eun-jin
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-98820
[STATUS] RESOLVED
[CREATED] 2026-02-05T10:47:02.106+0000
[SUMMARY] RDS and RCS licence renewal

[INITIAL_DESCRIPTION]
Dear Storage Services team,
We would like to renew our licences for both the RDS and RCS  (account 80/81) for another year.
On top of this is it possible to change the ownership of these licences to Maria (Cc’ed) who is our new head of bioinformatics?
Many thanks
Brian
**
Dr. Brian Lam
Assistant Research Professor
Institute of Metabolic Science-Metabolic Research Laboratories
Medical Research Council Metabolic Diseases Unit
University of Cambridge
Institute of Metabolic Science
Level 4, Box 289, Addenbrooke's Hospital
Cambridge CB2 0QQ
United Kingdom
Phone: +44 (0)1223 768628
Email: yhbl2@cam.ac.uk<[yhbl2@cam.ac.uk](mailto:yhbl2@cam.ac.uk)>


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hello Brain,
These actions can be taken within the relevant storage licenses on the self service storage portal: [https://selfservice.uis.cam.ac.uk/](https://selfservice.uis.cam.ac.uk/)
Please let me know if you have any troubles.
Best regards,
Elisabeth Reeve
HPC Support
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-98814
[STATUS] RESOLVED
[CREATED] 2026-02-05T09:04:03.632+0000
[SUMMARY] Login issues

[INITIAL_DESCRIPTION]
Dear officer,
I have some issues with login via this page. My colleague has added me as the co-leader in this project.
However, when I click on the " the “Sign in with Keycloak”" it didn't transfer me to the University of Liverpool credentials page. I tried to login anyway with my liverpool account but it doesn't work.
Could you kindly help me how should I login to this portal? Thank you very much for your time and help. Have a nice day.
Best regards,
Yingjie Wang
________________________________
From: airr-admin@hpc.cam.ac.uk <airr-admin@hpc.cam.ac.uk>
Sent: Friday, January 30, 2026 13:07
To: Wang, Yingjie [yjwang] <Yingjie.Wang2@liverpool.ac.uk>
Subject: Invitation to Multi-Agent Semantic Annealing Attack on LLMs Prompts, Phase 2 project
CAUTION: This email originated outside of the University. Do not click links unless you can verify the source of this email and know the content is safe. Check sender address, hover over URLs, and don't open suspicious email attachments.
Hello!
Yi Dong has invited you to join Multi-Agent Semantic Annealing Attack on LLMs Prompts, Phase 2 project in Co-investigator (can invite people) role.
Please visit this page<[https://access.hpc.cam.ac.uk/invitation/61e3977a84024e4296081056ee22cda1/](https://access.hpc.cam.ac.uk/invitation/61e3977a84024e4296081056ee22cda1/)> to sign up and accept your invitation. Please note: this invitation expires at 06.02.2026 13:07!
Kind regards,
Research Computing Services
University Information Services
University of Cambridge
Please email support@hpc.cam.ac.uk<[support@hpc.cam.ac.uk](mailto:support@hpc.cam.ac.uk)> if any problems are encountered.


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hello Yingjie,
You need to click the “MyAccessID” button underneath the login boxes to login with your university credentials.
Please see this guidance: [Dawn - Intel GPU (PVC) Nodes — CSD3 1.0 documentation](https://docs.hpc.cam.ac.uk/hpc/user-guide/pvc.html#users-accessing-open-on-demand-via-the-portal)
Best regards,
Elisabeth Reeve
HPC Support
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-98799
[STATUS] RESOLVED
[CREATED] 2026-02-04T16:59:02.507+0000
[SUMMARY] Copy-paste text between local and SRCP

[INITIAL_DESCRIPTION]
Dear HPC support team,
I was wondering if there is a way to copy paste text between local machine and the SRCP virtual desktop in browser? I've tried using the clipboard icon on the TurboVNC side toolbar, which is supposed to work as a medium for this, but it doesn't seem to sync properly (only picks up text from my local machine, cannot be pasted into the virtual desktop).
Is there an alternative method for transferring text?
Alternatively, is there a way to log into SRCP via ssh in the terminal? That would make text transfers and edits much easier.
Best,
Shilin


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hello Shilin,
The copy paste function from outside of the SRCP is not possible as this would violate the SRCP security policies. You can transfer data/files in via the secure channels if required.
[Secure Windows Desktop (SWD) — Secure Research Computing Platform Documentation documentation](https://docs.hpc.cam.ac.uk/srcp/swd/index.html)
Best regards,
Elisabeth Reeve
HPC Support
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-98754
[STATUS] RESOLVED
[CREATED] 2026-02-04T11:15:04.198+0000
[SUMMARY] Quote for RDS storage costs

[INITIAL_DESCRIPTION]
Good morning,
We are extending the duration of our team’s RCS and RDS licenses for one more year.
I have already obtained a quote for duration extension of our RCS storage (storage-6063) from the Self Service. This is good.
I would like to now request a bespoke quote for duration extension of our RDS licence that cannot be generated via the Self Service.
We have paid for 700TB of RDS until 21 April 2026 [https://selfservice.uis.cam.ac.uk/storage/project/114/](https://selfservice.uis.cam.ac.uk/storage/project/114/)
Firstly, to align our RDS with RCS expiry date, we would like to rebase this date so that they both expire on the same date.
Secondly, we only require 400TB of RDS for next year and I have already reduced our Lustre data to below 400TB.
Therefore, we need a quote for our next year’s RDS licence to look like this:
Duration Extension              Research Data Store     400 TB  Serena Nik-Zainal (sn206)       28 Feb 2026     28 Feb 2027
Could you please provide a quote for these RDS storage costs?
I believe it should cost around:
400TB*£39.36 per TB per year = £15,744
Minus 52 days between 28 Feb 2026 and 21 April 2026 for which we have paid already:
52/365*(700TB*£39.36) = £3,925
Total £15,744-£3,925 = £11,819
Once I have received your final quote, I will contact our finance team to produce a Purchase Order.
Regards
Yasin


[CONVERSATION]
<MESSAGE id=0001 role=OTHER>
Hi @Greg Habrych This group is requesting to reduce their RDS store and change the end date of the license to be in line with their cold store. Would this be amenable to do? They would need a custom quote if so too.
</MESSAGE>

<MESSAGE id=0002 role=HELPDESK_ASSIGNEE>
Hi @Elisabeth Reeve , I will grab this one and calculate cost of extension for them.
</MESSAGE>

<MESSAGE id=0003 role=HELPDESK_ASSIGNEE>
Hi Yasin,
Many thanks for getting in touch. Here is a modified quotation as requested. 
```
Your storage quote
------------------

Reference: storage-6068
Date: 06/02/2026


License Type: Duration Extension

Storage: Research Data Store

Capacity: 400 TB

Length: 1 year
Start date: 28/02/2026
Price/TB: £ 39.36
Line Total: £ 15744.02
Discount: -£ 3925.12
Payable Total: £ 11818.91


Contact us
----------

Storage Services Team
University Information Services
Email: storage-services@uis.cam.ac.uk
Tel: (+)44 1223 763517

Find out about UIS data storage
https://www.hpc.cam.ac.uk/
```
Kind regards,
Greg
RCS Team
</MESSAGE>

<MESSAGE id=0004 role=TICKET_CREATOR>
Hi Greg
Many thanks for this. I will now contact our finance team to request a Purchase Order and forward it to you for processing. This may take a couple of days.
Regards
Yasin
On 6 Feb 2026, at 11:41, Greg Habrych <support@hpc.cam.ac.uk> wrote:
</MESSAGE>

<MESSAGE id=0005 role=TICKET_CREATOR>
Hi Greg
Please find the Purchase Order attached.
Regards
Yasin
On 6 Feb 2026, at 11:51, Yasin Memari <ym255@cam.ac.uk> wrote:
Hi Greg
Many thanks for this. I will now contact our finance team to request a Purchase Order and forward it to you for processing. This may take a couple of days.
Regards
Yasin
On 6 Feb 2026, at 11:41, Greg Habrych <support@hpc.cam.ac.uk> wrote:
[FILE ATTACHMENT]
 (165 kB)
</MESSAGE>

<MESSAGE id=0006 role=HELPDESK_ASSIGNEE>
Hi Yasin,
Many thanks. I have updated your project in portal and on filesystem. 

Kind regards,
Greg
RCS Team
</MESSAGE>

<MESSAGE id=0007 role=TICKET_CREATOR>
Hi Greg
Many thanks. It looks good. 
While this ticket is open and you have admin access, please also delete these two directories.
rm -rf /rds/project/sn206/rds-sn206-nik-zainal/external/unc/
rm -rf /rcs/project/sn206/rcs-sn206-nik-zainal-hphi/data/raw/PEARLY/
I manage our team's data but do not have permission to delete them, and we are no longer in contact with the data owner.
Regards
Yasin
</MESSAGE>

<MESSAGE id=0008 role=HELPDESK_ASSIGNEE>
No problem, those two directories have been deleted.

Kind regards,
Greg
RCS Team
</MESSAGE>

<MESSAGE id=0009 role=TICKET_CREATOR>
Thanks. I’ve no other requests, so we can close this ticket.
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-98750
[STATUS] RESOLVED
[CREATED] 2026-02-04T10:37:03.080+0000
[SUMMARY] Purchase Order for RDS Duration Extension

[INITIAL_DESCRIPTION]
Good morning,
We are extending the duration of our team’s RCS and RDS licenses for one more year.
I have already obtained a quote for duration extension of our RCS storage (storage-6063) from the Self Service. This is good.
I would like to now request a bespoke quote for duration extension of our RDS licence that cannot be generated via the Self Service.
We have paid for 700TB of RDS until 21 April 2026 [https://selfservice.uis.cam.ac.uk/storage/project/114/](https://selfservice.uis.cam.ac.uk/storage/project/114/)
Firstly, to align our RDS with RCS expiry date, we would like to rebase this date so that they both expire on the same date.
Secondly, we only require 400TB of RDS for next year and I have already reduced our Lustre data to below 400TB.
Therefore, we need a Purchase Order so that our next year’s RDS licence would look like this:
Duration Extension              Research Data Store     400 TB  Serena Nik-Zainal (sn206)       28 Feb 2026     28 Feb 2027
I believe it should cost around:
400TB*£39.36 per TB per year = £15,744
Minus 52 days between 28 Feb 2026 and 21 April 2026 for which we have paid already:
52/365*(700TB*£39.36) = £3,925
Total £15,744-£3,925 = £11,819
Could you kindly produce this Purchase Order for us?
Regards
Yasin


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hello Yasin,
We do not produce purchase orders for users of our services as we do not have access to the funding points that you get from departmental purchase orders, you need to contact your finance team within your department.
Please submit your enquiry for reducing storage to support@hpc.cam.ac.uk so we can escalate it to the relevant team.
Best regards,
Elisabeth
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-98706
[STATUS] RESOLVED
[CREATED] 2026-02-03T16:07:04.039+0000
[SUMMARY] MFA reset request

[INITIAL_DESCRIPTION]
Dear HPC,
I switched phone but did not port the MFA information to my new device.
Would you be able to help me reset this?
Many thanks,
Bart.


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hello Bart, 
Have you still got your old phone? As you can transfer the authenticator codes over to your new phone. If you use Microsoft Authenticator, please see these [instructions](https://support.microsoft.com/en-us/account-billing/back-up-account-credentials-in-microsoft-authenticator-bb939936-7a8d-4e88-bc43-49bc1a700a40), if you use Google Authenticator, please see these [instructions](https://support.google.com/accounts/answer/1066447?hl=en&co=GENIE.Platform%3DAndroid)
If you can not transfer the codes over, we can reset your MFA. In order to do so we will need to have a quick video call, no more than 5 minutes, where you can present your photo ID for verification.
Please let me know a time and date that is suitable for you and I can send an MS Teams meeting invite. Service Desk hours are 9am - 5pm, Mon- Fri, excl. holidays.
Best regards,
Elisabeth Reeve 
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=HELPDESK_ASSIGNEE>
Hello Bart,
Do you require support on this still? If not, I will close this ticket.
Best regards,
Elisabeth Reeve
</MESSAGE>

<MESSAGE id=0003 role=TICKET_CREATOR>
Yes, i'd like to set up a face to face to reset my MFA.
Many thanks.
Can we pick a time early next week?
Best wishes,
Bart.
</MESSAGE>

<MESSAGE id=0004 role=HELPDESK_ASSIGNEE>
Hello Bart,
Can you do 1pm on Monday (9th)?
Best regards,
Elisabeth
</MESSAGE>

<MESSAGE id=0005 role=TICKET_CREATOR>
Yes that works for me,
many thanks,
Bart.
</MESSAGE>

<MESSAGE id=0006 role=HELPDESK_ASSIGNEE>
Hello Bart, 
This is just to confirm that your MFA for the cluster has been reset. To get your new TOTP please put the following into your terminal:
`ssh bd355@multi.hpc.cam.ac.uk`
It will then ask for a password, this should be your University of Cambridge password, and then a QR code will appear for you to scan into your authenticator app. If all goes well, you should have a TOTP labelled “CSD3:SSH Login” or something similar to that.
If you use the web interface, all you will need to do is login as normal and a QR code will appear for you to scan too. This TOTP should be labelled “CSD3:bd355”
We do also have our user documentation that highlights the process as well, that you may find helpful: [https://docs.hpc.cam.ac.uk/hpc/user-guide/mfa.html](https://docs.hpc.cam.ac.uk/hpc/user-guide/mfa.html)
Please do let me know if you have any issues,
Best regards,
Elisabeth
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-98611
[STATUS] RESOLVED
[CREATED] 2026-02-02T15:38:07.064+0000
[SUMMARY] Question about apparent discrepancy between quota and disk usage on RCS

[INITIAL_DESCRIPTION]
Hi HPC Support Team,
I’m writing to ask about a discrepancy I’ve noticed between the reported quota usage and the disk usage shown by du on our RCS space.
When I check the usage for rcs1 (rcs-zz485-sem-lab-cold) using quota, it reports approximately 1.17 TB in use. However, when I run du -h on the same RCS directory, it reports a total size of around 29 TB. In addition, I can confirm that my own subdirectory alone (/woody) is significantly larger than the ~45 GB indicated by the quota output.
This has made us a bit concerned about: whether all data on the RCS space is being correctly accounted for by the quota system, and whether there is any issue with how usage is being reported.
Could you please advise on why there might be, and whether this is expected behaviour for RCS storage?
Many thanks for your help.
All the best,
Woody
[cid:2e4c979f-7f13-4964-85b8-9b8614326b0f@GBRP265.PROD.OUTLOOK.COM]
[cid:e1468c0f-87a3-40d2-99da-259426e89246@GBRP265.PROD.OUTLOOK.COM]


[CONVERSATION]
<MESSAGE id=0001 role=TICKET_CREATOR>
[FILE ATTACHMENT]
[FILE ATTACHMENT]
</MESSAGE>

<MESSAGE id=0002 role=HELPDESK_ASSIGNEE>
Hello Woody,
Please use the command du --apparent-size to get an accurate quota usage of RCS. The quota command does not cache RCS regularly due to the nature of the cold store tapes.
Best regards,
Elisabeth Reeve
HPC Support
</MESSAGE>

<MESSAGE id=0003 role=HELPDESK_ASSIGNEE>
Hello Woody,
Do you require support on this still? If not, I will close this ticket.
Best regards,
Elisabeth Reeve
</MESSAGE>

<MESSAGE id=0004 role=TICKET_CREATOR>
Hi Elisabeth,
This is very helpful. I am good now.
Thank you!
All the best,
Woody
On 5 Feb 2026, at 14:15, Elisabeth Reeve <support@hpc.cam.ac.uk> wrote:
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-98608
[STATUS] RESOLVED
[CREATED] 2026-02-02T15:25:28.803+0000
[SUMMARY] Enquiry about my account name

[INITIAL_DESCRIPTION]
Dear Henry,
I hope this email finds you well!
I would like to load lammps gpu in my account, but I got the error of "sbatch: error: Batch job submission failed: Invalid account or account/partition combination specified". My slurm script is attached. Could you please let me know the correct format of the slurm script?
Many thanks!
Best Regards,
Ruitian
-------------------------------------------------
Dr. Ruitian He
Postdoctoral Research Assistant
Oxford Thermofluids Institute
Department of Engineering Science
University of Oxford
Oxford, OX2 0ES


[CONVERSATION]
<MESSAGE id=0001 role=TICKET_CREATOR>
[FILE ATTACHMENT]
 (1 kB)
</MESSAGE>

<MESSAGE id=0002 role=HELPDESK_ASSIGNEE>
Hello Ruitian,
You need to be using the Slurm project account to charge against, not your user account.
> Your Dawn user account has been created and the username is dn-he1, in Slurm project AIRR-P57-DAWN-GPU.
Best regards,
Elisabeth Reeve
HPC Support
</MESSAGE>

<MESSAGE id=0003 role=TICKET_CREATOR>
Dear Elisabeth,
May I ask whether I can use DeepMD software (GPU version) in Dawn? It requires compatible NVIDIA driver to be installed.
Many thanks!
Best Regards,
Ruitian
-------------------------------------------------
Dr. Ruitian He
Postdoctoral Research Assistant
Oxford Thermofluids Institute
Department of Engineering Science
University of Oxford
Oxford, OX2 0ES
</MESSAGE>

<MESSAGE id=0004 role=HELPDESK_ASSIGNEE>
Hello Ruitian,
If it can not run on Intel, then no, you will not be able to use it. [Dawn - Intel GPU (PVC) Nodes — CSD3 1.0 documentation](https://docs.hpc.cam.ac.uk/hpc/user-guide/pvc.html#hardware)
Best regards,
Elisabeth
</MESSAGE>

<MESSAGE id=0005 role=TICKET_CREATOR>
Dear Elisabeth,
Many thanks for your help!
Best Regards,
Ruitian
-------------------------------------------------
Dr. Ruitian He
Postdoctoral Research Assistant
Oxford Thermofluids Institute
Department of Engineering Science
University of Oxford
Oxford, OX2 0ES
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-98575
[STATUS] RESOLVED
[CREATED] 2026-02-02T09:01:03.343+0000
[SUMMARY] Query on extending SL3 CPU usage and annual reset

[INITIAL_DESCRIPTION]
Dear HPC Group,
I am Wenhao Xu, a PhD student in the Department of Clinical Neurosciences, working in Prof. Peter Smielewski’s group. I am writing to ask about extending our SL3 CPU allocation, as my current usage on account wx266 has reached the limit.
According to mybalance records, I have used 380,694 CPU hours under Account SMIELEWSKI-SL3-CPU over the last year, and I would be grateful if you could advise:
1.
Whether it is possible to request additional CPU hours for continued work this year; and
1.
Whether SL3 free usage reset annually, and if so, when the reset could occur.
If you need any additional details, please let me know.
Many thanks for your help.
Best,
–
Wenhao Xu
PhD candidate, Department of Clinical Neurosciences
Clare Hall, University of Cambridge


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hello Wenhao,
Credits found on SL3 project accounts are shared among the users that have access to them, not individual users. 
SL3 project account credits are refreshed at the start of each academic quarter: these are three month periods of the year running 1st February - 30th April, 1st May - 31st July, 1st August - 31st October and 1st November - 31st January.
You can read more about SL3 projects in our policies: [https://docs.hpc.cam.ac.uk/hpc/user-guide/policies.html#service-levels](https://docs.hpc.cam.ac.uk/hpc/user-guide/policies.html#service-levels)
Best regards,
Elisabeth Reeve
HPC Support
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-98537
[STATUS] RESOLVED
[CREATED] 2026-01-30T15:24:01.830+0000
[SUMMARY] Interactive Jupyter Notebooks crashing before loading

[INITIAL_DESCRIPTION]
Hi Team,
I am having an issue with my interactive OnDemand notebooks. They seem to reach the point of Starting and then crash before they can actually begin. Here is an output.log:
```
/var/spool/slurm/slurmd/job21509569/slurm_script: line 3: module: command not found
Script starting...
Waiting for Jupyter Notebook server to open port 61834...
TIMING - Starting main script at: Fri Jan 30 15:00:10 GMT 2026
TIMING - Starting wait at: Fri Jan 30 15:00:10 GMT 2026
/home/tsl30/ondemand/data/sys/dashboard/batch_connect/sys/jupyter/csd3/output/cad586e3-86c7-48bb-b093-8249dc27ee3f/script.sh: line 14: module: command not found
/home/tsl30/ondemand/data/sys/dashboard/batch_connect/sys/jupyter/csd3/output/cad586e3-86c7-48bb-b093-8249dc27ee3f/script.sh: line 17: module: command not found
/home/tsl30/ondemand/data/sys/dashboard/batch_connect/sys/jupyter/csd3/output/cad586e3-86c7-48bb-b093-8249dc27ee3f/script.sh: line 20: module: command not found
TIMING - Starting jupyter at: Fri Jan 30 15:00:10 GMT 2026
+ jupyter notebook --config=/home/tsl30/ondemand/data/sys/dashboard/batch_connect/sys/jupyter/csd3/output/cad586e3-86c7-48bb-b093-8249dc27ee3f/config.py
/home/tsl30/ondemand/data/sys/dashboard/batch_connect/sys/jupyter/csd3/output/cad586e3-86c7-48bb-b093-8249dc27ee3f/script.sh: line 27: jupyter: command not found
Timed out waiting for Jupyter Notebook server to open port 61834!
TIMING - Wait ended at: Fri Jan 30 15:01:11 GMT 2026
Cleaning up...
```
I do not understand what this means! Help!!
Best wishes,
Tim
Sent from Outlook for Mac


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hello Tim,
We were experiencing some disruption on the RDS file system which should hopefully be resolved soon. 
Best wishes, 
Henry
HPC Support
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-98532
[STATUS] RESOLVED
[CREATED] 2026-01-30T15:06:33.633+0000
[SUMMARY] [ukaea] Partition Query

[INITIAL_DESCRIPTION]
I'm helping someone with an issue which has involved the `ukaea-icl-himem` nodes and I noticed that it seems that the nodes for that partition ( `cpu-q-[429-440,442-444]` ) are also in the general `ukaea-icl` pool (see below). This has meant that although their empty I'm not able to test the issue on that partition. I just wanted to make sure this is the expected setup?
`[ir-swan1@login-p-1 jez_scripts]$ sinfo -p ukaea-icl-himem`
`PARTITION       AVAIL  TIMELIMIT  NODES  STATE NODELIST`
`ukaea-icl-himem    up 7-00:00:00      1  maint cpu-q-441`
`ukaea-icl-himem    up 7-00:00:00     15  alloc cpu-q-[429-440,442-444]`
`[ir-swan1@login-p-1 jez_scripts]$ squeue --format "%i,%20P,%j" -w cpu-q-[429-440,442-444]`
`JOBID,PARTITION           ,NAME`
`21455318,ukaea-icl           ,050m0400`
`21455285,ukaea-icl           ,050m0400`
`21455303,ukaea-icl           ,050m0400`
`21455282,ukaea-icl           ,050m0400`


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hello Jez, 
Can you please provide some more information for me please? The only practical difference between himem and regular nodes is that the himem partition is designed to allocate more RAM per CPU. 
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=TICKET_CREATOR>
Hi Henry,
I suppose practically the issue is that I can’t run anything promptly in that queue because the general `ukaea-icl `queue is using those nodes when the `ukaea-icl-himem` queue is empty seems counter intuitive. A couple of the people I’ve asked at UKAEA (Shaun DeWitt and Andrew Davis) seem a little confused by this arrangement.
</MESSAGE>

<MESSAGE id=0003 role=HELPDESK_ASSIGNEE>
Hi @Stuart Rankin ,we have someone from UKAEA who is dissatisfied with the way we’ve partitioned Icelake. Not sure what I can say other than use whatever works and request more CPUs on the regular icelake queue.
</MESSAGE>

<MESSAGE id=0004 role=OTHER>
The overlap of these partitions is intentional and mirrors the configuration of the Cambridge icelake/icelake-himem and cclake/cclake-himem partitions. The point is that rather than leave the higher memory nodes empty when there is demand elsewhere they are allowed to take jobs from the lower priority non-himem partition when there are no jobs requesting himem jobs waiting.  This means that they may be busy when new himem jobs are submitted and in that case you will need to wait for the existing jobs to release resources. Provided there is demand for himem the scheduler will favour these.
I hope this clarifies -
Best regards
Stuart
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-98497
[STATUS] RESOLVED
[CREATED] 2026-01-30T10:42:01.004+0000
[SUMMARY] File Permission Query 

[INITIAL_DESCRIPTION]
Hi, 
I wonder if I can get some advice. 
I am one of the data managers for the project rds-HvBBlpwx4dc, and need some advice on the best way to manage the file permissions. 
The space is used for a number of projects that our group actively work on, however when trying the manage the space and run commands such as du -sh /rds/project/rds-HvBBlpwx4dc/ I get a lot of permission denied for folders. 
In addition to this if new members of the group starts I cannot easily give them access to group data if the file was generated by a different member of the group and have to result in asking that user to run commands on my behalf to adjust the file permissions. 
Whats the best way to mitigate this issue ?
I look forward to hearing from you 
Best wishes
James


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
HI @Greg Habrych does this reply make sense: 
Hello James,
Setting permissions on RDS projects normally follows the route suggested in [https://docs.hpc.cam.ac.uk/storage/rds/permissions.html](https://docs.hpc.cam.ac.uk/storage/rds/permissions.html) where there is a hierarchy of permissions. In general, we would expect the group to be either rds-*-managers or rds-*-users so that those in each respective group can still access the files. For new members joining, we would suggest again following the linked docs and assigning the appropriate permissions with a `setfacl` command. Alternatively, you can set the default permissions for users group to be e.g., `r-x` by default should this be required.
</MESSAGE>

<MESSAGE id=0002 role=OTHER>
Yes, I think we should also point out that bit from docs for ACL:
`# The extra `d:` means set the default ACL which applies to any newly created items.`
That part will make sure that files under newly created folders will have default groups.
</MESSAGE>

<MESSAGE id=0003 role=HELPDESK_ASSIGNEE>
Hello James,
Setting permissions on RDS projects normally follows the route suggested in [https://docs.hpc.cam.ac.uk/storage/rds/permissions.html](https://docs.hpc.cam.ac.uk/storage/rds/permissions.html) where there is a hierarchy of permissions. 
In general, we would expect the group to be either rds-*-managers or rds-*-users so that those in each respective group can still access the files. For new members joining, we would suggest again following the linked docs and assigning the appropriate permissions with a `setfacl` command. 
Alternatively, you can set the default permissions for users group to be e.g., `r-x` by default should this be required. Note also the distinction mentioned in the docs page, namely
`# The extra `d:` means set the default ACL which applies to any newly created items.`
That part will make sure that files under newly created folders will have default groups.
Best wishes, 
Henry
HPC Support
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-98324
[STATUS] RESOLVED
[CREATED] 2026-01-27T15:45:04.712+0000
[SUMMARY] Public Key Authentication 

[INITIAL_DESCRIPTION]
Dear Support Team,
Please could my public key be authorised for use: AAAAC3NzaC1lZDI1NTE5AAAAIBxSn0jwGloBiJ+etrtwLgbA37Z2ZIEXlPuaf2KTjVuu
Yours,
Ayoife Dada.


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Sear Ayoife,
Since you are an internal user, you can authenticate first with your UIS password and use a command like `ssh copy-id` to place the key on CSD3 (see https://askubuntu.com/a/46427  for example). Thanks  
Best wishes, 
Henry
HPC Support
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-98311
[STATUS] RESOLVED
[CREATED] 2026-01-27T14:28:01.929+0000
[SUMMARY] Compiling LAMMPS on Ampere

[INITIAL_DESCRIPTION]
Dear CSD3 support,
I am trying to compile the newest release version of LAMMPS on Ampere with the GPU package. Following the instructions on [https://docs.hpc.cam.ac.uk/hpc/software-packages/lammps.html](https://docs.hpc.cam.ac.uk/hpc/software-packages/lammps.html) leads to an error when running a benchmark:
Cuda driver error 1 in call at file '/home/dc-bole2/git/lammps_amp/lib/gpu/geryon/nvd_kernel.h' in line 340.
Cuda driver error 1 in call at file '/home/dc-bole2/git/lammps_amp/lib/gpu/geryon/nvd_kernel.h' in line 340.
Cuda driver error 1 in call at file '/home/dc-bole2/git/lammps_amp/lib/gpu/geryon/nvd_kernel.h' in line 340.
Cuda driver error 1 in call at file '/home/dc-bole2/git/lammps_amp/lib/gpu/geryon/nvd_kernel.h' in line 340.
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 1 in communicator MPI_COMM_WORLD
with errorcode -1.
NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
This is working without any issues when using version stable_29Aug2024_update2 as per the instructions. By any chance, do you happen to have any information on how to compile a more recent version of LAMMPS?
Many thanks,
Max


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Thank you for your message. I will be investigating this for you and will respond as soon as I have some more information.  In the meantime, if you have any additional updates, questions or comments, please reply and update this ticket.  
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=HELPDESK_ASSIGNEE>
Hi Max, 
Can you give this another go for me using the newest software stack please? 
```
module load rhel8/ampere/base
module load gcc/14.3.0/vlhhcp6m
module load cmake/3.31.10/gcc/7ddsybx7
module load cuda/12.8.1/gcc/kdeps6ab
module load openmpi/4.1.8/gcc/hemliivg 
```
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0003 role=HELPDESK_ASSIGNEE>
Hello,
I have not had any updates on this ticket so I will go ahead and close it for you. If you wish to re-open it, please reply to this email.
Alternatively if you need further support on a different item then please open a new ticket by emailing (not forwarded or a reply to this) [support@hpc.cam.ac.uk](mailto:support@hpc.cam.ac.uk). Thank you
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-98296
[STATUS] RESOLVED
[CREATED] 2026-01-27T13:16:01.482+0000
[SUMMARY] Repeated password requests

[INITIAL_DESCRIPTION]
Hi there,
I am attempting to download CT scan folders from the server rcs.rja50.umzc.ctdata. These folders contain approximately 3000 images each, and I am being requested to input a password before the transfer of every single file. This has happened on multiple machines and has not been an issue previously. It is delaying accessing files significantly and meaning I have to constantly attend downloads. Is there a way to fix this? Thanks in advance.
Best wishes,
Ket
Keturah Smithson (she/her), Managing Operator
Cambridge Biotomography Centre, Department of Zoology
University of Cambridge
CB2 3EJ
Tel: (01223 7) 65405
[https://www.cbc.zoo.cam.ac.uk/](https://www.cbc.zoo.cam.ac.uk/)


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Dear Ket,
Unfortunately this is one of the drawbacks if you are using e.g., FileZilla. You will be prompted to enter credentials for every transfer. We normally suggest compressing the files into a tar or zip to make the transfer smoother and easier. 
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=HELPDESK_ASSIGNEE>
Dear Ket
Can you confirm please if you require any further support with this item? Thank you
Best wishes, 
Henry
HPC Support
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-98292
[STATUS] RESOLVED
[CREATED] 2026-01-27T12:55:02.444+0000
[SUMMARY] Fw: DAWN Access Assistance

[INITIAL_DESCRIPTION]
Dear Support,
Can someone please address this one from yesterday and today? Thanks.
Regards,
Muhammad Ahmed
________________________________
From: Jun Yao Chan <jun@revax.co.uk>
Sent: 27 January 2026 12:34
To: HPC JIRA service desk inbox <jiraservice@hpc.cam.ac.uk>
Cc: Alex Bartlam <Alex@revax.co.uk>; Jack Mander <jack@revax.co.uk>
Subject: DAWN Access Assistance
Hi,
I am looking to gain access to the DAWN Supercomputer, some of my colleagues already have access but I am not set up with an account yet. Are you able to set up login details for my account?
Here is the all the details:
Name: Jun Yao Chan
Email: jun@revax.co.uk
SSH keys: AAAAC3NzaC1lZDI1NTE5AAAAIL+klunbwQNR+EoEuzyqe0y0HGjf25GM3hIfka8DL1Ra
Thanks.
Regards,
Jun


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hello Jun,
You need to be invited to the DAWN project by the PI on Waldur and then we will receive a provisioning ticket for your user account to be created.
Please see this guidance: [Dawn - Intel GPU (PVC) Nodes — CSD3 1.0 documentation](https://docs.hpc.cam.ac.uk/hpc/user-guide/pvc.html#users-accessing-open-on-demand-via-the-portal)
Best wishes,
Henry Carr
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=REPORTER>
Hi Henry,
I have been invited to the Project Revax and needed the login details. Could you set me up for the login details?
Name: Jun Yao Chan
Email: jun@revax.co.uk
SSH keys: AAAAC3NzaC1lZDI1NTE5AAAAIL+klunbwQNR+EoEuzyqe0y0HGjf25GM3hIfka8DL1Ra
Thanks.
Regards,
Jun
</MESSAGE>

<MESSAGE id=0003 role=HELPDESK_ASSIGNEE>
Hello Jun,
Please follow [Dawn - Intel GPU (PVC) Nodes — CSD3 1.0 documentation](https://docs.hpc.cam.ac.uk/hpc/user-guide/pvc.html#users-accessing-open-on-demand-via-the-portal) and accept the invitation to join the project, once this is done we can create your login account.
Best wishes,
Henry Carr
HPC Support
</MESSAGE>

<MESSAGE id=0004 role=HELPDESK_ASSIGNEE>
Hi @Deepak Aggarwal has this user accepted their invitation and if so what steps do they need to take next? Thanks
</MESSAGE>

<MESSAGE id=0005 role=HELPDESK_PRINCIPAL_INVESTIGATOR>
Hi @Henry Carr, I created a local account, and they should have received an email to set up their password. Using the email and password, they can log in to the Dawn access portal to accept the project invitation.
Please check this https://ucam-rcs.atlassian.net/browse/HPCSSUP-98074 for more details, as it relates to the same project and the user was added today.
</MESSAGE>

<MESSAGE id=0006 role=HELPDESK_ASSIGNEE>
Hello 
We’ve created a local account, and you should have received an email to set up your password. Using the email and password, you can log in to the Dawn access portal to accept the project invitation. 
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0007 role=HELPDESK_ASSIGNEE>
Dawn user account was created and user has been sent instructions on that ticket.
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-98278
[STATUS] RESOLVED
[CREATED] 2026-01-27T11:04:05.502+0000
[SUMMARY] Cannot login to the HPC web portal

[INITIAL_DESCRIPTION]
Dear HPC support team,
I have received the email that the HPC login issue has been resolved. But since yesterday evening till now, I still cannot login via the web portal [https://login-web.hpc.cam.ac.uk/](https://login-web.hpc.cam.ac.uk/). I wonder if this issue has been resolved or not.
Best,
Yiran


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hello 
Can you please try clearing your cache or switching to another browser window to see if the issue is simply a browser caching problem? If that doesn’t work, can you please confirm if this link lets you log in?
https://login-web.hpc.cam.ac.uk/nginx/stop?redir=/pun/sys/dashboard/ 
 
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=TICKET_CREATOR>
Hi Henry!
Yes this one works. What is the difference? And thanks for the hint. Maybe I should clear my cache. But switching browser doesn't really work though. I have tried both chrome and edge.
Thanks for the help!
Best,
Yiran
</MESSAGE>

<MESSAGE id=0003 role=HELPDESK_ASSIGNEE>
Hi Yiran,
This link is just a redirect that changes the path to login-web. The original link should work eventually however.  
Best wishes, 
Henry
HPC Support
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-98277
[STATUS] RESOLVED
[CREATED] 2026-01-27T11:04:02.926+0000
[SUMMARY] Scheduling jobs during maintenance

[INITIAL_DESCRIPTION]
Good morning,
I have a question regarding the cluster’s behavior during reduced power consumption periods. I’ve noticed that jobs submitted during these windows are accepted and scheduled, but they execute at a significantly lower speed. This has led to several jobs timing out before completion, resulting in a loss of compute hours and requiring expensive reruns (even when requesting the same amount of resources as previously successful jobs).
Is there a way to prevent jobs from starting if the cluster is in a low-power state? Specifically, I’m looking for a requirement or constraint I can add to my job scripts (e.g., a specific #SLURM flag) to ensure they only run when full performance resources are available.
Thank you for your help!
Best regards,
Clara


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hi Clara,
The power status of the cluster will not change how your jobs perform since slurm will only start them once the resources become available. Specific slowdowns will likely be down to the status of the RDS shared file system whose performance changes based on the demand put on it. My advice is to continue submitting jobs as usual and if necessary, request in your submission script that they not be re-queued. 
Best wishes, 
Henry
HPC Support
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-98114
[STATUS] RESOLVED
[CREATED] 2026-01-24T09:00:01.299+0000
[SUMMARY] Unusually long queue time 

[INITIAL_DESCRIPTION]
Dear Support Desk,
*
Your name: Jiakai Chen
*
Your account/PI: Prof. Sebastian Schemm/ Prof. Simon Driscoll (account: schemm-sl+)
*
your job submission script: Job ID 21047257
*
the working directories or paths you are using (e.g. /rds/user/$USER/hpc-work/foo/bar/): /home/jc2405/Project/neuralgcm/neuralgcm
*
as much detail as possible on what you are working on, what you have tried, and error messages you receive:
The above script requests for 20 minutes of GPU (1 node) but it has been in the queue for around 15 hours, while it usually takes just around an hour. Can I check if that's expected? Thank you.
Best,
Kai


[CONVERSATION]
<MESSAGE id=0001 role=TICKET_CREATOR>
Hi,
The job was ran after two days of queue, however I have some new issues:
I also lost access to both the CSD3 dashboard and SSH services. In the dashboard login ([https://id.hpc.cam.ac.uk/](https://id.hpc.cam.ac.uk/)), I used the exact same password and email, which was autofilled and I checked manually, but it gives an error "Invalid username or password.". I could, however, log in through MyAccessID.
I also noticed that I only received email notification for the start of 21112568, when usually I will receive email for the start and completion of each job.
I also am not able to access via SSH anymore, either through VSCode or through CSD3 shell access.
All this happened after my previous ticket about unusually long queue time (https://ucam-rcs.atlassian.net/browse/HPCSSUP-98114#icft=HPCSSUP-98114), where for the two jobs above it waited around 2 days, when usually it only takes around 30 min for the same configurations. ,
Thanks,
Kai
Get Outlook for Android<[https://aka.ms/AAb9ysg](https://aka.ms/AAb9ysg)>
</MESSAGE>

<MESSAGE id=0002 role=HELPDESK_ASSIGNEE>
Dear Kai,
I’ve checked and can see that you cancelled these jobs? Please note that queue times are liable to change significantly as demand (and correspondingly,  the ability of the cluster to meet it) changes. Cancelling your jobs will invalidate their position in the queue and removes any additional priority in the running order they would have accumulated by staying in the queue. Rest assured, your jobs will run as soon as the cluster is able to accommodate  them. 
Regarding your other question, yes we are aware of this and are looking into the problem. Thank you.
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0003 role=TICKET_CREATOR>
Hi Henry,
Thank you, I'm now able to log back in.
Just wanted to check, is there any way to for us to check the expected wait time for a job?
Also, if I already have a sbatch job in queue, will starting another request for an interactive node affect the queue time for the old sbatch job request?
Best,
Kai
</MESSAGE>

<MESSAGE id=0004 role=HELPDESK_ASSIGNEE>
Dear Kai,
No problem. Yes to check roughly when a job will start, you can use `squeue -u <your CRSid> --start`. Regarding your second question, no starting an interactive job at the same time as queuing up a batch job will not alter the priority of either job. 
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0005 role=TICKET_CREATOR>
Hi Henry,
Thank you for the prompt reply!
Sorry can I just ask another question: The expected start time for my interactive node is tomorrow afternoon, but if I lose connection to ssh any time before that (e.g. if my computer sleeps), the job will be cancelled automatically. Is there any solutions to that? Thanks!
Best,
Kai
</MESSAGE>

<MESSAGE id=0006 role=HELPDESK_ASSIGNEE>
Hello Kai,
For this purpose, we would suggest using Tmux to preserve your terminal session. Please see https://github.com/tmux/tmux/wiki/Getting-Started  for more information. 
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0007 role=HELPDESK_ASSIGNEE>
Dear Kai,
Do you still require support on this item please?  
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0008 role=TICKET_CREATOR>
Dear Henry,
No I don't, thanks for your help!
Best,
Kai
Get Outlook for Android<[https://aka.ms/AAb9ysg](https://aka.ms/AAb9ysg)>
</MESSAGE>

<MESSAGE id=0009 role=HELPDESK_ASSIGNEE>
Thank you for the update,
I will go ahead and mark this issue as closed for you. If you wish to re-open it, please reply to this email.
Alternatively if you need further support on a different item then please open a new ticket by emailing (not forwarded or a reply to this) [support@hpc.cam.ac.uk](mailto:support@hpc.cam.ac.uk). Thank you
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-98039
[STATUS] RESOLVED
[CREATED] 2026-01-22T18:46:02.632+0000
[SUMMARY] Slurm jobs not executing

[INITIAL_DESCRIPTION]
Dear HPC team,
I am Tigran, an MPhil student in ACS. I am using the CSD3 server for my MPhil dissertation, the slurm jobs that I submit do not leave the queue and start executing.
When I run mybalance command, it shows that the available hours is 1, is this the cause?
Best,
Tigran


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hello Tigran,
Can you please attach your submission script here.
Best regards,
Elisabeth Reeve
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=TICKET_CREATOR>
Dear Elisabeth,
Here is my slurm bash script
"20910394_submission.sh" 20L, 824C                                                                                              1,1           All
#!/bin/bash
1. Parameters
#SBATCH --account=LIO-SL2-GPU
#SBATCH --cpus-per-task=32
#SBATCH --error=/home/tf426/grokalign/slurm_jobs/grok/2026-01-21/job_0/%j/%j_0_log.err
#SBATCH --gpus-per-node=1
#SBATCH --job-name=submitit
#SBATCH --mem=80GB
#SBATCH --nodes=1
#SBATCH --open-mode=append
#SBATCH --output=/home/tf426/grokalign/slurm_jobs/grok/2026-01-21/job_0/%j/%j_0_log.out
#SBATCH --partition=ampere
#SBATCH --signal=USR2@90
#SBATCH --time=120
#SBATCH --wckey=submitit
1. command
export SUBMITIT_EXECUTOR=slurm
srun --unbuffered --output /home/tf426/grokalign/slurm_jobs/grok/2026-01-21/job_0/%j/%j_%t_log.out --error /home/tf426/grokalign/slurm_jobs/grok/2026-01-21/job_0/%j/%j_%t_log.err /home/tf426/miniforge3/envs/grok/bin/python3 -u -m submitit.core._submit /home/tf426/grokalign/slurm_jobs/grok/2026-01-21/job_0/%j
Best,
Tigran
</MESSAGE>

<MESSAGE id=0003 role=HELPDESK_ASSIGNEE>
Hello Tigran,
Yes, there is only one computing hour left on LIO-SL2-GPU and so your job will not be able to run. Please cancel the job and resubmit it with the SL3-GPU project account.
Best regards,
Elisabeth
</MESSAGE>

<MESSAGE id=0004 role=TICKET_CREATOR>
Dear Elisabeth,
As an MPhil in Advanced Computer Science student, I believe I should have been allocated 300 A100 GPU hours for my dissertation on the SL2-GPU account by my department, which I would like to utilize, since SL3-GPU queues are extremely long (I have a job that is in the queue for 3 days now) and timewise I am unable to work with it.
Can you please clarify how exactly I should use this 300 hours on SL2?
Best,
Tigran
</MESSAGE>

<MESSAGE id=0005 role=HELPDESK_ASSIGNEE>
Hello Tigran,
You will need to raise this with your PI.
Best regards,
Elisabeth
</MESSAGE>

<MESSAGE id=0006 role=TICKET_CREATOR>
Dear Elisabeth,
I see. Can you please clarify one more thing.
Is this 300 hours specifically going to be allocated for me or the resources are shared across all the counts that are part of my PIs group?
If so, how will I make sure that others do not use the compute that is allocated for me?
Best,
Tigran
</MESSAGE>

<MESSAGE id=0007 role=TICKET_CREATOR>
Dear Elisabeth,
Writing to kindly remind about this.
Thank you for your support.
Best,
Tigran
</MESSAGE>

<MESSAGE id=0008 role=HELPDESK_ASSIGNEE>
Hello Tigran,
No, the 300 hours are added to a shared SL2 resource that is accessible to those who have access to it. You will need to track your usage by using the command “mybalance” to see your usage.
Other such accountancy should be done within your research group.
Best regards,
Elisabeth
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-97991
[STATUS] RESOLVED
[CREATED] 2026-01-22T10:14:02.988+0000
[SUMMARY] Quote for 200 SL2-GPU hours

[INITIAL_DESCRIPTION]
Hello,
I’ve been directed from the UIS support team. I am writing to request a quote for 200 SL2 GPU hours and for the creation of an SL2 GPU account under Dr. Tian Zhao’s name (crsid: txz20). Our current GPU account is ZHAO-SL3-GPU.
Could you please let me know what information is required from our end? I would also appreciate it if you could outline the process for purchasing these resources and for account creation, including any approvals that may be needed. This will allow us to proceed with raising a purchase order.
Thank you very much for your help.
Kind Regards,
Fiona Charlier


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hello Fiona,
Please follow the instructions found on this page: [https://www.hpc.cam.ac.uk/charges](https://www.hpc.cam.ac.uk/charges)
Best regards,
Elisabeth Reeve
HPC Support
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-97962
[STATUS] RESOLVED
[CREATED] 2026-01-21T16:17:10.761+0000
[SUMMARY] SSH login requests TOTP but MFA not set up yet

[INITIAL_DESCRIPTION]
Dear CSD3 support team,
I am able to log in to login.hpc.cam.ac.uk with my username and password, after which I am prompted to enter a TOTP code.
However, I have not yet been able to set up CSD3 MFA:
- I never received a QR code for CSD3 TOTP
- login-web.hpc.cam.ac.uk reports invalid username or password
- connecting to multi.hpc.cam.ac.uk closes the connection immediately after password entry
Could you please help me with this? Thank you in advance!
My username: jh2642
Best regards,
Jin Huang
—
Jin Huang
Marie Skłodowska-Curie Postdoctoral Fellow
@ AFAR Lab<[https://cambridge-afar.github.io/](https://cambridge-afar.github.io/)>, University of Cambridge
[https://www.cst.cam.ac.uk/people/jh2642](https://www.cst.cam.ac.uk/people/jh2642)


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hello Jin,
Have you previously applied for an account via this form: [Internal HPC Application Form | Research Computing Services (cam.ac.uk)](https://www.hpc.cam.ac.uk/rcs-application)
If not, please fill it out with your details and your PI’s details and submit it. That will trigger the account process for you to get access.
Please let me know if this is not the case and we can investigate further!
Best regards,
Elisabeth Reeve 
HPC Support
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-97859
[STATUS] RESOLVED
[CREATED] 2026-01-20T12:04:10.591+0000
[SUMMARY] Running TensorFlow on ampere: "module load python/3.8.11/gcc-9.4.0-yb6rzr6" not found. 

[INITIAL_DESCRIPTION]
Dear Support,
I'm William Lee, working with Mike Roberts e.g. MROBERTS-SL3-GPU and AUTOQC-DAMTP-SL2-GPU.
I'd like to run TensorFlow on ampere and I've been trying to follow the instructions here:
[https://docs.hpc.cam.ac.uk/hpc/software-packages/tensorflow.html](https://docs.hpc.cam.ac.uk/hpc/software-packages/tensorflow.html)
But the line
module load python/3.8.11/gcc-9.4.0-yb6rzr6
doesn't work.
Is there an updated version of the instructions or a drop-in replacement for this line please?
Best wishes,
William.


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hello William,
Are you following the instructions while in an interactive session, as indicated, on an ampere node? 
I can see that the module is available as such:
```
[er666@gpu-q-38 ~]$ module avail python/3.8.11
--- /usr/local/software/spack/spack-modules/a100-20210927/linux-centos8-zen2 ---
python/3.8.11/gcc-9.4.0-yb6rzr6
```
Is it that the module does not load appropriately? Please let me know if you continue to have issues.
Best regards,
Elisabeth Reeve
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=HELPDESK_ASSIGNEE>
Hello William,
Do you require support on this still? If not, I will close this ticket.
Best regards,
Elisabeth Reeve
</MESSAGE>

<MESSAGE id=0003 role=TICKET_CREATOR>
Thanks for your help. I can load the module as long as I omit the "module purge" command.  Please do close the ticket.
[https://public.www.evernote.com/resources/s281/00a29f63-8484-a421-36f3-9bfa093435f8](https://public.www.evernote.com/resources/s281/00a29f63-8484-a421-36f3-9bfa093435f8)
Best wishes,
William
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-97741
[STATUS] RESOLVED
[CREATED] 2026-01-16T16:21:32.400+0000
[SUMMARY] CSD3 login - vm462

[INITIAL_DESCRIPTION]
Hello,
For some reason I cannot log into the CSD3 headnodes. I was logged in yesterday, and after some idle period I had to log back in, and since then I cannot log in.
I enter my password and MFA details, then it requests for password again (seemingly looking like my password is wrong, though I'm sure I've entered it correctly as I had been logging in and out lately).
Do you have any ideas? (user vm462)
Cheers,
Vijay
Dr Vijay Mahatma
Research Associate
Battcock Centre for Experimental Astrophysics (Room G04)
Cavendish Laboratory, University of Cambridge


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Dear Vijay,
It looks like your account has been password locked owing to too many unsuccessful login attempts. This will clear on its own after 30 minutes. Once it does, please make sure to enter your UIS/Raven password when prompted in the terminal. 
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=TICKET_CREATOR>
Dear Henry,
Okay — I had changed my UIS/Raven password recently due to University policy, and I wasn't aware that it would automatically update my CSD3 login password. I'll try again at 5pm, if it still doesn't work I will let you know.
Cheers,
Vijay
Dr Vijay Mahatma
Research Associate
Battcock Centre for Experimental Astrophysics (Room G04)
Cavendish Laboratory, University of Cambridge
</MESSAGE>

<MESSAGE id=0003 role=TICKET_CREATOR>
Issue is resolved.
Many thanks
Dr Vijay Mahatma
Research Associate
Battcock Centre for Experimental Astrophysics (Room G04)
Cavendish Laboratory, University of Cambridge
</MESSAGE>

<MESSAGE id=0004 role=HELPDESK_ASSIGNEE>
Thank you for the update,
I will go ahead and mark this issue as closed for you. If you wish to re-open it, please reply to this email.
Alternatively if you need further support on a different item then please open a new ticket by emailing (not forwarded or a reply to this) support@hpc.cam.ac.uk. Thank you
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-97739
[STATUS] RESOLVED
[CREATED] 2026-01-16T15:53:33.762+0000
[SUMMARY] HPC password

[INITIAL_DESCRIPTION]
Hello,
Please advise, I do not know the password. I do not think I ever set up my password when I first activated my account.
faylindfield@user0252 ~ % ssh fl483@login-icelake.hpc.cam.ac.uk
<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>
<>                                                        <>
<>                        
[FILE ATTACHMENT]
                       <>
<>                                                        <>
<>                    RCS CSD3 Facility                   <>
<>             Unauthorised Access Prohibited             <>
<>    Use of this system constitutes acceptance of our    <>
<>                     policies - see                     <>
<> [http://docs.hpc.cam.ac.uk/hpc/user-guide/policies.html](http://docs.hpc.cam.ac.uk/hpc/user-guide/policies.html) <>
<>        All data is stored in the United Kingdom.       <>
<>                                                        <>
<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>
(fl483@login-icelake.hpc.cam.ac.uk) Password:
Thank you for your help,
Best wishes,
Fay


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Dear Fay,
Your HPC password is the same as your UIS/Raven password. Please authenticate using that and the TOTP token called “CSD3:ssh”.  
Best wishes, 
Henry
HPC Support
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-97675
[STATUS] RESOLVED
[CREATED] 2026-01-15T15:36:31.425+0000
[SUMMARY] SRCP Epi platform - storage query

[INITIAL_DESCRIPTION]
Hi,
We would like to archive some old projects on our platform. Is RFS the only storage option available, or is RCS available from within the SRCP?
Thanks
Tom


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hi @Greg Habrych Is this something we can allow SRCP users to do? Thanks
</MESSAGE>

<MESSAGE id=0002 role=OTHER>
Hi @Henry Carr , by design SRCP has no access to any outside storage. If this is a one-off operation we can help copying data to nominated RFS project.
</MESSAGE>

<MESSAGE id=0003 role=HELPDESK_ASSIGNEE>
Thanks Greg, just wanted to be sure I hadn’t overlooked anything
</MESSAGE>

<MESSAGE id=0004 role=HELPDESK_ASSIGNEE>
Dear Tom
I’m afraid that by design SRCP has no access to any outside storage. If this is a one-off operation we can help copying data to nominated RFS project. Thanks
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0005 role=TICKET_CREATOR>
Hi Henry,
Thanks for the response. I guess I could pitch my question slightly differently. My understanding is that somehow storage for SRCP is provisionned on RFS. Is this RFS dedicated hardware that is isolated for use by a particular platform? Or does it work differently? In which case, is there the option to have dedicated RCS hardware, which will be cheaper?
Thanks
Tom
</MESSAGE>

<MESSAGE id=0006 role=HELPDESK_ASSIGNEE>
Hi Tom,
By design, the RFS shares associated with SRCP projects are separate from other storage systems and are totally isolated. Whilst we don’t presently have any plans to merge e.g., cold storage with the SRCP, you may be able to achieve this by downloading the data and re-uploading it to an RCS project of your choice. Thanks  
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0007 role=TICKET_CREATOR>
OK understood, thank you. I think this can be closed now.
Tom
</MESSAGE>

<MESSAGE id=0008 role=HELPDESK_ASSIGNEE>
Thank you for the update,
I will go ahead and mark this issue as closed for you. If you wish to re-open it, please reply to this email.
Alternatively if you need further support on a different item then please open a new ticket by emailing (not forwarded or a reply to this) support@hpc.cam.ac.uk. Thank you
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-97660
[STATUS] RESOLVED
[CREATED] 2026-01-15T13:32:33.376+0000
[SUMMARY] Adding new user to the lab RFS/RDS space

[INITIAL_DESCRIPTION]
Dear HPC support team, 
Apologies for bothering you about this.
A couple of days ago, I added Victor (CC’d; CRSid: vj292) to our lab RDS (rds-djh1002-hodson-rds) and RFS-NFS (rfs-djh1002-hodson-rfs-nfs) space. However, in the self-service portal he is still showing as “Provisioning”.
I just wanted to check whether there is anything we can do to speed up access to the data, or whether there is something we may have missed on our end.
Many thanks for your help.
Best wishes, 
Joanna


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Dear Joanna,
Thank you for your message. I have checked on the system and I can see that Victor has not yet accepted the terms and conditions of the storage service. This can be done if they visit [https://selfservice.uis.cam.ac.uk/account/](https://selfservice.uis.cam.ac.uk/account/) then click on the link(s) to the project(s) in question. 
Once the terms and conditions are accepted, a provisioning ticket is sent to us which we can then use to activate their access. Al parties will be notified by email automatically once this happens. 
Best wishes, 
Henry
HPC Support
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-97622
[STATUS] RESOLVED
[CREATED] 2026-01-14T15:22:30.914+0000
[SUMMARY] TumourVue SRCP platform

[INITIAL_DESCRIPTION]
Dear Team,
I appreciate your help with setting up a level 3 (given high IP value) SRCP platform for TumourVue - cancer surgery trials data. Three of my masters students will have access. The data sharing agreement is in place.
The students will start next week and I would be grateful if I could please have your support as a high priority.
Thanks a lot
Gita
—
Gita Khalili Moghaddam, PhD
Principal Investigator
Department of Clinical Neurosciences
University of Cambridge
CB2 0QQ
Royal Society Industry Fellow
GSK Global Health
While it suits me to email outside normal working hours, I do not expect a response outside your own.


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hi Gita,
Can you please clarify what is being requested here so that we can assist you? Do the students for example need access to a project/platform? If so please ask them to consult https://docs.hpc.cam.ac.uk/srcp/user-onboarding/index.html#user-onboarding  and fill out an access request form, making sure to request the correct role and project/platform.  The link to do so can be found here [https://www.hpc.cam.ac.uk/srcp-request-user-access](https://www.hpc.cam.ac.uk/srcp-request-user-access)
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=TICKET_CREATOR>
Hello Henry,
Many thanks for getting back to me. I need to setup a new platform for TumourVue (separate from existing Predict) because the data are from different trials. The students will need access settings similar to what Suleiman does for Predict to analyse images using Python.
The funding is available to set up this new platform for one year initially.
Thank you
Gita
—
Gita Khalili Moghaddam, PhD
Principal Investigator
Department of Clinical Neurosciences
University of Cambridge
CB2 0QQ
Royal Society Industry Fellow
GSK Global Health
While it suits me to email outside normal working hours, I do not expect a response outside your own.
</MESSAGE>

<MESSAGE id=0003 role=HELPDESK_ASSIGNEE>
Hi Gita,
In this case, you will need to fill out an SRCP resource request by following this link [https://www.hpc.cam.ac.uk/form/srcp-resource-request](https://www.hpc.cam.ac.uk/form/srcp-resource-request). Please also consult this documentation:  https://docs.hpc.cam.ac.uk/srcp/user-onboarding/index.html#user-onboarding  for clarity on the different levels on the SRCP platforms. Thanks
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0004 role=TICKET_CREATOR>
Many thanks Henry, submitted.
Gita
—
Gita Khalili Moghaddam, PhD
Principal Investigator
Department of Clinical Neurosciences
University of Cambridge
CB2 0QQ
Royal Society Industry Fellow
GSK Global Health
While it suits me to email outside normal working hours, I do not expect a response outside your own.
</MESSAGE>

<MESSAGE id=0005 role=HELPDESK_ASSIGNEE>
Great, thanks. We're processing that and will attach updates to the request when they are available.
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-97621
[STATUS] RESOLVED
[CREATED] 2026-01-14T15:12:32.349+0000
[SUMMARY] Help creating python/conda environment on CSD3

[INITIAL_DESCRIPTION]
Hi,
I am a new user of CSD3 and I am trying to create a virtual environment for the few Python libraries I need for my project (those in requirements.txt file), but I run into the following error when trying to install them by the usual conda -c conda-forge [library]:
Collecting package metadata (current_repodata.json): done
Solving environment: failed with initial frozen solve. Retrying with flexible solve.
Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.
Collecting package metadata (repodata.json): done
Solving environment: failed with initial frozen solve. Retrying with flexible solve.
Solving environment: /
Found conflicts! Looking for incompatible packages.
This can take several minutes.  Press CTRL-C to abort.
failed
UnsatisfiableError: The following specifications were found to be incompatible with each other:
Package sqlite conflicts for:
python=3.12 -> sqlite[version='>=3.41.2,<4.0a0|>=3.45.3,<4.0a0|>=3.50.2,<4.0a0']
Package tzdata conflicts for:
python=3.12 -> tzdata
Package libcblas conflicts for:
numpy=2.3.5 -> libcblas[version='>=3.9.0,<4.0a0']
Package libffi conflicts for:
python=3.12 -> libffi[version='>=3.4,<4.0a0|>=3.4.6,<3.5.0a0|>=3.5.2,<3.6.0a0']
Package expat conflicts for:
python=3.12 -> expat[version='>=2.5.0,<3.0a0|>=2.6.2,<3.0a0|>=2.6.3,<3.0a0|>=2.6.4,<3.0a0|>=2.7.1,<3.0a0']
Package mkl_random conflicts for:
numpy=2.3.5 -> mkl_random
Package bzip2 conflicts for:
python=3.12 -> bzip2[version='>=1.0.8,<2.0a0']
Package libexpat conflicts for:
python=3.12 -> libexpat[version='>=2.5.0,<3.0a0|>=2.6.2,<3.0a0|>=2.6.3,<3.0a0|>=2.6.4,<3.0a0|>=2.7.0,<3.0a0|>=2.7.1,<3.0a0']
Package readline conflicts for:
python=3.12 -> readline[version='>=8.0,<9.0a0|>=8.1.2,<9.0a0|>=8.2,<9.0a0']
Package pip conflicts for:
python=3.12 -> pip
Package blas conflicts for:
numpy=2.3.5 -> blas[version='*|1.0',build='mkl|openblas']
Package tk conflicts for:
python=3.12 -> tk[version='>=8.6.12,<8.7.0a0|>=8.6.13,<8.7.0a0|>=8.6.14,<8.7.0a0|>=8.6.15,<8.7.0a0']
Package libxcrypt conflicts for:
python=3.12 -> libxcrypt[version='>=4.4.36']
Package openssl conflicts for:
python=3.12 -> openssl[version='>=3.0.11,<4.0a0|>=3.0.12,<4.0a0|>=3.0.13,<4.0a0|>=3.0.14,<4.0a0|>=3.0.15,<4.0a0|>=3.0.16,<4.0a0|>=3.0.18,<4.0a0|>=3.1.3,<4.0a0|>=3.2.0,<4.0a0|>=3.2.1,<4.0a0|>=3.3.1,<4.0a0|>=3.3.2,<4.0a0|>=3.4.0,<4.0a0|>=3.4.1,<4.0a0|>=3.5.0,<4.0a0|>=3.5.4,<4.0a0']
Package libblas conflicts for:
numpy=2.3.5 -> libblas[version='>=3.9.0,<4.0a0']
Package libsqlite conflicts for:
python=3.12 -> libsqlite[version='>=3.43.0,<4.0a0|>=3.44.2,<4.0a0|>=3.45.1,<4.0a0|>=3.45.2,<4.0a0|>=3.46.0,<4.0a0|>=3.46.1,<4.0a0|>=3.47.0,<4.0a0|>=3.48.0,<4.0a0|>=3.49.1,<4.0a0|>=3.50.0,<4.0a0|>=3.50.4,<4.0a0']
Package python_abi conflicts for:
python=3.12 -> python_abi=3.12[build=*_cp312]
numpy=2.3.5 -> python_abi[version='3.11.|3.12.|3.13.|3.13.|3.14.|3.14.',build='_cp313t|_cp311|_cp312|_cp313|_cp314|_cp314t']
Package libuuid conflicts for:
python=3.12 -> libuuid[version='>=1.41.5,<2.0a0|>=2.38.1,<3.0a0|>=2.41.2,<3.0a0']
Package ld_impl_linux-64 conflicts for:
python=3.12 -> ld_impl_linux-64[version='>=2.35.1|>=2.36.1']
Package __glibc conflicts for:
numpy=2.3.5 -> __glibc[version='>=2.17,<3.0.a0|>=2.28,<3.0.a0']
python=3.12 -> __glibc[version='>=2.17,<3.0.a0']
Package xz conflicts for:
python=3.12 -> xz[version='>=5.2.6,<6.0a0|>=5.4.2,<6.0a0|>=5.4.5,<6.0a0|>=5.4.6,<6.0a0|>=5.6.4,<6.0a0']
Package libgcc conflicts for:
python=3.12 -> libgcc[version='>=13|>=14']
numpy=2.3.5 -> libgcc[version='>=14|>=14,>=14']
Package libgcc-ng conflicts for:
python=3.12 -> libgcc-ng[version='>=11.2.0|>=12']
Package libstdcxx conflicts for:
numpy=2.3.5 -> libstdcxx[version='>=14']
Package numpy-base conflicts for:
numpy=2.3.5 -> numpy-base==2.3.5[build='py314h5cadfd5_0|py312h4bc27c9_0|py311h4bc27c9_0|py311h00548fb_0|py312h00548fb_0|py313h00548fb_0|py313h4bc27c9_0|py314h7c74580_0']
Package ncurses conflicts for:
python=3.12 -> ncurses[version='>=6.4,<7.0a0|>=6.4.20240210,<7.0a0|>=6.5,<7.0a0']
Package libopenblas conflicts for:
numpy=2.3.5 -> libopenblas[version='>=0.3.30,<1.0a0']
Package libnsl conflicts for:
python=3.12 -> libnsl[version='>=2.0.0,<2.1.0a0|>=2.0.1,<2.1.0a0']
Package mkl_fft conflicts for:
numpy=2.3.5 -> mkl_fft
Package liblzma conflicts for:
python=3.12 -> liblzma[version='>=5.6.3,<6.0a0|>=5.6.4,<6.0a0|>=5.8.1,<6.0a0']
Package libzlib conflicts for:
python=3.12 -> libzlib[version='>=1.2.13,<2.0.0a0|>=1.3.1,<2.0a0']
Package mkl conflicts for:
numpy=2.3.5 -> mkl[version='>=2025.0.0,<2026.0a0']
Package zlib conflicts for:
python=3.12 -> zlib[version='>=1.2.13,<2.0.0a0|>=1.2.13,<2.0a0']
Package mkl-service conflicts for:
numpy=2.3.5 -> mkl-service[version='>=2.3.0,<3.0a0']
Package liblapack conflicts for:
numpy=2.3.5 -> liblapack[version='>=3.9.0,<4.0a0']
Which seems to be due to conflicts, with the central packages?
I already tried using virtualenv and pip, but some packages (such as pytorch) need to be installed outside of it, so I was trying to use conda for it. I also tried using the central packages, but I cannot make it work. Do you know what is the problem here? Is it something specific to CSD3? Is there a best practice for installing packages in CSD3 in this case?
Best,
Nico


[CONVERSATION]
<MESSAGE id=0001 role=TICKET_CREATOR>
[FILE ATTACHMENT]
 (0.2 kB)
</MESSAGE>

<MESSAGE id=0002 role=HELPDESK_ASSIGNEE>
Hi Nico,
Can you please provide some more information for me? Are you using the central miniconda module for example? We advise against this since it’s quite old now and won’t function as well as a personal install. Can you similarly please provide any and all commands you’ve used to build these packages? Thanks. 
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0003 role=TICKET_CREATOR>
Hi Henry,
Thanks for the quick response.
I am not sure what's the central miniconda module, I ran this command to create the environment:
conda create -n gnn-crn -c conda-forge python=3.12
conda activate gnn-crn
conda install -c conda-forge numpy=2.3.5
Is this the recommended way of using environments in the HPC?
Best,
Nico
</MESSAGE>

<MESSAGE id=0004 role=HELPDESK_ASSIGNEE>
Hi Nico, 
Firstly, I’d suggest downloading and installing miniconda into your `hpc-work` by following https://www.anaconda.com/docs/getting-started/miniconda/install#linux-terminal-installer . 
Then, the steps will look like this: 
1. Create the env with the specific Python version with `conda create -n HPCSSUP-97621 python=3.12.4 -y`
2. Activate it with `conda activate HPCSSUP-97621`
3. Install rdkit specifically from conda-forge (standard practice for rdkit) with `conda install -c conda-forge rdkit=2025.09.2 -y`
4. Install the requirements.txt using `pip install -r requirements.txt` on the requirements file I’ve attached below.
The error you saw is happening because your version requirements are logically impossible to satisfy because of NumPy 2.x binary breaking changes. Specifically, Matplotlib 3.8.3 was built for the NumPy 1.x era. It contains a hard requirement for `numpy<2`, while you are explicitly asking for `numpy==2.3.5`. It will take some time for this venv to build but it should work fine on one of the login nodes, thanks.
[FILE ATTACHMENT]
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0005 role=TICKET_CREATOR>
Hi Henry,
Thank you so much, it worked perfectly!
Best regards,
Nico
</MESSAGE>

<MESSAGE id=0006 role=HELPDESK_ASSIGNEE>
Thank you for the update,
I will go ahead and mark this issue as closed for you. If you wish to re-open it, please reply to this email.
Alternatively if you need further support on a different item then please open a new ticket by emailing (not forwarded or a reply to this) support@hpc.cam.ac.uk. Thank you
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-97477
[STATUS] RESOLVED
[CREATED] 2026-01-14T11:15:30.658+0000
[SUMMARY] Getting write permission to rds project 

[INITIAL_DESCRIPTION]
Hi,
I need read and write access to the rds project rds-bru20-ukbb with the project ID isCN5CtgAac. I don’t think it’s possible to add two data managers, but I don’t think I can upload files to that rds without write permission. How else can this permission be given? Thanks!
Best wishes,
Emilia


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hello Emilia,
Data Owners can add as many Data Managers as are required on the project.  I can see that you are a Data User so you will need to discuss with either the Data Owner/ a Data Manager and either: 
1. Re-assign your role as Data Manager
2. Grant the required permissions in line with [https://docs.hpc.cam.ac.uk/storage/rds/permissions.html](https://docs.hpc.cam.ac.uk/storage/rds/permissions.html)
Best wishes, 
Henry
HPC Support
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-96933
[STATUS] RESOLVED
[CREATED] 2025-12-26T00:50:31.028+0000
[SUMMARY] SSH login failing 

[INITIAL_DESCRIPTION]
Hi Sir/Madam,
Hope you are doing well! I am having some troubles in SSHing into the HPC.
I can successfully log into [https://login-web.hpc.cam.ac.uk](https://login-web.hpc.cam.ac.uk/) using my CRSid (vd327), and my HPC account appears to be active.
However, when I try to log in via SSH (e.g. ssh vd327@login-cpu.hpc.cam.ac.uk), I am prompted for my password and then a TOTP verification code, but after three attempts I receive “Permission denied”.
I have verified that:
- I am using my Cambridge Raven/UIS password
- MFA/TOTP is set up and working for login-web
- The SSH host key has been accepted correctly
Could you please advise me on what I should do/ how to fix this?
Many thanks,
Vivek Dherani


[CONVERSATION]
<MESSAGE id=0001 role=TICKET_CREATOR>
I also should mention that I also changed my password.
Thanks,
Vivek
</MESSAGE>

<MESSAGE id=0002 role=HELPDESK_ASSIGNEE>
Hello Vivek,
I can see that you have not got MFA set up for SSH, please follow this guide: [MultiFactor Authentication (MFA) — CSD3 1.0 documentation](https://docs.hpc.cam.ac.uk/hpc/user-guide/mfa.html#walkthrough-ssh-to-multi-hpc-cam-ac-uk)
Best regards,
Elisabeth Reeve
HPC Support
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-96776
[STATUS] RESOLVED
[CREATED] 2025-12-18T10:52:31.516+0000
[SUMMARY] Fw: Unable to submit slurm jobs on callender+

[INITIAL_DESCRIPTION]
Hi,
I can’t submit any Slurm jobs using the Callender+ account, PI Dr Callender copied in,  because it doesn’t seem to have any partitions attached to it, so every sbatch call fails with an “Invalid account or account/partition combination” error. I can install packages on the login node, but can’t see that my environment works end-to-end without running jobs on compute nodes. I would be grateful for your advice on whether a CPU partition is available under callender+ and how to resolve this please?
Best wishes,
Megha


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hi Megha,
Can you please show me the command you used to see which slurm account to submit your jobs?  
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=TICKET_CREATOR>
When I just submit an
sbatch gen.sh
It seems to run it on schonlieb so I tried to specify within my gen.sh file with the following:
#SBATCH —account=callender+
#SBATCH —partition=cclake
Best wishes,
Megha
</MESSAGE>

<MESSAGE id=0003 role=HELPDESK_ASSIGNEE>
Hi Megha,
Thanks, can you please show me the command you used or how you determined what the account was called? I’m asking because you should be using the `mybalance` command. Running this should show 
```
 User           Usage |        Account     Usage | Account Limit Available (hours)
---------- --------- + -------------- --------- + ------------- ---------
mb2023             0 | CALLENDER-SL3-CPU         0 |       200,000   200,000
mb2023             0 | CALLENDER-SL3-GPU         0 |         3,000     3,000
mb2023            10 | SCHONLIEB-SL3-CPU    16,695 |       216,372   199,677
```
Please see https://docs.hpc.cam.ac.uk/hpc/user-guide/batch.html?accounting-commands#accounting-commands 
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0004 role=TICKET_CREATOR>
Ah thank you for clarifying because I wasn’t using that!
So, what command should I use to submit a job under the callender account please?
Currently I just use sbatch
Best wishes,
Megha
</MESSAGE>

<MESSAGE id=0005 role=HELPDESK_ASSIGNEE>
Hi Megha,
Yes, `sbatch` is the correct command. The command needed to find your accounts is `mybalance`. Please change your submission script lines to include 
```
#SBATCH —account=CALLENDER-SL3-CPU 
#SBATCH —partition=cclake
```
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0006 role=TICKET_CREATOR>
Hi Henry,
Thank you - I added those lines to my script(below) but I still get
(base) [mb2023@login-p-3 new]$ sbatch run_gan_job.sh
sbatch: error: Batch job submission failed: Invalid account or account/partition combination specified
run_gan_job.sh:
#!/bin/bash
#SBATCH --job-name=synthmed_job
#SBATCH --output=synthmed_job_%j.out
#SBATCH --error=synthmed_job_%j.err
#SBATCH --time=01:00:00
#SBATCH --mem=8G
#SBATCH --cpus-per-task=1
#SBATCH --account=CALLENDER-SL3_CPU
#SBATCH --partition=cclake
source ~/.bashrc
conda activate synth_env_backup
cd /home/mb2023/my_hpc_projects/synthcity-docker-project/new
python main_GAN_script.py
Best wishes,
Megha
</MESSAGE>

<MESSAGE id=0007 role=HELPDESK_ASSIGNEE>
Hello 
Please note that you added `CALLENDER-SL3_CPU` in place of `CALLENDER-SL3-CPU` . The latter option should let you submit this job, thanks.
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0008 role=TICKET_CREATOR>
whoops! Thank you!
</MESSAGE>

<MESSAGE id=0009 role=HELPDESK_ASSIGNEE>
No problem, do you have any further questions for us? Thanks 
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0010 role=TICKET_CREATOR>
All good - thank you for your help!
Best wishes,
Megha
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-96609
[STATUS] RESOLVED
[CREATED] 2025-12-15T08:00:29.592+0000
[SUMMARY] Adding student collaborators to RDS disk and supervisor's accounts

[INITIAL_DESCRIPTION]
Hello HPC support team,
We'd like to add Cambridge MPhil students Boqiao Zhang (bz317) and Oszkar Urban (ou222) to:
1) RDS disk
`rds-posecraft-5SVx1x5hoTY`
2) My supervisor Prof Cengiz Oztireli's accounts
OZTIRELI-SL2-CPU
OZTIRELI-SL2-GPU
OZTIRELI-SL3-CPU
OZTIRELI-SL3-GPU
Please let us know if anything or any approval is needed. Many thanks!
Best wishes,
Zhilin


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Dear Zhilin,
Regarding your first request, we do not control or administer storage project memberships: this is done by the Data Owner/Data Manager(s) associated with that specific storage project via the self-service portal. 
Similarly, we can only add Boqiao Zhang (bz317) and Oszkar Urban (ou222) to:
1. OZTIRELI-SL2-CPU
2. OZTIRELI-SL2-GPU
3. OZTIRELI-SL3-CPU
4. OZTIRELI-SL3-GPU
Once Prof Cengiz (who I’ve added as CC) expresses their approval of us doing so.
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=HELPDESK_PRINCIPAL_INVESTIGATOR>
I approve. Thank you.
Best,
Cengiz
</MESSAGE>

<MESSAGE id=0003 role=HELPDESK_ASSIGNEE>
Boqiao Zhang (bz317) and Oszkar Urban (ou222) have been added to the requested slurm accounts.
Best wishes,
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0004 role=TICKET_CREATOR>
Hello Henry,
I hope you are well!
Boqiao Zhang (bz317) reported that he does not have access to my supervisor's GPU account OZTIRELI-SL2-GPU.
Could you kindly check that access to all four accounts are added for Boqiao Zhang (bz317) and Oszkar Urban (ou222)?
1.  OZTIRELI-SL2-CPU
2.  OZTIRELI-SL2-GPU
3.  OZTIRELI-SL3-CPU
4.  OZTIRELI-SL3-GPU
Many thanks!
Boqiao's terminal output:
User           Usage |        Account     Usage | Account Limit Available (hours)
---------- --------- + -------------- --------- + ------------- ---------
bz317              0 | MLMI-BZ317-SL2-CPU         0 |            20        20
bz317              8 | MLMI-BZ317-SL2-GPU         8 |            20        12
bz317              0 | OZTIRELI-SL2-CPU       960 |       600,000   599,040
bz317              0 | OZTIRELI-SL3-CPU    12,798 |       212,798   200,000
bz317              2 | OZTIRELI-SL3-GPU    12,865 |        15,858     2,993
Best wishes,
Zhilin
</MESSAGE>

<MESSAGE id=0005 role=HELPDESK_ASSIGNEE>
Dear Zhilin,
This has now been sorted for you, thanks. 
Best wishes, 
Henry
HPC Support
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-96250
[STATUS] RESOLVED
[CREATED] 2025-12-04T16:02:30.502+0000
[SUMMARY] "[UKAEA] AIRR Access Last Resort"

[INITIAL_DESCRIPTION]
I have been invited to join the UKAEA early adopters project on AIRR.  Could you please create a local keycloak entry for me.
Name: Waqar Butt ,
Organisation: (UKAEA)
email: waqar.butt@ukaea.uk
partition: UKAEA Early Adopters
Thanks,
Waqar
________________________________
From: airr-admin@hpc.cam.ac.uk <airr-admin@hpc.cam.ac.uk>
Sent: 04 December 2025 15:56
To: Butt, Waqar <waqar.butt@ukaea.uk>
Subject: Invitation to UKAEA Early Use project
You don't often get email from airr-admin@hpc.cam.ac.uk. Learn why this is important<[https://aka.ms/LearnAboutSenderIdentification](https://aka.ms/LearnAboutSenderIdentification)>
Hello!
Aleksander Dubas has invited you to join UKAEA Early Use project in Researcher (project member) role.
Please visit this page<[https://access.hpc.cam.ac.uk/invitation/0aae954f566c4c7485c219c393818a52/](https://access.hpc.cam.ac.uk/invitation/0aae954f566c4c7485c219c393818a52/)> to sign up and accept your invitation. Please note: this invitation expires at 11.12.2025 15:56!
You are invited to join the UKAEA Early Adopters project on AIRR. Once you have registered, please continue to follow the instructions at [https://nucleus.ukaea.uk/page/7190?SearchId=7342533](https://nucleus.ukaea.uk/page/7190?SearchId=7342533)
Kind regards,
Research Computing Services
University Information Services
University of Cambridge
Please email support@hpc.cam.ac.uk<[support@hpc.cam.ac.uk](mailto:support@hpc.cam.ac.uk)> if any problems are encountered.


[CONVERSATION]
<MESSAGE id=0001 role=OTHER>
Hello Waqar,
Thank you for submitting a ticket, I have passed this over to the AIRR team
Best regards,
Elisabeth Reeve
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=HELPDESK_ASSIGNEE>
Hi Waqar,
I have set-up the local account. You should receive an email to set-up the password (check SPAM as well). Once your account is set, you can accept the invitation link from Aleksander Dubas and use “Sign in with Keycloak“ and provide your local account credentials.
https://docs.hpc.cam.ac.uk/hpc/user-guide/pvc.html#accessing-without-myaccessid-last-resort 
Best regards,
Deepak
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-96168
[STATUS] RESOLVED
[CREATED] 2025-12-03T00:22:30.332+0000
[SUMMARY] HPC Job Scheduling Error

[INITIAL_DESCRIPTION]
To whom it may concern,
I have submitted a job on the HPC, and it took almost 2 weeks to get scheduled. I was wondering if there were any issues with my setup. The job script I used is below.
#!/bin/bash
#SBATCH -J job_gpu_1
#SBATCH -o /home/av670/logfiles/job_gpu_1.log
#SBATCH -A SVOBODA-SL3-GPU
#SBATCH -p ampere
#SBATCH --gres=gpu:4
#SBATCH --time=12:00:00
echo "This job is running on: $(hostname)"
echo "Present working directory: $(pwd)"
echo "Job ID: $SLURM_JOB_ID"
echo "Job start time: $(date)"
module purge
echo "loading python"
module load python/3.11.0-icl
echo "loading cuda"
module load cuda/12.1
echo "activating venv"
source /rds/user/av670/hpc-work/venvs/venv/bin/activate
echo "running file"
python -u /home/av670/projects/part-ii-project/job.py
Kind regards,
Amogh Vishwakarma


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Dear Amogh,
There is nothing wrong with your account or jobs, except that they are at the non-paying service level and there is a lot of paying activity which has higher priority. 
Please bear in mind that each paying job can occupy its resources for 36 hours. Please be patient and don’t be tempted to cancel and resubmit - since all jobs steadily increase in priority the longer they wait, that would be counterproductive. 
Your jobs will run when resources become available.
Best regards,
Elisabeth Reeve
HPC Support
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-95566
[STATUS] RESOLVED
[CREATED] 2025-11-18T10:19:13.230+0000
[SUMMARY] Support for job submisions.

[INITIAL_DESCRIPTION]
Hello,
I am trying to submit jobs to run my analysis using my GPU allocation for my project.
It seems that there is a 36 hour wall time limit and max number of jobs running at the same time.
Currently I am setting of my analysis with:
#SBATCH --array=0-99
#SBATCH --time=35:30:00
So I don’t think I can make max use of my allocation. Are you able to advice what I can do for this?
Also can you advice what settings to use in the slurm script if I do not need a GPU?
Many thanks
Sam


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hi Sam, 
Apologies but I’m not sure I follow. Can you provide more information about your issue? In particular, are you seeing error messages etc.? Thanks.  
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=TICKET_CREATOR>
Hi thanks for the reply.
If I try and submit a job that takes more than 3 days I get this error:
warn(
slurmstepd: error: *** JOB 17745358 ON pvc-s-55 CANCELLED AT 2025-11-16T18:45:50 DUE TO TIME LIMIT ***
I would like to be able to submit longer jobs? I have more gpu hours in my budget then I can use due to the limits?
Sam
</MESSAGE>

<MESSAGE id=0003 role=HELPDESK_ASSIGNEE>
Hi Sam, 
Just to be clear, your dawn gpu account has the following usage stats:
```
User           Usage |        Account     Usage | Account Limit Available (hours)
---------- --------- + -------------- --------- + ------------- ---------
dn-neav1       1,432 | AIRR-P13-DAWN-GPU     1,432 |        50,000    48,568
```
And regarding this issue, my suggestion would be to deploy checkpointing on your jobs so that they can resume once the wallclock time is reached. 
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0004 role=HELPDESK_ASSIGNEE>
Further to this, can you please paste the entire error message for me as well as attach any out/err files the job produded? Thanks 
Best wishes, 
Henry
HPC Support
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-95541
[STATUS] RESOLVED
[CREATED] 2025-11-17T16:35:14.189+0000
[SUMMARY] Q about how to request CPUs on Wilkes 

[INITIAL_DESCRIPTION]
Hi,
Just a quick Q please - if I running a process on Wilkes using 1 node and 1 GPU and 1 task but I want to increase the number of CPUs used from 32 to 76, how would I do that?
I only need 1 GPU, but I would like to use 76 CPUs, can I increase the task number to achieve this?
Thank you for the information.
Cheers,
Mel


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hello Mel 
Unfortunately, you cannot get 76 CPUs with only 1 GPU on Wilkes3, because Slurm enforces 32 CPUs per GPU on the Ampere nodes. This is to avoid starving the GPUs of cpu allocations. You will need to request `32 × number of GPUs` (because this is the maximum cpu count per GPU [https://docs.hpc.cam.ac.uk/hpc/user-guide/a100.html](https://docs.hpc.cam.ac.uk/hpc/user-guide/a100.html))so here that will be `2.38` GPUs which in real terms means you will need to request 3 GPUs to get this many CPUs. 
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=TICKET_CREATOR>
Hi Henry,
O.K ,thank you for the information. I will have a go at 1 node, 3 GPUs and 76 tasks then.
Thanks for your time,
Mel
</MESSAGE>

<MESSAGE id=0003 role=HELPDESK_ASSIGNEE>
No problem, please let me know if you have any further questions, thanks. 
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0004 role=TICKET_CREATOR>
No that covers everything,
Thanks very much,
Mel
</MESSAGE>

<MESSAGE id=0005 role=HELPDESK_ASSIGNEE>
Thank you for the update,
I will go ahead and mark this issue as closed for you. If you wish to re-open it, please reply to this email.
Alternatively if you need further support on a different item then please open a new ticket by emailing (not forwarded or a reply to this) support@hpc.cam.ac.uk. Thank you
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-95504
[STATUS] RESOLVED
[CREATED] 2025-11-17T12:04:09.988+0000
[SUMMARY] Issues with GPU compilation of a package

[INITIAL_DESCRIPTION]
Hello,
I have been trying to compile the following package on GPU for a Molecular Dynamics code called LAMMPS ([https://github.com/wcwitt/symmetrix/blob/main/pair_symmetrix/README.md](https://github.com/wcwitt/symmetrix/blob/main/pair_symmetrix/README.md)). Given that some of the listed requirements aren’t directly available on CSD3, I have downloaded and compiled CUDA 12.4.1 and CMAKE 3.29. Before compilation I run module purge, then load the following modules:
1) gcc/9   2) openmpi/gcc/9.3/4.0.4   3) gcc/11
Gcc 11 is required to compile, therefore I have checked that it overrides the automatically loaded gcc/9 bundled with openmpi. Furthermore, I have checked nvcc –version to check CUDA is correctly included in my path, and the same for CMAKE. I then run the following cmake command:
cmake \
-B build-gpu \
-D CMAKE_BUILD_TYPE=Release \
-D CMAKE_CXX_STANDARD=20 \
-D CMAKE_CUDA_COMPILER=$CUDA_HOME/bin/nvcc \
-D CMAKE_CXX_COMPILER=$CUDA_HOME/bin/nvcc \
-D CUDAToolkit_ROOT=$CUDA_HOME \
-D CUDA_TOOLKIT_ROOT_DIR=$CUDA_HOME \
-D CMAKE_CXX_STANDARD_REQUIRED=ON \
-D CMAKE_CXX_COMPILER=$(pwd)/lib/kokkos/bin/nvcc_wrapper \
-D CMAKE_CXX_FLAGS="${CMAKE_CXX_FLAGS} -ffast-math" \
-D CMAKE_CUDA_COMPILER=~/rds/rds-ukaea-ap002-mOlK9qn0PlQ/ir-dick3/codes/lammps-symmetrix/cuda-12.4.1/bin/nvcc \
-D CUDA_TOOLKIT_ROOT_DIR=~/rds/rds-ukaea-ap002-mOlK9qn0PlQ/ir-dick3/codes/lammps-symmetrix/cuda-12.4.1 \
-D CUDA_INCLUDE_DIRS=~/rds/rds-ukaea-ap002-mOlK9qn0PlQ/ir-dick3/codes/lammps-symmetrix/cuda-12.4.1/include \
-D CUDA_CUDART_LIBRARY=~/rds/rds-ukaea-ap002-mOlK9qn0PlQ/ir-dick3/codes/lammps-symmetrix/cuda-12.4.1/lib64 \
-D CMAKE_CUDA_ARCHITECTURES=80 \
-D BUILD_SHARED_LIBS=ON \
-D BUILD_OMP=ON \
-D BUILD_MPI=ON \
-D PKG_KOKKOS=ON \
-D Kokkos_ENABLE_SERIAL=ON \
-D Kokkos_ENABLE_OPENMP=ON \
-D Kokkos_ENABLE_AGGRESSIVE_VECTORIZATION=ON \
-D Kokkos_ENABLE_CUDA=ON \
-D Kokkos_ARCH_AMPERE80=ON \
-D SYMMETRIX_KOKKOS=ON \
-D SYMMETRIX_SPHERICART_CUDA=ON \
cmake
This runs without any errors (except for a CMAKE FIND_CUDA routine deprecated warning, however this shouldn’t be an issue as cmake shows it has found all the correct CUDA libraries, hence the cmake flags for different paths). After running make on this cmake config the binary compiles without any errors. When I run the binary, I get the following error:
‘’’
[gpu-q-49:22268] mca_base_component_repository_open: unable to open mca_btl_openib: libosmcomp.so.4: cannot open shared object file: No such file or directory (ignored) [gpu-q-49:22268] mca_base_component_repository_open: unable to open mca_btl_usnic: libfabric.so.1: cannot open shared object file: No such file or directory (ignored) [gpu-q-49:22268] mca_base_component_repository_open: unable to open mca_mtl_ofi: libfabric.so.1: cannot open shared object file: No such file or directory (ignored) -------------------------------------------------------------------------- Primary job terminated normally, but 1 process returned a non-zero exit code. Per user-direction, the job has been aborted. -------------------------------------------------------------------------- -------------------------------------------------------------------------- mpirun noticed that process rank 0 with PID 22268 on node gpu-q-49 exited on signal 4 (Illegal instruction).
‘’’
This is from running on a single GPU on the ukaea-amp partition. I load my CUDA 12.4.1 compilation, the same openmpi module used for compilation of lammps and gcc/11. I can’t understand why exactly there is a problem here. Any help on this issue would be hugely appreciated!
Many thanks
Ashley Dickson


[CONVERSATION]
<MESSAGE id=0001 role=OTHER>
Hello Ashley,
I’ll check with our RSE team about this error but in the meantime, can you confirm if you’ve consulted our docs page on this item https://docs.hpc.cam.ac.uk/hpc/software-packages/lammps.html#lammps-molecular-dynamics-simulator ? Thanks 
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=TICKET_CREATOR>
Hi,
Thanks for getting back to me so quickly. I have successfully compiled LAMMPS a couple of times previously (for GPU use) following the instructions detailed at the link provided. The problem is, for the package I am trying to install, a CUDA version of at least 12 is required. The rhel8/default-amp module (specified in the instructions you linked)  automatically loads a conflicting CUDA module and causes a number of issues. Therefore I don’t think I can compile LAMMPS with symmetrix using this method.
Thanks
Ashley
</MESSAGE>

<MESSAGE id=0003 role=OTHER>
Hi Ashley,
In that case you will need to run `module purge` then load only the modules which are needed for compilation. This should stop any conflicts with system CUDA runtimes. 
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0004 role=TICKET_CREATOR>
Hi Henry,
I have done this already, and only loaded the modules that are needed. This is what I did for the compilation that gave me the main error I am worried about. So there must be another problem causing the issues.
Thanks
Ashley
</MESSAGE>

<MESSAGE id=0005 role=HELPDESK_ASSIGNEE>
Hi Ashley,
I will take over from Henry helping you with this issue.
As you have realised, our default Ampere software stack is a bit old now and we are in the process of updating it.
Before I provide further details, I just wanted to caution against using a random Open MPI module on a GPU partition. To ensure best performance, it’s important to ensure that the MPI implementation (usually Open MPI for Nvidia GPUs) has been built correctly to be GPU-aware. This is the case for the `openmpi/4.1.1/gcc-9.4.0-epagguv` module in our detault Ampere software stack. In your case, I believe the `openmpi/gcc/9.3/4.0.4` module you have chosen, was not only built on a Skylake CPU (which has instructions sets that are not supported on the AMD Zen 3 CPUs on the ampere partition) but was also built on a completely different OS version (RHEL7 when the ampere and login nodes run RHEL8) so I would not expect it work. I will take this opportunity to apologise for the confusing state of our modules.
In order to build your software, we will need to use the new test ampere software stack. First purge all modules (and use a fresh shell so that we don’t pollute our environment with any of the software you have previously downloaded) and load the base ones: 
```
module purge
module load rhel8/global rhel8/slurm
```
Next, make the test ampere modules available with the following command
```
module use /usr/local/software/spack/csd3/spack-modules/test/ampere-2025-06-01/linux-rocky8-zen3
```
We can now load the required modules with the following command 
```
module load gcc/14.3.0/vlhhcp6m \
            cuda/12.8.1/gcc/kdeps6ab \
            openmpi/4.1.8/gcc/hemliivg \
            cmake/3.31.10/gcc/7ddsybx7
```
Please delete any old build directories:
```
cd /path/to/lammps
rm -rf build-gpu
```
Configure the build with the following command:
```
cmake \
    -B build-gpu \
    -D CMAKE_BUILD_TYPE=Release \
    -D CMAKE_CXX_STANDARD=20 \
    -D CMAKE_CXX_STANDARD_REQUIRED=ON \
    -D CMAKE_CXX_COMPILER=$(pwd)/lib/kokkos/bin/nvcc_wrapper \
    -D CMAKE_CXX_FLAGS="${CMAKE_CXX_FLAGS} -march=znver3 -ffast-math" \
    -D BUILD_SHARED_LIBS=ON \
    -D BUILD_OMP=ON \
    -D BUILD_MPI=ON \
    -D PKG_KOKKOS=ON \
    -D Kokkos_ENABLE_SERIAL=ON \
    -D Kokkos_ENABLE_OPENMP=ON \
    -D Kokkos_ARCH_ZEN3=ON \
    -D Kokkos_ENABLE_AGGRESSIVE_VECTORIZATION=ON \
    -D Kokkos_ENABLE_CUDA=ON \
    -D Kokkos_ARCH_AMPERE80=ON \
    -D SYMMETRIX_KOKKOS=ON \
    -D SYMMETRIX_SPHERICART_CUDA=ON \
    -D SPHERICART_ARCH_NATIVE=OFF \
    cmake
```
Note that since we are cross-compiling (I configured and built on a login node), it is necessary to disable the use of `-march=native` which sphericart seems to enable by default (hence the last configure argument). This may have been the cause of your illegal instruction error you shared.
I have omitted some of the instructions above as they are unchanged from when you built it previously.
As usual, please load the same modules when running the built executables.
I was able to build the code successfully by using the steps described above but have not been able to test running as I am unsure what arguments/options to use. If you require further assistance after following the above steps, please can you provide me with your full submission scripts and/or the commands you use to run the code.
Please let me know how you get on.
Best wishes,
Miren Radia
Research Software Engineer
</MESSAGE>

<MESSAGE id=0006 role=TICKET_CREATOR>
Hi Miren,
Thank you so much for the detailed reply. I have compiled according to your instructions and everything seems to be working perfectly. As a side note, I very much appreciate you taking the time to explain why my previous compilation was failing – I have very little experience with compiling, especially for GPUs, so this advice is really valuable!
Many thanks,
Ashley
</MESSAGE>

<MESSAGE id=0007 role=HELPDESK_ASSIGNEE>
Hi Ashley,
I'm glad we were able to help with your issue. Good luck with your simulations!
Best wishes,
Miren
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-95411
[STATUS] RESOLVED
[CREATED] 2025-11-13T12:08:12.336+0000
[SUMMARY] Path to my rfs storage

[INITIAL_DESCRIPTION]
Dear HPC support,
I am trying to find the path my my rfs folder on HPC:
Project name: storageactive
Directory: rfs-hem48-storageactive
Project ID: B1vWzswnwnE
I looked in /rfs/project/ , but it doesn’t exist there. Where can I find it?
Thank you!
Best,
Heather
–
Heather Machado
Group Leader
CRUK Career Development Fellow
Department of Pathology
Department of Genetics
University of Cambridge
Cambridge, UK


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hello Heather,
Please follow the relevant guides here for your OS: [Research File Share — Research Storage Documentation documentation](https://docs.hpc.cam.ac.uk/storage/rfs/index.html#access-guides)
Best regards,
Elisabeth Reeve
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=TICKET_CREATOR>
Hi Elisabeth,
Thank you for your response. Am I interpreting this correctly- I log onto HPC and run the “mounting” instructions, is that right?
Best,
Heather
</MESSAGE>

<MESSAGE id=0003 role=TICKET_CREATOR>
Hi Elisabeth,
To be a little more specific, on HPC I plan on working in my rds folder (/rds/project/rds-zyHqhA5YyDI), and storing data in the rfs (since it is backed up). So I’m trying to find the path to the rfs space. I am correct in assuming there is read/write across rds/rfs, right?
Best,
Heather
</MESSAGE>

<MESSAGE id=0004 role=HELPDESK_ASSIGNEE>
Hello Heather,
As the storage is RFS, it can not be accessed through the HPC.
Best regards,
Elisabeth Reeve
HPC Support
</MESSAGE>

<MESSAGE id=0005 role=TICKET_CREATOR>
Oh, ok. Could you help me understand a couple things:
Is there a type of backed up storage that is accessible through HPC?
How do people typically use RFS- are copying files from RFS to RDS when they are needed?
Thanks!
Best,
Heather
</MESSAGE>

<MESSAGE id=0006 role=HELPDESK_ASSIGNEE>
Hello Heather,
If you wish to access RFS on the HPC, you will need to request for it to be converted to NFS-RFS [RFS on CSD3 (RFS-NFS) — Research Storage Documentation documentation](https://docs.hpc.cam.ac.uk/storage/rfs/accessing-rfs/rfs-nfs.html) Please read the documentation to get an understanding of the storage and if this is the right move for you.
Additionally, here is a comparison matrix with case uses of the storage options: [Comparison matrix — Research Storage Documentation documentation](https://docs.hpc.cam.ac.uk/storage/comparison_matrix.html)
Best regards,
Elisabeth
</MESSAGE>

<MESSAGE id=0007 role=TICKET_CREATOR>
Hi Elisabeth,
This NFS-RFS looks to be what I need- for datasets that need to be backed up, but are being actively used on HPC.
Once the datasets are only rarely used I’ll then transfer them to RCS.
Does that make sense?
Best,
Heather
</MESSAGE>

<MESSAGE id=0008 role=HELPDESK_ASSIGNEE>
Hello Heather,
That makes sense, please can you make a new request by emailing [support@hpc.cam.ac.uk](mailto:support@hpc.cam.ac.uk) with the storage details to convert to the NFS-RFS.
Best regards,
Elisabeth
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-95370
[STATUS] RESOLVED
[CREATED] 2025-11-12T14:43:11.430+0000
[SUMMARY] MPI-related runtime error 

[INITIAL_DESCRIPTION]
Dear Sir/Madam,
I am encountering an MPI-related runtime error when attempting to use the gmx_mpi executable from the gromacs/2024.5 module on the pvc9 partition. Here is a job submission script as a minimal example to reproduce the issue:
#!/bin/bash
#SBATCH --job-name=LSN_prep
#SBATCH --partition=pvc9
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --gres=gpu:1
#SBATCH --account=airr-p15-dawn-gpu
#SBATCH --time=2:00:00
. /etc/profile.d/modules.sh
module purge
module use /usr/local/dawn/software/spack-rocky9/spack-modules/dawn-2025-03-23/linux-rocky9-sapphirerapids
module load gromacs/2024.5
module load intel-oneapi-compilers/2025.1.0/gcc/5berjkxu
mpirun -np 1 gmx_mpi -h
And here is the SLURM output I got:
Loading gromacs/2024.5/oneapi/intel-oneapi-mpi/6c6ghrys
Loading requirement: glibc/2.34/gcc/wzlt7jl4 gcc-runtime/14.2.0/gcc/nykri6wk
libiconv/1.17/gcc/qigiow5l libunistring/1.2/gcc/pfn6mgyq
libidn2/2.3.7/gcc/wvlq7snl nghttp2/1.65.0/gcc/wwkph6fx
openssl/3.2.2/gcc/3ujzcve5 zlib-ng/2.2.3/gcc/ktid6u24
curl/8.11.1/gcc/kwum77u6 gmake/4.4.1/gcc/igeiap6r ncurses/6.5/gcc/goa6wr6a
cmake/3.31.6/gcc/afkypz52 intel-oneapi-tbb/2022.1.0/oneapi/dzifcpo4
intel-oneapi-mkl/2025.1.0/oneapi/hc67rita
intel-oneapi-mpi/2021.15.0/oneapi/ufie2hgm
heffte/2.4.1/oneapi/intel-oneapi-mpi/fou7zqpv libpciaccess/0.17/gcc/y3rehifv
xz/5.6.3/gcc/rpltstvq libxml2/2.13.5/gcc/txngsb5d
oneapi-level-zero/1.14/gcc/czctrcfw hwloc/2.11.1/gcc/upz5b3tq
Loading intel-oneapi-compilers/2025.1.0/gcc/5berjkxu
Loading requirement: zstd/1.5.6/gcc/yywdc4uz binutils/2.43.1/gcc/o5vnsbyp
[mpiexec@pvc-s-28] Error: Unable to run bstrap_proxy on pvc-s-28 (pid 65338, exit code 65280)
[mpiexec@pvc-s-28] poll_for_event (../../../../../src/pm/i_hydra/libhydra/demux/hydra_demux_poll.c:157): check exit codes error
[mpiexec@pvc-s-28] HYD_dmx_poll_wait_for_proxy_event (../../../../../src/pm/i_hydra/libhydra/demux/hydra_demux_poll.c:206): poll for event error
[mpiexec@pvc-s-28] HYD_bstrap_setup (../../../../../src/pm/i_hydra/libhydra/bstrap/src/intel/i_hydra_bstrap.c:1063): error waiting for event
[mpiexec@pvc-s-28] Error setting up the bootstrap proxies
[mpiexec@pvc-s-28] Possible reasons:
[mpiexec@pvc-s-28] 1. Host is unavailable. Please check that all hosts are available.
[mpiexec@pvc-s-28] 2. Cannot launch hydra_bstrap_proxy or it crashed on one of the hosts.
[mpiexec@pvc-s-28]    Make sure hydra_bstrap_proxy is available on all hosts and it has right permissions.
[mpiexec@pvc-s-28] 3. Firewall refused connection.
[mpiexec@pvc-s-28]    Check that enough ports are allowed in the firewall and specify them with the I_MPI_PORT_RANGE variable.
[mpiexec@pvc-s-28] 4. slurm bootstrap cannot launch processes on remote host.
[mpiexec@pvc-s-28]    You may try using -bootstrap option to select alternative launcher.
[mpiexec@pvc-s-28] HYD_spawn (../../../../../src/pm/i_hydra/libhydra/spawn/intel/hydra_spawn.c:177): execvp error on file /usr/bin/srun (No such file or directory)
[mpiexec@pvc-s-28] Error: Unable to run bstrap_proxy on pvc-s-28 (pid 65361, exit code 65280)
[mpiexec@pvc-s-28] poll_for_event (../../../../../src/pm/i_hydra/libhydra/demux/hydra_demux_poll.c:157): check exit codes error
[mpiexec@pvc-s-28] HYD_dmx_poll_wait_for_proxy_event (../../../../../src/pm/i_hydra/libhydra/demux/hydra_demux_poll.c:206): poll for event error
[mpiexec@pvc-s-28] HYD_bstrap_setup (../../../../../src/pm/i_hydra/libhydra/bstrap/src/intel/i_hydra_bstrap.c:1063): error waiting for event
Could you please advise me how I can resolve this issue? When using an interactive node launched by the command srun --partition=pvc9 -n 1 -c 8 --gres=gpu:1 --nodes=1 --account=airr-p15-dawn-gpu --pty bash, everything worked fine for me.
Thanks a lot for your help.
Best,
Wei-Tse
-----------------------------------------------------------------------
Wei-Tse Hsu
Email: wei-tse.hsu@bioch.ox.ac.uk
Website: [https://weitsehsu.com](https://weitsehsu.com/)
Postdoctoral Research Associate in Drug Design in the Biggin Group
Department of Biochemistry
University of Oxford


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hello Wei-Tse,
Thank you for submitting a ticket, I will see if we can assist you.
Can you please add `module load rhel9/default-dawn` to your submission script so it loads the suitable environment for the node. If you continue to get the error, please attach the full submission script file and the error and output files.
Best regards,
Elisabeth Reeve 
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=HELPDESK_ASSIGNEE>
Hello Wei-Tse,
Do you require support on this still? If not, I will close this ticket.
Best regards,
Elisabeth
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-95197
[STATUS] RESOLVED
[CREATED] 2025-11-10T10:43:11.547+0000
[SUMMARY] Unable to connect to GPU node (gpu-r-4) and start new VNC session

[INITIAL_DESCRIPTION]
Dear HPC team
I hope you are well.
I’m currently experiencing an issue when trying to start a new VNC session. The password window in the VNC viewer keeps blinking so I can not enter the password, and the connection never stabilises. I also tried to connect to the GPU node (gpu-r-4) directly to check whether a session was running, but the connection closes immediately after entering my password with the message: Connection closed by 10.43.79.4 port 22
It seems I am unable to access gpu-r-4 to create or manage a new session. Could you please advise on how to resolve this and re-establish a working VNC connection? Since I really need to finish some of the work and it just stopped working.
Thank you very much for your help.
Iryna


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hello Iryna,
Please setup a new session on a different r node.
Best regards,
Elisabeth Reeve
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=TICKET_CREATOR>
Hi Elizabeth
Thank you for your reply!
I was trying to run ssh gpu-r-4 and it asks for password, when I enter the password, it says that connection is closed, therefore I could not start the new session. Can you please advise me what to do ? Since I can not do any work without vnc.
Best wishes
Iryna
</MESSAGE>

<MESSAGE id=0003 role=HELPDESK_ASSIGNEE>
Hello Iryna,
Can you please provide a full screenshot of the steps taken in your terminal.
Best regards,
Elisabeth
</MESSAGE>

<MESSAGE id=0004 role=TICKET_CREATOR>
Hi Elisabeth
Thank you for your response.
Here is the screenshot of my terminal.
Best wishes,
Iryna
Sent from Outlook for Mac
[FILE ATTACHMENT]
</MESSAGE>

<MESSAGE id=0005 role=HELPDESK_ASSIGNEE>
Hello Iryna,
As mentioned previously, please setup a new session on a different r node, such as gpu-r-5
Best regards,
Elisabeth
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-95016
[STATUS] RESOLVED
[CREATED] 2025-11-05T11:50:11.991+0000
[SUMMARY]  Dawn A100 allocation not visible on AIRR portal

[INITIAL_DESCRIPTION]
Hello,
I have accepted the PI invitation for the project:
"Agentic AI Workflow Benchmarking and GPU Optimization for Verifiable Automation"
(Hypereum Ltd – UKRI AIRR)
My PI role is active and I can access the AIRR portal, however:
- The Dawn (A100 80GB) allocation is not visible under "UKRI Allocatable Offerings"
- I only see Isambard-AI offerings (IAG, IAI, IARA)
Could you please attach the Dawn allocation to my AIRR project and enable my Dawn user account provisioning?
Thank you!
Giovanni De Lillo
Principal Investigator – Hypereum Ltd


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hi Giovanni,
Perhaps there has been some confusion here. Dawn operates GPUs associated with the intel PVC (AKA data centre max) product family. Please consult this docs page and let me know if you have any further questions. [https://docs.hpc.cam.ac.uk/hpc/user-guide/pvc.html#hardware](https://docs.hpc.cam.ac.uk/hpc/user-guide/pvc.html#hardware)
Best wishes, 
Henry
HPC Support
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-94974
[STATUS] RESOLVED
[CREATED] 2025-11-04T16:23:01.033+0000
[SUMMARY] Quota exceeded with no apparent reason

[INITIAL_DESCRIPTION]
- Your name
Liyou Zhou
- Your account/PI
lz307/Sebastian pattinson
- your job submission script
#!/bin/bash
#!
#! Example SLURM job script for Wilkes3 (AMD EPYC 7763, ConnectX-6, A100)
#! Last updated: Fri 30 Jul 11:07:58 BST 2021
#!
#!#############################################################
#!#### Modify the options in this section as appropriate ######
#!#############################################################
#! sbatch directives begin here ###############################
#! Name of the job:
#SBATCH -J smolvla_mikasa
#! Which project should be charged (NB Wilkes2 projects end in '-GPU'):
#SBATCH -A T2-CS178-GPU
#! How many whole nodes should be allocated?
#SBATCH --nodes=1
#! How many (MPI) tasks will there be in total?
#! Note probably this should not exceed the total number of GPUs in use.
#SBATCH --ntasks=1
#! Specify the number of GPUs per node (between 1 and 4; must be 4 if nodes>1).
#! Note that the job submission script will enforce no more than 32 cpus per GPU.
#SBATCH --gres=gpu:1
#! How much wallclock time will be required?
#SBATCH --time=36:00:00
#! What types of email messages do you wish to receive?
#SBATCH --mail-type=ALL
#! Uncomment this to prevent the job from being requeued (e.g. if
#! interrupted by node failure or system downtime):
#SBATCH --no-requeue
#! Do not change:
#SBATCH -p ampere
#! sbatch directives end here (put any additional directives above this line)
#! Notes:
#! Charging is determined by GPU number*walltime.
#! Number of nodes and tasks per node allocated by SLURM (do not change):
numnodes=$SLURM_JOB_NUM_NODES
numtasks=$SLURM_NTASKS
mpi_tasks_per_node=$(echo "$SLURM_TASKS_PER_NODE" | sed -e 's/^([0-9][0-9]).$/\1/')
#! ############################################################
#! Modify the settings below to specify the application's environment, location
#! and launch method:
#! Optionally modify the environment seen by the application
#! (note that SLURM reproduces the environment at submission irrespective of ~/.bashrc):
. /etc/profile.d/modules.sh # Leave this line (enables the module command)
module purge # Removes all modules still loaded
module load rhel8/default-amp # REQUIRED - loads the basic environment
#! Insert additional module load commands after this line if needed:
#! Full path to application executable:
nvidia-smi
application="./convert.sh"
#! Run options for the application:
options=""
#! Work directory (i.e. where the job will run):
workdir="$SLURM_SUBMIT_DIR" # The value of SLURM_SUBMIT_DIR sets workdir to the directory
1. in which sbatch is run.
#! Are you using OpenMP (NB this is unrelated to OpenMPI)? If so increase this
#! safe value to no more than 128:
export OMP_NUM_THREADS=1
#! Number of MPI tasks to be started by the application per node and in total (do not change):
np=$[${numnodes}*${mpi_tasks_per_node}]
#! Choose this for a pure shared-memory OpenMP parallel program on a single node:
#! (OMP_NUM_THREADS threads will be created):
CMD="$application $options"
#! Choose this for a MPI code using OpenMPI:
#CMD="mpirun -npernode $mpi_tasks_per_node -np $np $application $options"
###############################################################
1. 1. 1. You should not have to change anything below this line ####
###############################################################
cd $workdir
echo -e "Changed directory to `pwd`.\n"
JOBID=$SLURM_JOB_ID
echo -e "JobID: $JOBID\n======"
echo "Time: `date`"
echo "Running on master node: `hostname`"
echo "Current directory: `pwd`"
if [ "$SLURM_JOB_NODELIST" ]; then
#! Create a machine file:
export NODEFILE=`generate_pbs_nodefile`
cat $NODEFILE | uniq > archive_logs/machine.file.$JOBID
echo -e "\nNodes allocated:\n================"
echo `cat archive_logs/machine.file.$JOBID | sed -e 's/\..*$//g'`
fi
echo -e "\nnumtasks=$numtasks, numnodes=$numnodes, mpi_tasks_per_node=$mpi_tasks_per_node (OMP_NUM_THREADS=$OMP_NUM_THREADS)"
echo -e "\nExecuting command:\n==================\n$CMD\n"
eval $CMD
- the working directories or paths you are using (e.g. /rds/user/$USER/hpc-work/foo/bar/), and
/home/lz307/rds/hpc-work/any4lerobot/openx2lerobot
- as much detail as possible on what you are working on, what you have tried, and error messages you receive.
I am working on a dataset building job, literally translating a dataset from 1 format into another format. But I keep running into quota warnings half way through the job.
Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s][A
Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 391.08ba/s]
12047it [1:05:18,  2.29it/s]Processing episode: 12047, elapsed time: 3919.00 seconds, per episode: 0.33 seconds
Error writing image /home/lz307/rds/rds-vlamemory-R8GV8V7LHCg/datasets/mikasa_robo_tfds_all_1.0.0_lerobot/images/observation.images.image/episode_012047/frame_000054.png: [Errno 122] Disk quota exceeded: '/home/lz307/rds/rds-vlamemory-R8GV8V7LHCg/datasets/mikasa_robo_tfds_all_1.0.0_lerobot/images/observation.images.image/episode_012047/frame_000054.png'
Error writing image /home/lz307/rds/rds-vlamemory-R8GV8V7LHCg/datasets/mikasa_robo_tfds_all_1.0.0_lerobot/images/observation.images.image/episode_012047/frame_000056.png: [Errno 122] Disk quota exceeded: '/home/lz307/rds/rds-vlamemory-R8GV8V7LHCg/datasets/mikasa_robo_tfds_all_1.0.0_lerobot/images/observation.images.image/episode_012047/frame_000056.png'
Error writing image /home/lz307/rds/rds-vlamemory-R8GV8V7LHCg/datasets/mikasa_robo_tfds_all_1.0.0_lerobot/images/observation.images.image/episode_012047/frame_000055.png: [Errno 122] Disk quota exceeded: '/home/lz307/rds/rds-vlamemory-R8GV8V7LHCg/datasets/mikasa_robo_tfds_all_1.0.0_lerobot/images/observation.images.image/episode_012047/frame_000055.png'
Error writing image /home/lz307/rds/rds-vlamemory-R8GV8V7LHCg/datasets/mikasa_robo_tfds_all_1.0.0_lerobot/images/observation.images.image/episode_012047/frame_000057.png: [Errno 122] Disk quota exceeded: '/home/lz307/rds/rds-vlamemory-R8GV8V7LHCg/datasets/mikasa_robo_tfds_all_1.0.0_lerobot/images/observation.images.image/episode_012047/frame_000057.png'
Error writing image /home/lz307/rds/rds-vlamemory-R8GV8V7LHCg/datasets/mikasa_robo_tfds_all_1.0.0_lerobot/images/observation.images.image/episode_012047/frame_000058.png: [Errno 122] Disk quota exceeded: '/home/lz307/rds/rds-vlamemory-R8GV8V7LHCg/datasets/mikasa_robo_tfds_all_1.0.0_lerobot/images/observation.images.image/episode_012047/frame_000058.png'
Error writing image /home/lz307/rds/rds-vlamemory-R8GV8V7LHCg/datasets/mikasa_robo_tfds_all_1.0.0_lerobot/images/observation.images.image/episode_012047/frame_000059.png: [Errno 122] Disk quota exceeded: '/home/lz307/rds/rds-vlamemory-R8GV8V7LHCg/datasets/mikasa_robo_tfds_all_1.0.0_lerobot/images/observation.images.image/episode_012047/frame_000059.png'
Error writing image /home/lz307/rds/rds-vlamemory-R8GV8V7LHCg/datasets/mikasa_robo_tfds_all_1.0.0_lerobot/images/observation.images.image/episode_012047/frame_000060.png: [Errno 122] Disk quota exceeded: '/home/lz307/rds/rds-vlamemory-R8GV8V7LHCg/datasets/mikasa_robo_tfds_all_1.0.0_lerobot/images/observation.images.image/episode_012047/frame_000060.png'
Error writing image /home/lz307/rds/rds-vlamemory-R8GV8V7LHCg/datasets/mikasa_robo_tfds_all_1.0.0_lerobot/images/observation.images.image/episode_012047/frame_000061.png: [Errno 122] Disk quota exceeded: '/home/lz307/rds/rds-vlamemory-R8GV8V7LHCg/datasets/mikasa_robo_tfds_all_1.0.0_lerobot/images/observation.images.image/episode_012047/frame_000061.png'
Error writing image /home/lz307/rds/rds-vlamemory-R8GV8V7LHCg/datasets/mikasa_robo_tfds_all_1.0.0_lerobot/images/observation.images.image/episode_012047/frame_000062.png: [Errno 122] Disk quota exceeded: '/home/lz307/rds/rds-vlamemory-R8GV8V7LHCg/datasets/mikasa_robo_tfds_all_1.0.0_lerobot/images/observation.images.image/episode_012047/frame_000062.png'
Error writing image /home/lz307/rds/rds-vlamemory-R8GV8V7LHCg/datasets/mikasa_robo_tfds_all_1.0.0_lerobot/images/observation.images.image/episode_012047/frame_000063.png: [Errno 122] Disk quota exceeded: '/home/lz307/rds/rds-vlamemory-R8GV8V7LHCg/datasets/mikasa_robo_tfds_all_1.0.0_lerobot/images/observation.images.image/episode_012047/frame_000063.png'
Error writing image /home/lz307/rds/rds-vlamemory-R8GV8V7LHCg/datasets/mikasa_robo_tfds_all_1.0.0_lerobot/images/observation.images.image/episode_012047/frame_000064.png: [Errno 122] Disk quota exceeded: '/home/lz307/rds/rds-vlamemory-R8GV8V7LHCg/datasets/mikasa_robo_tfds_all_1.0.0_lerobot/images/observation.images.image/episode_012047/frame_000064.png'
Error writing image /home/lz307/rds/rds-vlamemory-R8GV8V7LHCg/datasets/mikasa_robo_tfds_all_1.0.0_lerobot/images/observation.images.image/episode_012047/frame_000065.png: [Errno 122] Disk quota exceeded: '/home/lz307/rds/rds-vlamemory-R8GV8V7LHCg/datasets/mikasa_robo_tfds_all_1.0.0_lerobot/images/observation.images.image/episode_012047/frame_000065.png'
Error writing image /home/lz307/rds/rds-vlamemory-R8GV8V7LHCg/datasets/mikasa_robo_tfds_all_1.0.0_lerobot/images/observation.images.image/episode_012047/frame_000066.png: [Errno 122] Disk quota exceeded: '/home/lz307/rds/rds-vlamemory-R8GV8V7LHCg/datasets/mikasa_robo_tfds_all_1.0.0_lerobot/images/observation.images.image/episode_012047/frame_000066.png'
Map:   0%|          | 0/67 [00:00<?, ? examples/s][A
Map:  81%|████████  | 54/67 [00:00<00:00, 1086.58 examples/s]
12047it [1:05:18,  3.07it/s]
Traceback (most recent call last):
File "/rds/user/lz307/hpc-work/any4lerobot/openx2lerobot/openx_rlds.py", line 309, in <module>
main()
File "/rds/user/lz307/hpc-work/any4lerobot/openx2lerobot/openx_rlds.py", line 305, in main
create_lerobot_dataset(**vars(args))
File "/rds/user/lz307/hpc-work/any4lerobot/openx2lerobot/openx_rlds.py", line 232, in create_lerobot_dataset
save_as_lerobot_dataset(lerobot_dataset, raw_dataset, keep_images=keep_images)
File "/rds/user/lz307/hpc-work/any4lerobot/openx2lerobot/openx_rlds.py", line 168, in save_as_lerobot_dataset
lerobot_dataset.save_episode()
File "/rds/user/lz307/hpc-work/lerobot/src/lerobot/datasets/lerobot_dataset.py", line 877, in save_episode
self._save_episode_table(episode_buffer, episode_index)
File "/rds/user/lz307/hpc-work/lerobot/src/lerobot/datasets/lerobot_dataset.py", line 927, in _save_episode_table
ep_dataset = embed_images(ep_dataset)
File "/rds/user/lz307/hpc-work/lerobot/src/lerobot/datasets/utils.py", line 140, in embed_images
dataset = dataset.map(embed_table_storage, batched=False)
File "/home/lz307/miniconda3/envs/lerobot/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 562, in wrapper
out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
File "/home/lz307/miniconda3/envs/lerobot/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3079, in map
for rank, done, content in Dataset._map_single(**dataset_kwargs):
File "/home/lz307/miniconda3/envs/lerobot/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3495, in _map_single
for i, example in iter_outputs(shard_iterable):
File "/home/lz307/miniconda3/envs/lerobot/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3469, in iter_outputs
yield i, apply_function(example, i, offset=offset)
File "/home/lz307/miniconda3/envs/lerobot/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3392, in apply_function
processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)
File "/home/lz307/miniconda3/envs/lerobot/lib/python3.10/site-packages/datasets/table.py", line 2270, in embed_table_storage
arrays = [
File "/home/lz307/miniconda3/envs/lerobot/lib/python3.10/site-packages/datasets/table.py", line 2271, in <listcomp>
embed_array_storage(table[name], feature) if require_storage_embed(feature) else table[name]
File "/home/lz307/miniconda3/envs/lerobot/lib/python3.10/site-packages/datasets/table.py", line 1795, in wrapper
return pa.chunked_array([func(chunk, *args, **kwargs) for chunk in array.chunks])
File "/home/lz307/miniconda3/envs/lerobot/lib/python3.10/site-packages/datasets/table.py", line 1795, in <listcomp>
return pa.chunked_array([func(chunk, *args, **kwargs) for chunk in array.chunks])
File "/home/lz307/miniconda3/envs/lerobot/lib/python3.10/site-packages/datasets/table.py", line 2140, in embed_array_storage
return feature.embed_storage(array)
File "/home/lz307/miniconda3/envs/lerobot/lib/python3.10/site-packages/datasets/features/image.py", line 273, in embed_storage
[
File "/home/lz307/miniconda3/envs/lerobot/lib/python3.10/site-packages/datasets/features/image.py", line 274, in <listcomp>
(path_to_bytes(x["path"]) if x["bytes"] is None else x["bytes"]) if x is not None else None
File "/home/lz307/miniconda3/envs/lerobot/lib/python3.10/site-packages/datasets/utils/py_utils.py", line 309, in wrapper
return func(value) if value is not None else None
File "/home/lz307/miniconda3/envs/lerobot/lib/python3.10/site-packages/datasets/features/image.py", line 268, in path_to_bytes
with xopen(path, "rb") as f:
File "/home/lz307/miniconda3/envs/lerobot/lib/python3.10/site-packages/datasets/utils/file_utils.py", line 943, in xopen
return open(main_hop, mode, *args, **kwargs)
FileNotFoundError: [Errno 2] No such file or directory: '/home/lz307/rds/rds-vlamemory-R8GV8V7LHCg/datasets/mikasa_robo_tfds_all_1.0.0_lerobot/images/observation.images.image/episode_012047/frame_000054.png'
I paid for rds-vlamemory-R8GV8V7LHCg 2TB and it is no where near full. I have no idea why would it fail. I tried manually creating this file:
dd if=/dev/zero of=/home/lz307/rds/rds-vlamemory-R8GV8V7LHCg/datasets/mikasa_robo_tfds_all_1.0.0_lerobot/images/observation.png bs=1M count=1
It works no problem


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hi Liyou,
So that we may better diagnose your issue,  can you please attach this script as a file to the email? Secondly, can you please connect to a login node and show me the output of `quota`? Thanks 
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=TICKET_CREATOR>
also had problem with tab completion 

(base) [lz307@login-p-1 ~]$ ls -bash: cannot create temp file for here-document: Disk quota exceeded
-bash: cannot create temp file for here-document: Disk quota exceeded
-bash: cannot create temp file for here-document: Disk quota exceeded
-bash: cannot create temp file for here-document: Disk quota exceeded
</MESSAGE>

<MESSAGE id=0003 role=HELPDESK_ASSIGNEE>
Hi Liyou,
Can you try logging out then back in for me please? Can you also update the ticket as below? 
> So that we may better diagnose your issue,  can you please attach this script as a file to the email? Secondly, can you please connect to a login node and show me the output of `quota`? 
Thanks
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0004 role=TICKET_CREATOR>
[FILE ATTACHMENT]
base ❯ ssh [lz307@login.hpc.cam.ac.uk](mailto:lz307@login.hpc.cam.ac.uk)
```
    <><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>
    <>                                                        <>
    <>                        !WARNING!                       <>
    <>                                                        <>
    <>                    RCS CSD3 Facility                   <>
    <>             Unauthorised Access Prohibited             <>
    <>    Use of this system constitutes acceptance of our    <>
    <>                     policies - see                     <>
    <> <http://docs.hpc.cam.ac.uk/hpc/user-guide/policies.html> <>
    <>        All data is stored in the United Kingdom.       <>
    <>                                                        <>
    <><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>
```
([lz307@login.hpc.cam.ac.uk](mailto:lz307@login.hpc.cam.ac.uk)) Password:
([lz307@login.hpc.cam.ac.uk](mailto:lz307@login.hpc.cam.ac.uk)) TOTP Verification Code: 422871
Last failed login: Tue Nov  4 14:50:49 GMT 2025 from [host-78-149-67-91.as13285.net](http://host-78-149-67-91.as13285.net) on ssh:notty
There was 1 failed login attempt since the last successful login.
Last login: Thu Sep 25 10:57:15 2025 from login-p-4.data.cluster
(base) [lz307@login-q-3 ~]$ quota
Filesystem/Project    GB        quota     limit          grace           files    quota    limit   grace User/Grp/Proj
/home                 13.3       50.0      55.0                     -    ------- No File Quotas  ------- U:lz307
/rds-d6              608.4     1099.5    1209.5                     -   610433  1048576  1048576       - P:47242
/rds-d2                0.0        0.0       0.0                     -        1        0        0       - G:rds
rds-R8GV8V7LHCg      614.5     2000.0    2000.0                     - 1024000*  1024000  1024000       - P:93503
(base) [lz307@login-q-3 ~]$
</MESSAGE>

<MESSAGE id=0005 role=HELPDESK_ASSIGNEE>
```
Filesystem/Project    GB        quota     limit          grace           files    quota    limit   grace User/Grp/Proj
/home                 13.3       50.0      55.0                     -    ------- No File Quotas  ------- U:lz307
/rds-d6              608.4     1099.5    1209.5                     -   610433  1048576  1048576       - P:47242
/rds-d2                0.0        0.0       0.0                     -        1        0        0       - G:rds
rds-R8GV8V7LHCg      614.5     2000.0    2000.0                     - 1024000*  1024000  1024000       - P:93503
```
</MESSAGE>

<MESSAGE id=0006 role=TICKET_CREATOR>
this is from a fresh login session just now.
</MESSAGE>

<MESSAGE id=0007 role=HELPDESK_ASSIGNEE>
Hello Liyou,
Looks like this RDS project has hit its inode quota:
```
     Filesystem    used   quota   limit   grace   files   quota   limit   grace
/rds-d6/project/rds-R8GV8V7LHCg
                 572.3G  1.819T  1.819T       - 1024000* 1024000 1024000       - 
```
You may wish to remove (carefully) or transfer unecessary files to bring this total down. This is indicated by the asterisk next to the quota value.
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0008 role=TICKET_CREATOR>
so even tho I have 2 gb, I am still limited to 1 million files? would it be possible to increase the number of files limit?
</MESSAGE>

<MESSAGE id=0009 role=TICKET_CREATOR>
sorry, I meant i have 2 TB quota, i thought I can have more files.
</MESSAGE>

<MESSAGE id=0010 role=HELPDESK_ASSIGNEE>
Hello Liyou,
I’m afraid that inode quotas are fixed with the only way to increase them being to increase the storage quota of the project itself. This is outlined here: 
https://docs.hpc.cam.ac.uk/storage/rds/details.html#usage-quotas 
Where we have 512000 inodes per TiB 
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0011 role=TICKET_CREATOR>
ok I will delete files. thx.
</MESSAGE>

<MESSAGE id=0012 role=HELPDESK_ASSIGNEE>
No problem
Do you have any further questions for us on this issue?   
Best wishes, 
Henry
HPC Support
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-94925
[STATUS] RESOLVED
[CREATED] 2025-11-04T12:27:59.500+0000
[SUMMARY] Quote

[INITIAL_DESCRIPTION]
Dear All,
I’m not sure if this is the correct address to use, I’m trying to purchase the following but Chemistry Stores are insisting on a quote, can you help please?
Cumulus CPU 200,000 hours * £0.01/CPU hour = £2000 PI is Prof Sir David Klenerman dk10012@cam.ac.uk
and
Research Data Store (RDS) 10TB for 3 years = £162/TB* 10 TB = £1620 PI is Prof Sir David Klenerman dk10012@cam.ac.uk
Regards
Dave
Mr David Pratt (he/him/his)
Senior Support Technician
Telephone Liaison Officier
Yusuf Hamied Department Of Chemistry,
University of Cambridge,
Lensfield Rd. Cambridge, CB2 1EW
Direct Line 01223 747611
Murphy's Law
If everything seems to be going well, you have obviously overlooked something.


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Dear Dave, 
I’m afraid we don’t issue quotes for compute hour purchases but those costs are correct and in line with  [https://www.hpc.cam.ac.uk/charges](https://www.hpc.cam.ac.uk/charges) which also indicates the procedure: 
> How to buy CSD3 resources
> For Service Level 2, please ask your department to raise a purchase order (PO) to Information Services for the desired number and type of resource units. Please be sure to mention on the PO the name of the project, or the PI, owning the new resources, and email the PDF of the PO to [purchases@hpc.cam.ac.uk](mailto:purchases@hpc.cam.ac.uk).
Similarly, storage services are distinct from the HPC service, there is a different procedure for storage purchases - please visit
[https://selfservice.uis.cam.ac.uk/](https://selfservice.uis.cam.ac.uk/)
If you are purchasing new storage, please pick the appropriate option on the front page.
If you are extending existing storage duration or size, please navigate to the existing storage license page, press the appropriate button in the top right on the storage's license page.
Both options will generate a quote for you. 
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=HELPDESK_ASSIGNEE>
Hello,
I have not had any updates on this ticket so I will go ahead and close it for you. If you wish to re-open it, please reply to this email.
Alternatively if you need further support on a different item then please open a new ticket by emailing (not forwarded or a reply to this) support@hpc.cam.ac.uk. Thank you
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-94250
[STATUS] RESOLVED
[CREATED] 2025-10-22T17:20:57.903+0100
[SUMMARY] Could We Add Newer CUDA modules?

[INITIAL_DESCRIPTION]
Dear HPC Team,
Could we add a few more recent CUDA modules to the cluster? At the moment I can load cuda/12.1, but many current DL packages (e.g., recent PyTorch/TensorFlow wheels) target CUDA 12.4 or 12.6. Having cuda/12.4 and cuda/12.6available would greatly improve compatibility and avoid building from source.
If feasible, installing these alongside the existing cuda/12.1 (plus matching cuDNN where applicable) would be ideal. I’m happy to test the new modules once they’re deployed.
Many thanks!
Best regards,
Yijiang Dong


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Dear Yijiang
We have a new software stack which should grant access to cuda 12.8 however at the moment we do not officially support versions 12.4 or 12.6. To load the stack, please run
```
module purge
module load rhel8/slurm
module load rhel8/global
module use /usr/local/software/spack/csd3/spack-modules/test/ampere-2025-06-01/linux-rocky8-zen3 
```
Then 
```
module load cuda/12.8.1/gcc/kdeps6ab
```
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=HELPDESK_ASSIGNEE>
Hello,
I have not had any updates on this ticket so I will go ahead and close it for you. If you wish to re-open it, please reply to this email.
Alternatively if you need further support on a different item then please open a new ticket by emailing (not forwarded or a reply to this) support@hpc.cam.ac.uk. Thank you
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-93979
[STATUS] RESOLVED
[CREATED] 2025-10-16T15:43:58.918+0100
[SUMMARY] Turbo VNC running issues 

[INITIAL_DESCRIPTION]
Dear HPC Support team
I hope this email finds you well!
I was trying to open Turbo VNC but it does not work unfortunately.
I took following steps to run it:
I run this. - /opt/TurboVNC/bin/vncserver
then i have gotten this started on display login-q-3:9
then I press exit
then type - ssh -L 5909:localhost:5909 iv285@login-q-3.hpc.cam.ac.uk
then password
However, I am getting this error:
bind [::1]:5909: Cannot assign requested address
channel_setup_fwd_listener_tcpip: cannot listen to port: 5909
Could not request local forwarding.
Last login: Thu Oct 16 15:26:53 2025 from login-q-3.hpc.cam.ac.uk
[iv285@login-q-3 ~]$
Cold you advise me what can I do in this case ?
Best wishes
Iryna


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hello Iryna,
You should be creating the vnc session on an interactive node (*-r-gpu), please follow the guide attached.
[FILE ATTACHMENT]
Please let me know if you run into any problems.
Best regards,
Elisabeth Reeve
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=TICKET_CREATOR>
Dear Elisabeth,
Thank you for your reply.
It was very helpful!
Everything works now!
Best wishes
Iryna
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-93947
[STATUS] RESOLVED
[CREATED] 2025-10-15T19:42:03.599+0100
[SUMMARY] Lost private side of the SSH key

[INITIAL_DESCRIPTION]
Dear IT team
I am Alejo Nevado-Holgado, user "n_neva1" of Dawn. A couple of months ago I was trying to SSH into dawn from my laptop, but in order to do that I first had to create an SSH key with the following command:
ssh-keygen -t ed25519 -a 100 -C "dn_neva1@dawn (AIRR-p19)"
Then I sent the public key to this email address in a file called "id_ed25519.pub". A couple of days ago I reinstalled Ubuntu, and now I am not able to SSH into Dawn again. I didn't save the private side of the key that I generated before. I was wondering, how could I connect to Dawn again from my laptop? Claude says that I have to generate a new key and send to you the new "id_ed25519.pub" file. I attach it in case this would actually work.
Very best and many thanks for your help
Alejo
Alejo Nevado-Holgado
Associate Professor
Department of Psychiatry & Big Data Institute | University of Oxford | Oxford | OX3 7JX
alejo.nevado-holgado@psych.ox.ac.uk<[alejo.nevado-holgado@psych.ox.ac.uk](mailto:alejo.nevado-holgado@psych.ox.ac.uk)>
[cid:108711ff-f78d-4b60-b2a2-bb8b3941fc7a]  [cid:af762036-bceb-4b4b-a09e-6924cd209afa]


[CONVERSATION]
<MESSAGE id=0001 role=TICKET_CREATOR>
[FILE ATTACHMENT]
[FILE ATTACHMENT]
[FILE ATTACHMENT]
 (0.1 kB)
</MESSAGE>

<MESSAGE id=0002 role=HELPDESK_ASSIGNEE>
Hello Alejo,
The new public key has been appended to your user account.
Best regards,
Elisabeth Reeve
HPC Support
</MESSAGE>

<MESSAGE id=0003 role=TICKET_CREATOR>
Hello Elisabeth
Many thanks for doing that. However, I just noticed something unusual. I was going to connect just now from my office, and Dawn asked me for the password:
[cid:675d658a-5880-4b6e-97d4-a2989cc5ed55]
Until yesterday it would only ask for the code that I get from the authentification app of my phone. I get the same problem when trying to connect with VS code. I don't have a password, so I can only log in with these codes that I get from the app. Could it be that the IP address or key of my office PC has been removed from my user account or something?
I attach here the key file of my office PC. I need to be able to connect to Dawn both from my office PC and from my laptop at home.
Very best and many thanks in advance
Alejo
Alejo Nevado-Holgado
Associate Professor
Department of Psychiatry & Big Data Institute | University of Oxford | Oxford | OX3 7JX
alejo.nevado-holgado@psych.ox.ac.uk<[alejo.nevado-holgado@psych.ox.ac.uk](mailto:alejo.nevado-holgado@psych.ox.ac.uk)>
[cid:4b03dd91-2328-4d85-bad6-b5e878d7efcd]  [cid:a5cf2486-5328-49eb-86bb-67e6b88be67b]
[FILE ATTACHMENT]
[FILE ATTACHMENT]
[FILE ATTACHMENT]
</MESSAGE>

<MESSAGE id=0004 role=HELPDESK_ASSIGNEE>
Hello Alejo,
You will need an ssh key pair for each device you are connecting from. You will need to supply an ssh key from the additional device.
Best regards,
Elisabeth Reeve
HPC Support
</MESSAGE>

<MESSAGE id=0005 role=TICKET_CREATOR>
Dear IT team
I was wondering if you could have a look at my query from last week? I am not able to access Dawn anymore from my office PC.
Very best
Alejo
Alejo Nevado-Holgado
Associate Professor
Department of Psychiatry & Big Data Institute | University of Oxford | Oxford | OX3 7JX
alejo.nevado-holgado@psych.ox.ac.uk<[alejo.nevado-holgado@psych.ox.ac.uk](mailto:alejo.nevado-holgado@psych.ox.ac.uk)>
[cid:7045f69f-4be0-44df-821f-e56dc7c0e4b8]  [cid:42a78539-d547-44d7-a0fb-12bfbfb8a17d]
[FILE ATTACHMENT]
[FILE ATTACHMENT]
[FILE ATTACHMENT]
[FILE ATTACHMENT]
</MESSAGE>

<MESSAGE id=0006 role=TICKET_CREATOR>
Dear Elisabeth
Many thanks for replying to this query. I attach here the key file of my office PC. Could this be added as well to the server? I make a note that the name of the file (i.e. id_ed25519) may be the same as the file that I sent for my home laptop.
Very best
Alejo
Alejo Nevado-Holgado
Associate Professor
Department of Psychiatry & Big Data Institute | University of Oxford | Oxford | OX3 7JX
alejo.nevado-holgado@psych.ox.ac.uk<[alejo.nevado-holgado@psych.ox.ac.uk](mailto:alejo.nevado-holgado@psych.ox.ac.uk)>
[cid:d335a5df-fdcf-4307-addc-b565d90285ab]  [cid:dbce2bb5-4854-41b8-ba23-4530b84d8ae9]
[FILE ATTACHMENT]
[FILE ATTACHMENT]
</MESSAGE>

<MESSAGE id=0007 role=HELPDESK_ASSIGNEE>
Hello Alejo,
I do not see a new public key attached to the reply.
Best regards,
Elisabeth
</MESSAGE>

<MESSAGE id=0008 role=TICKET_CREATOR>
Dear Elisabeth
It was attached to the original email from last week. I attach it here again. Please do let me know if it does not show up or something. Outlook was giving me an error a moment ago when trying to attach the zip file, although now outlook says that it is attached.
Very best
Alejo
Alejo Nevado-Holgado
Associate Professor
Department of Psychiatry & Big Data Institute | University of Oxford | Oxford | OX3 7JX
alejo.nevado-holgado@psych.ox.ac.uk<[alejo.nevado-holgado@psych.ox.ac.uk](mailto:alejo.nevado-holgado@psych.ox.ac.uk)>
[cid:e16b41d0-2c8b-455e-a715-915e0542507c]  [cid:f7c2aad1-0277-47b9-b463-5a2a4be4a579]
[FILE ATTACHMENT]
[FILE ATTACHMENT]
</MESSAGE>

<MESSAGE id=0009 role=HELPDESK_ASSIGNEE>
Hello Alejo,
The public key you provided last week has already been appended to your user account. This was the public key for laptop.
I can not see the public key for your office computer attached, please can you paste the public key into the email body as plain text?
Best regards,
Elisabeth
</MESSAGE>

<MESSAGE id=0010 role=TICKET_CREATOR>
Hello Elisabeth
No problem. I copy here the key:
ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIHxAXxDryHDj08mD5eWdNa7S6qrESY7MHc5E0oBs3LnI dn_neva1@dawn (AIRR-p19)
Those are all the contents of the file that I was trying to attach.
Very best and many thanks in advance
Alejo
Alejo Nevado-Holgado
Associate Professor
Department of Psychiatry & Big Data Institute | University of Oxford | Oxford | OX3 7JX
alejo.nevado-holgado@psych.ox.ac.uk<[alejo.nevado-holgado@psych.ox.ac.uk](mailto:alejo.nevado-holgado@psych.ox.ac.uk)>
[cid:84939ae6-554c-4332-a758-bce1fa70782e]  [cid:e24b636f-ab36-45ce-b3ee-651c5c3aa6d4]
[FILE ATTACHMENT]
[FILE ATTACHMENT]
</MESSAGE>

<MESSAGE id=0011 role=HELPDESK_ASSIGNEE>
Hello Alejo,
This public key has been appended to your user account.
Best regards,
Elisabeth
</MESSAGE>

<MESSAGE id=0012 role=TICKET_CREATOR>
Dear Elisabeth
Many thanks. My office PC is connecting all right now.
Very best
Alejo
Alejo Nevado-Holgado
Associate Professor
Department of Psychiatry & Big Data Institute | University of Oxford | Oxford | OX3 7JX
alejo.nevado-holgado@psych.ox.ac.uk<[alejo.nevado-holgado@psych.ox.ac.uk](mailto:alejo.nevado-holgado@psych.ox.ac.uk)>
[cid:31979d47-ca18-4450-a1e4-0895994e74fe]  [cid:a262bf8d-4ebd-4bc1-bd29-f1f887269b20]
[FILE ATTACHMENT]
[FILE ATTACHMENT]
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-93204
[STATUS] RESOLVED
[CREATED] 2025-10-01T10:38:21.154+0100
[SUMMARY] sync of rcs data

[INITIAL_DESCRIPTION]
Dear support team,
I need to rsync a large dataset from our rcs project (cc234). Doing it from a login node is probably not the way, as I'm being kicked out, I guess because the rsync is too heavy. Is there a dedicated data transfer node I can ssh to, or should I do it via an interactive job?
Thanks,
Yaniv
Sent from Outlook for Android<[https://aka.ms/AAb9ysg](https://aka.ms/AAb9ysg)>


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hello Yaniv,
You can use a screen to complete the rsync command or a GUI application to transfer data [Access RCS Using a GUI Client — Research Storage Documentation documentation](https://docs.hpc.cam.ac.uk/storage/rcs/gui.html)
Please ensure you are following the best practise for data in RCS [Best Practice — Research Storage Documentation documentation](https://docs.hpc.cam.ac.uk/storage/rcs/best-practice.html)
Best regards,
Elisabeth Reeve
HPC Support
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-93140
[STATUS] RESOLVED
[CREATED] 2025-09-30T12:15:20.632+0100
[SUMMARY] Gaia Arcus cloud ceph connection issues

[INITIAL_DESCRIPTION]
Hi,
We are having some issues with various ceph shares on the Arcus cloud 
today and yesterday. Seeing metadata servers switch to reconnecting e.g.:
> a900cf30-f8a3-42bf-98d6-af7ce92f1a1a.client1188705722/mds_sessions
> ::::::::::::::
> global_id 1188705722
> name "iris-gaia-code-spec-ro"
> mds.1 reconnecting
> a900cf30-f8a3-42bf-98d6-af7ce92f1a1a.client1188705717/mds_sessions
> ::::::::::::::
> global_id 1188705717
> name "process-space-1"
> mds.1 reconnecting
This is causing filesystem access to hang.
Rebooting the instances seems to be clearing this in some cases but it 
is happening on multiple instances and also recurring. Is there any 
indication of an underlying issue?
Cheers,
Patrick.


[CONVERSATION]
<MESSAGE id=0001 role=TICKET_CREATOR>
Additional information: it seems to be mds.1 always causing the issue. I tried rebooting the instance vampire and all shares using mds.0 are open. Those reporting mds.1 are not available (report closing and the share does not mount):
::::::::::::::
a900cf30-f8a3-42bf-98d6-af7ce92f1a1a.client1260850383/mds_sessions
::::::::::::::
global_id 1260850383
name "DILOG-151-priepochs"
mds.1 closing
::::::::::::::
a900cf30-f8a3-42bf-98d6-af7ce92f1a1a.client1260850393/mds_sessions
::::::::::::::
global_id 1260850393
name "iris-gaia-code-spec-ro"
mds.1 closing
::::::::::::::
a900cf30-f8a3-42bf-98d6-af7ce92f1a1a.client1260850398/mds_sessions
::::::::::::::
global_id 1260850398
name "process-space-1"
mds.0 open
::::::::::::::
a900cf30-f8a3-42bf-98d6-af7ce92f1a1a.client1261039481/mds_sessions
::::::::::::::
global_id 1261039481
name "dilog-177-photometry"
mds.1 closing
</MESSAGE>

<MESSAGE id=0002 role=HELPDESK_ASSIGNEE>
Other than some small rebalancing happening around a failed OSD disk I'm not aware of any other issues recently occuring, but I'll go looking deeper into the CephFS state now.
</MESSAGE>

<MESSAGE id=0003 role=TICKET_CREATOR>
Thanks Paul. We’re still having the issues: I’ve just tried to mount one share and got a timeout:
```
[pwb@vampire ~]$ sudo mount /iris-process-space
mount error 110 = Connection timed out
```
Some shares seem to be working and others not working.
</MESSAGE>

<MESSAGE id=0004 role=HELPDESK_ASSIGNEE>
@Patrick Burgessmaybe try again now
</MESSAGE>

<MESSAGE id=0005 role=TICKET_CREATOR>
That seems to be working now. Is it worth rebooting those machines to check they remount everything properly on startup?
</MESSAGE>

<MESSAGE id=0006 role=HELPDESK_ASSIGNEE>
Sure, if it's not going to be disruptive to your environments to do that.
</MESSAGE>

<MESSAGE id=0007 role=TICKET_CREATOR>
The reboots do seem to be mounting everything successfully now. Out of interest, what did you change?
I will reboot the remaining servers this evening and tomorrow as fits in with our processes. I’ll let you know if there are any further issues.
Thanks!
Cheers,
Patrick.
</MESSAGE>

<MESSAGE id=0008 role=HELPDESK_ASSIGNEE>
One of the two active MDSes had come back from the shutdown missing some additional routing, but this has been fixed and should now be persistent across reboots now. NetworkManager does have a habit of removing additional interface or route configuration and not persisting it.
</MESSAGE>

<MESSAGE id=0009 role=TICKET_CREATOR>
Thanks Paul! Since your fix things seem to be working fine again. I’ve rebooted all the affected instances (some don’t use any ceph storage).
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-93090
[STATUS] RESOLVED
[CREATED] 2025-09-29T14:16:21.341+0100
[SUMMARY] Quote for extra GPU core times and RDS disk spaces

[INITIAL_DESCRIPTION]
Dear support team,
Our team wanted to top up some more GPU core times and extra rds disk spaces for project 'QAKG-SL2-GPU'? Could you please give us a quote for the price of 10000 extra GPU hours and 20 GB extra rds space?
Best wishes,
Wenyu
The University of Edinburgh is a charitable body, registered in Scotland, with registration number SC005336. Is e buidheann carthannais a th' ann an Oilthigh Dh?n ?ideann, cl?raichte an Alba, ?ireamh cl?raidh SC005336.


[CONVERSATION]
<MESSAGE id=0001 role=OTHER>
Hello Wenyu,
Thank you for submitting a ticket, I will see if we can assist you.
If you have any further information, please let me know, otherwise I will get back to you soon,
Best regards,
Elisabeth Reeve 
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=OTHER>
HI @Stuart Rankin I believe this is a CORE customer?
</MESSAGE>

<MESSAGE id=0003 role=HELPDESK_ASSIGNEE>
Dear Wenyu,
Do you mean 20TB rather than 20GB?
Looking into this I see you purchased 2TB for one year on 2022-11-24, so I’m afraid you owe us for the last 22 months on this 2TB. The base cost is 54 GBP per TB per year, so if you wanted for example to extend this to 22TB for the next year, then this cost would be 
((667/365)*2 + 20)*54 = £ 1277.35 plus VAT
Separately, the cost of GPU hours is £0.55 plus VAT, so the cost of 10000 extra GPU hours would be
10000*0.55 = £ 5500 plus VAT.
I hope this helps -
Best regards,
Stuart
</MESSAGE>

<MESSAGE id=0004 role=TICKET_CREATOR>
Hi Stuart,
Yes, it’s a typo.
After discussion with the team leader, we decided to purchase 10TB extra disk space, plus 10000 GPU hours. Could you help provide a new quote for us.
In addition, we also want to create some new accounts for our team, one for j.z.pan@ed.ac.uk<[j.z.pan@ed.ac.uk](mailto:j.z.pan@ed.ac.uk)> and two guest accounts.
Best wishes,
Wenyu
On 1 Oct 2025, at 00:05, Stuart Rankin <support@hpc.cam.ac.uk<[support@hpc.cam.ac.uk](mailto:support@hpc.cam.ac.uk)>> wrote:
</MESSAGE>

<MESSAGE id=0005 role=HELPDESK_ASSIGNEE>
Dear Wenyu,
The total cost of renewing your current 2TB and extending it by 10TB for one year would be
((667/365)*2 + 12)*54 = £845.36 + VAT
The cost of 10000 additional GPU hours would be 
10000*0.55 = £ 5500 plus VAT.
Please accept this as an email quote and send your PO to this ticket when ready.
Regarding new users, please note that we do not accept anonymous guest accounts, each individual requiring access to our services must separately complete the online form for external applications at https://www.hpc.cam.ac.uk/external-application  selecting type “CORE”; I suggest they use your PI’s name as “Primary contact” and quote project QAKG.
Best regards,
Stuart
</MESSAGE>

<MESSAGE id=0006 role=TICKET_CREATOR>
Thanks Stuart,
The school requires us to provide a formal quotation document to create the PO, it would be great if you can help provide one for us. Many thanks.
Best wishes,
Wenyu
On 7 Oct 2025, at 03:08, Stuart Rankin <support@hpc.cam.ac.uk<[support@hpc.cam.ac.uk](mailto:support@hpc.cam.ac.uk)>> wrote:
</MESSAGE>

<MESSAGE id=0007 role=HELPDESK_ASSIGNEE>
I get this sometimes from departments in Cambridge, and it always turns out to be rubbish. That is a valid email quote and constitutes a written document. They can also refer to the original contract document for the agreed prices.
</MESSAGE>

<MESSAGE id=0008 role=TICKET_CREATOR>
Hi Stuart,
I hope you're well.
We’d like to clarify the Primary Contact listed for the QAKG project in your system. We had assumed it was Mirella (mlap@inf.ed.ac.uk), but since she’s currently managing multiple projects, she’s unsure about this assignment.
Could you please confirm whether Mirella is indeed the Primary Contact for QAKG? If so, would it be possible to update the contact to Jeff Pan (j.z.pan@ed.ac.uk) instead, for convenience and smoother coordination?
Best wishes,
Wenyu
</MESSAGE>

<MESSAGE id=0009 role=HELPDESK_ASSIGNEE>
Dear Wenyu,
I can confirm that Mirella is the primary contact for QAKG. No problem changing this to Jeff Pan, but of course we would need Mirella’s confirmation as current primary contact before making such a change - I have added Mirella to this ticket.
Best regards
Stuart
</MESSAGE>

<MESSAGE id=0010 role=TICKET_CREATOR>
Hi Stuart,
Thanks!
Yes, please add both Jeff (j.z.pan@ed.ac.uk) and Mirella (mlap@inf.ed.ac.uk) to the ticket so they can stay updated on the latest progress.
Best wishes,
Wenyu
</MESSAGE>

<MESSAGE id=0011 role=HELPDESK_PRINCIPAL_INVESTIGATOR>
Hi Stuart,
I am happy with this change.
thank you,
Mirella
</MESSAGE>

<MESSAGE id=0012 role=TICKET_CREATOR>
Hi Stuart,
Our finance team has informed me that PO UOE1629005 has been completed.
I am writing because I have not yet received the confirmation, nor is the credit visible on our account.
Could you please look into this and provide an update on the status?
Best wishes,
Wenyu
On 23 Oct 2025, at 15:39, Stuart Rankin <support@hpc.cam.ac.uk<[support@hpc.cam.ac.uk](mailto:support@hpc.cam.ac.uk)>> wrote:
</MESSAGE>

<MESSAGE id=0013 role=HELPDESK_ASSIGNEE>
I’ve received no such PO. Please can you ask your finance team where they sent it, and if there is a ticket reference from us.
</MESSAGE>

<MESSAGE id=0014 role=HELPDESK_ASSIGNEE>
Just to confirm that we have received UOE1629005 this morning and I am actioning it.
</MESSAGE>

<MESSAGE id=0015 role=HELPDESK_ASSIGNEE>
```
CORE project - QAKG-SL2-GPU cf HPCSSUP-93090 (quote)
Edinburgh PO UOE1629005 cf HPCSSUP-95564
GPU hours: 10000*0.55 = £ 5500 plus VAT.
Storage - in arrears for 2TB 2022-11-24 - 2023-11-23 license.

Retrospective extension 24-11-2023 - 23-11-2025 (730 days):
2*2*54 = £216 + VAT

845.36-216 = 629.36 ex VAT remains

Storage account uIn3z4K7QHQ
Storage project 2iBGk7DbOVc
Licenses:      qtbRRz4ho0s - Start: 2022-11-24 - End: 2023-11-24
               GzVxdJmbYvU - Start: 2023-11-24 - End: 2026-11-23 <-- Latest License
Correct license end date to 2025-11-23 in https://selfservice.uis.cam.ac.uk/admin/

1 year new license for 12TB
12*54 = £648 + VAT
=> 629.36 gets (629.36/648)*365= 355 days, i.e. new license starts 24-11-2025 and ends 13-11-2026.

               vRGhfozgTZo - Start: 2025-11-18 - End: 2025-11-23 <-- Latest License
Correct start and end time 24-11-2025 - 13-11-2026

!! Project now can't be increased to 12TB through the portal until 24/11. (Now done)

Give it to them now anyway:

# fs-admin1
modquotaTB(){    # puuid qTB
  project=$1
  block_quota_in_tb=$2
  inodes_per_tb=512000
  inode_quota="$((block_quota_in_tb*inodes_per_tb))"
  block_quota="$((block_quota_in_tb*1000*1000*1000*1000/1024))"
  filesystem=`df /rds/project/rds-${project} | sed -ne 's?^.*:\(/rds-d[1-9][0-9]*\) .*$?\1?p'`
  project_path="/${filesystem}/project/rds-${project}"
  gid="$(stat -c '%g' "${project_path}")"
  prjid=`lfs project -d "${project_path}" | cut -f1 -d ' '`
  [ $gid != $prjid ] && { echo "GID $gid does not match project id $prjid" ; return 1 ; }
  lfs setquota --projid "${gid}" --block-softlimit ${block_quota} --block-hardlimit ${block_quota} --inode-softlimit ${inode_quota} --inode-hardlimit ${inode_quota} "${project_path}"
  lfs quota -hp "${gid}" "${project_path}"
}

modquotaTB 2iBGk7DbOVc 12



gdeposit -z 10000 -p QAKG-SL2-GPU

gbalance -p QAKG-SL2-GPU
User           Usage |        Account     Usage | Account Limit Available (hours)
---------- --------- + -------------- --------- + ------------- ---------

co-dand1           0 |   QAKG-SL2-GPU    42,620 |        63,031    20,411
co-huan1      27,103 |   QAKG-SL2-GPU    42,620 |        63,031    20,411
co-zhen1      15,517 |   QAKG-SL2-GPU    42,620 |        63,031    20,411


```
</MESSAGE>

<MESSAGE id=0016 role=HELPDESK_ASSIGNEE>
The updates have now been applied.
Best regards
Stuart
</MESSAGE>

<MESSAGE id=0017 role=TICKET_CREATOR>
Thanks, Stuart. I can now see these updates.
Best wishes,
Wenyu
On 18 Nov 2025, at 13:11, Stuart Rankin <support@hpc.cam.ac.uk<[support@hpc.cam.ac.uk](mailto:support@hpc.cam.ac.uk)>> wrote:
</MESSAGE>

<MESSAGE id=0018 role=HELPDESK_ASSIGNEE>
The PO has been passed on for invoicing.
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-92768
[STATUS] RESOLVED
[CREATED] 2025-09-22T09:36:21.485+0100
[SUMMARY] check point example

[INITIAL_DESCRIPTION]
To whom it may concern,
We have a job on HPC that takes more than 36 hours to run, and we would like to try the check point method. Could you provide some examples of how to use the check point?
Thanks,
Qi


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hi Qi,
I’m afraid we don’t have specific examples at hand for this but the concept of checkpointing code essentially means that you will need to configure it so that at certain intervals, the results are saved. You might find this page useful: https://rc-docs.northeastern.edu/en/latest/best-practices/checkpointing.html#the-checkpointing-technique  but please be aware that the commands and scripts it shows will not necessarily work on CSD3. 
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=TICKET_CREATOR>
Thank you for the link! It seems we shall try user-level checkpointing in general code, before trying system-level solutions.
Best,
Qi
</MESSAGE>

<MESSAGE id=0003 role=HELPDESK_ASSIGNEE>
Great, 
Do you have any further questions for us on this issue?   
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0004 role=TICKET_CREATOR>
No. We are researching different options. Thank you!
</MESSAGE>

<MESSAGE id=0005 role=HELPDESK_ASSIGNEE>
Thank you for the update,
I will go ahead and mark this issue as closed for you. If you wish to re-open it, please reply to this email.
Alternatively if you need further support on a different item then please open a new ticket by emailing (not forwarded or a reply to this) support@hpc.cam.ac.uk. Thank you
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-92750
[STATUS] RESOLVED
[CREATED] 2025-09-19T15:29:19.439+0100
[SUMMARY] Accessing HPC after maintenance works

[INITIAL_DESCRIPTION]
Hello,
I am having problems logging in to hpc via ssh irs38@login-gpu.hpc.cam.ac.uk as usual, even though an email has been sent out confirming the end of the maintenance work. I just wanted to check if there isn't something I am missing, or if it is just taking time until hpc will be fully available.
Kind regards,
Ieva


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hello Ieva,
We are still bring services online, please keep an eye on email communications and this page for updates [Service Status | Research Computing Services](https://www.hpc.cam.ac.uk/service-status)
Best regards,
Elisabeth Reeve
HPC Support
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-92485
[STATUS] RESOLVED
[CREATED] 2025-09-10T17:21:20.405+0100
[SUMMARY] Request for ~/rfs Symlink in Home Directory

[INITIAL_DESCRIPTION]
Hi HPC Support Team,
I noticed that my home directory does not have a symlink ~/rfs pointing to the RFS project folder. Currently, I can access the project data using the absolute path /rfs/project/rfs-iCNyzSAaucw, but having the symlink would make it much more convenient.
Could you please create the ~/rfs symlink in my home directory?
Thank you so much for your help!
Best regards,
Hansheng


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
ln -s /rfs/project/rfs-iCNyzSAaucw /home/<crsID>/rfs
</MESSAGE>

<MESSAGE id=0002 role=HELPDESK_ASSIGNEE>
Hello Hansheng, 
Can you please try logging into a login node and running
```
cd $HOME
ln -s /rfs/project/rfs-iCNyzSAaucw /home/hx305/rfs 
```
This should hopefully symlink the RFS project. Thanks
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0003 role=TICKET_CREATOR>
Hi Henry,
Thank you so much for your kind help!
I ran the command but got the below results. It seems not work well.
(base) [hx305@login-q-1 ~]$ ln -s /rfs/project/rfs-iCNyzSAaucw /home/hx305/rfs
ln: failed to create symbolic link '/home/hx305/rfs': No space left on device
Many thanks!
Best regards,
Hansheng
</MESSAGE>

<MESSAGE id=0004 role=HELPDESK_ASSIGNEE>
Hi Hansheng,
Can you show me the output of the `quota` command please? Thanks  
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0005 role=TICKET_CREATOR>
Hi Henry,
Here, please.
(base) [hx305@login-q-1 ~]$ quota -s
Filesystem/Project    GB        quota     limit          grace           files    quota    limit   grace User/Grp/Proj
/home                 54.2       50.0      55.0                     -    ------- No File Quotas  ------- U:hx305
/rds-d6              157.9     1099.5    1209.5                     -   194799  1048576  1048576       - P:48134
rds-C9woKbOCf2Y    82530.8   100000.0  100000.0                     -  2361623 51200000 51200000       - P:92859
/rds-d2                0.0        0.0       0.0                     -        1        0        0       - G:rds
/rds-d2               16.8        0.0       0.0                     -       75        0        0       - G:rfs
Many thanks!
Best regards,
Hansheng
</MESSAGE>

<MESSAGE id=0006 role=HELPDESK_ASSIGNEE>
```
Filesystem/Project    GB        quota     limit          grace           files    quota    limit   grace User/Grp/Proj

/home                 54.2       50.0      55.0                     -    ------- No File Quotas  ------- U:hx305

/rds-d6              157.9     1099.5    1209.5                     -   194799  1048576  1048576       - P:48134

rds-C9woKbOCf2Y    82530.8   100000.0  100000.0                     -  2361623 51200000 51200000       - P:92859

/rds-d2                0.0        0.0       0.0                     -        1        0        0       - G:rds

/rds-d2               16.8        0.0       0.0                     -       75        0        0       - G:rfs
```
</MESSAGE>

<MESSAGE id=0007 role=HELPDESK_ASSIGNEE>
Hello, 
I see, thank you for the update. It looks like you’ve filled your home directory past its `50GB` quota. In this instance you will need to (carefully) move some data into `hpc-work` or delete any unwanted files from `home` to bring the quota back down. If you delete anything accidentally from `home`, don’t worry as you can copy it back from `~/.snapshot`. Please see https://docs.hpc.cam.ac.uk/hpc/user-guide/io_management.html#summary-of-available-filesystems  for more information. 
Best wishes, 
Henry
HPC Support
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-91750
[STATUS] RESOLVED
[CREATED] 2025-08-19T17:29:20.095+0100
[SUMMARY] problems reading module mpi.mod

[INITIAL_DESCRIPTION]
hello,
after upgrading from gfortran-5.4 to gfortran-13.3 my fortran based mpi 
code produced interface related warnings during compile and crashed 
during execution. Replacing 'include mpif.h' statements with 'use mpi' 
statements (plus a few other changes) fixed the problems on my local 
linux box. However, when compiling on CSD3 I get the following mpi.mod 
error:
f951: Fatal Error: Reading module 
'/usr/local/software/spack/csd3/opt-2024-06-01/linux-rocky8-cascadelake/gcc-13.3.0/intel-oneapi-mpi-2021.12.1-cvatknvvaxe4ohzbsri6keicyjoy3w7f/mpi/2021.12/include/mpi/mpi.mod' 
at line 1 column 2: Unexpected EOF
The code is in /home/mh526/Atham/svn/branches/FlAshPlume. The compiler 
settings are in 
/home/mh526/Atham/svn/branches/FlAshPlume/source/Makefile.COMPILE
For the compile I load the following modules:
module load rhel8/cclake/base
module load gcc/13.3.0/7ukda7ns
module load netcdf-fortran-pnetcdf/4.6.1/gcc/intel-oneapi-mpi/ptuvn62k
The compile command  that produces the error is
/usr/local/software/spack/csd3/opt-2024-06-01/linux-rocky8-cascadelake/gcc-13.3.0/intel-oneapi-mpi-2021.12.1-cvatknvvaxe4ohzbsri6keicyjoy3w7f/mpi/2021.12/bin/mpif90 
-c -DMPI -g -O3 -ffree-line-length-none -mcmodel=medium 
-I/usr/local/software/spack/csd3/opt-2024-06-01/linux-rocky8-cascadelake/gcc-13.3.0/netcdf-fortran-4.6.1-ptuvn62k6et3sihhin2vrwbtyjuycp4o/include 
-I/usr/local/software/spack/csd3/opt-2024-06-01/linux-rocky8-cascadelake/gcc-13.3.0/parallel-netcdf-1.12.3-sn2y3yw32wdavsrvyy6g2dgru3x363d3/include 
/home/mh526/Atham/svn/branches/FlAshPlume/source/Basic/precision.F90
Are you able to tell me what the problem is? Am I using the wrong 
mpi.mod file?
Many thanks,
Michael


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hello Michael,
Thank you for submitting a ticket, I will see if we can assist you.
If you have any further information, please let me know, otherwise I will get back to you soon,
Best regards,
Elisabeth Reeve 
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=HELPDESK_ASSIGNEE>
Hello Michael,
Can you please attach your code and settings here, so we can take a look.
Best regards,
Elisabeth
</MESSAGE>

<MESSAGE id=0003 role=TICKET_CREATOR>
Hi Elisabeth,
the attached code is a small module that defines kind values as 
parameters. The only reference to the mpi module is the MPI_REAL8 
parameter. This precision module is referenced throughout the rest of my 
code/model. Since I use pnetcdf for I/O I load the following modules:
module purge
module load rhel8/cclake/base
module load gcc/13.3.0/7ukda7ns
module load netcdf-fortran-pnetcdf/4.6.1/gcc/intel-oneapi-mpi/ptuvn62k
A simple compile
mpif90 -c -DMPI precision.F90
produces
f951: Fatal Error: Reading module 
'/usr/local/software/spack/csd3/opt-2024-06-01/linux-rocky8-cascadelake/gcc-13.3.0/intel-oneapi-mpi-2021.12.1-cvatknvvaxe4ohzbsri6keicyjoy3w7f/mpi/2021.12/include/mpi/mpi.mod' 
at line 1 column 2: Unexpected EOF
compilation terminated.
Normally, I'd expect that - if built correctly - mpif90 should know 
where to look for the correct mpi.mod file. However, this does not seem 
to be the case.
Thanks,
Michael
[FILE ATTACHMENT]
 (2 kB)
</MESSAGE>

<MESSAGE id=0004 role=OTHER>
I think we’ve seen this problem before. The problem is that Intel MPI only ships with Fortran modules for specific GCC/gfortran versions. In particular, it seems like this Intel MPI installation provides Fortran modules for gfortran version s(looking at the contents of `/usr/local/software/spack/csd3/opt-2024-06-01/linux-rocky8-cascadelake/gcc-13.3.0/intel-oneapi-mpi-2021.12.1-cvatknvvaxe4ohzbsri6keicyjoy3w7f/mpi/2021.12/include/mpi/gfortran`)
- 4.8.0
- 4.9.0
- 5.1.0
- 6.1.0
- 7.1.0
- 8.2.0
- 9.1.0
- 10.2.0
- 11.1.0
Really we should build the Fortran module for the GCC version in our software stack (13.3.0) but for now the only solutions I know of are:
- Switch to the Intel compiler
- Try and force gfortran to use the fortran MPI module for an older gfortran version (which should work).
</MESSAGE>

<MESSAGE id=0005 role=OTHER>
Hi Michael,
Can you try to compile adding this flag to the compile stage:
`-I /usr/local/software/spack/csd3/opt-2024-06-01/linux-rocky8-cascadelake/gcc-13.3.0/intel-oneapi-mpi-2021.12.1-cvatknvvaxe4ohzbsri6keicyjoy3w7f/mpi/2021.12/include/mpi/gfortran/10.2.0`.  So, e,g, your precision.f90 example below compiles to an object file for me in your suggested module environment with the command:
`mpif90 -I /usr/local/software/spack/csd3/opt-2024-06-01/linux-rocky8-cascadelake/gcc-13.3.0/intel-oneapi-mpi-2021.12.1-cvatknvvaxe4ohzbsri6keicyjoy3w7f/mpi/2021.12/include/mpi/gfortran/10.2.0  -c -DMPI precision.F90`
I appreciate that using the gcc 10.2.0 version of the module file with the 13.3.0 version of gcc may look odd but we’re fairly sure it should work.
</MESSAGE>

<MESSAGE id=0006 role=OTHER>
There’s also a version 11.1.0 which I somehow missed!  So `-I /usr/local/software/spack/csd3/opt-2024-06-01/linux-rocky8-cascadelake/gcc-13.3.0/intel-oneapi-mpi-2021.12.1-cvatknvvaxe4ohzbsri6keicyjoy3w7f/mpi/2021.12/include/mpi/gfortran/11.1.0` also works.
</MESSAGE>

<MESSAGE id=0007 role=TICKET_CREATOR>
Hi Simon,
many thanks. The 11.1.0 mpi.mod file works (and so did the 10.2.0 version).
Best wishes,
Michael
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-91551
[STATUS] RESOLVED
[CREATED] 2025-08-13T15:21:20.348+0100
[SUMMARY] Run MPI process on cluster

[INITIAL_DESCRIPTION]
Hi,
Is it possible to run MPI-enabled processes on nodes?
[mf810@cpu-q-209 fasta]$ mpirun -n 1 ~/meme-mpi/bin/meme --help
MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found
Abort(1090959) on node 0 (rank 0 in comm 0): Fatal error in PMPI_Init: Other MPI error, error stack:
MPIR_Init_thread(178)........:
MPID_Init(1532)..............:
MPIDI_OFI_mpi_init_hook(1474):
(unknown)(): Other MPI error
Thanks in advance!
Best regards,
Milena Flankova


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Dear Milena,
Thank you for reaching out to us. Can you please refer the following link https://docs.hpc.cam.ac.uk/hpc/user-guide/a100.html?highlight=mpirun#jobs-requiring-mpi for a proper drafting of slurm script and syntax to be used.
Regards,
Muhammad Ahmed
HPC Services
----------
Note: I am sending you this email/message now because it suits me; I respect your choice of when and how you work so I do not expect you to read, action or respond to this message outside your own working hours.
----------
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-91107
[STATUS] RESOLVED
[CREATED] 2025-07-31T22:40:17.804+0100
[SUMMARY] Copying large file to RCS

[INITIAL_DESCRIPTION]
Dear Support
I started to copy a 108GB zip file to RCS when it occurred to me that this might be a bad idea. It quickly completed anyway. Do you recommend that I don't do this or is it OK?
Kind regards
Simon


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hello Simon,
We have a best practice guide for transferring data to RCS that you may wish to look at [Best Practice — Research Storage Documentation documentation](https://docs.hpc.cam.ac.uk/storage/rcs/best-practice.html)
Zipping is okay but tarring would be better and preferred.
Best regards,
Elisabeth Reeve
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=TICKET_CREATOR>
Dear Elizabeth
Thanks for that. The files are from a Windows server and were password protected which was easiest to do using zip. I found I can split the zip file into three smaller versions up to 50GB
zip file.zip --out file_parts.zip -s 50g
But does it matter that a file is bigger than 50GB? If the tapes are 100GB then maybe it does but they may be bigger than that now, I don't know.
Regards
Simon
</MESSAGE>

<MESSAGE id=0003 role=HELPDESK_ASSIGNEE>
Hello Simon,
That should be fine then, as long as that’s the smallest you can get the archive since you can not password protect tar files. The main thing is the bigger the files, the longer it will take to store and retrieve them when needed.
Best regards,
Elisabeth
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-90029
[STATUS] RESOLVED
[CREATED] 2025-07-03T10:50:18.911+0100
[SUMMARY] Unable to connect to rcs.uis.cam.ac.uk

[INITIAL_DESCRIPTION]
Hi,
I have noticed that me and my colleague are unable to connect to the RCS. We both are connecting by SFTP, rcs.uis.cam.ac.uk on port 22 and both get the same unable to connect message.
We have also had a ticket from a user in our department explaining that she is also unable to connect where she was able to last week.
Is there a problem with the service at the moment? Or has anything changed that might be causing this?
Thanks
Kind Regards,
Shaun Cooke (he/him)
IT Service Manager
Department of Plant Sciences
University of Cambridge
Downing Street, Cambridge, CB2 3EA
Tel: 44 (0)1223 748962 | stc48@cam.ac.uk<[stc48@cam.ac.uk](mailto:stc48@cam.ac.uk)>
[https://www.plantsci.cam.ac.uk<https://www.plantsci.cam.ac.uk/](https://www.plantsci.cam.ac.uk%3Chttps://www.plantsci.cam.ac.uk/)>
This email (together with any files transmitted with it) is intended only for the use of the individual(s) to whom it is addressed. It may contain information which is confidential and/or legally privileged. If you have received this email in error, please notify the sender and delete the original message.


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hello Shuan,
Thank you for submitting a ticket, we are currently investigating this issue.
If you have any further information, please let me know, otherwise I will update you once I know more.
Best regards,
Elisabeth Reeve 
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=TICKET_CREATOR>
Hi,
Following up on this. This morning, I am able to connect, by my colleague Josh Hollingworth jh2640 is seeing a Access Denied error and so is the user who reporting the issue (Juliet Anderson jra68)
Do you have any suggestions for them?
Kind Regards,
Shaun Cooke (he/him)
IT Service Manager
Department of Plant Sciences
University of Cambridge
Downing Street, Cambridge, CB2 3EA
Tel: 44 (0)1223 748962 | stc48@cam.ac.uk<[stc48@cam.ac.uk](mailto:stc48@cam.ac.uk)>
[https://www.plantsci.cam.ac.uk<https://www.plantsci.cam.ac.uk/](https://www.plantsci.cam.ac.uk%3Chttps://www.plantsci.cam.ac.uk/)>
This email (together with any files transmitted with it) is intended only for the use of the individual(s) to whom it is addressed. It may contain information which is confidential and/or legally privileged. If you have received this email in error, please notify the sender and delete the original message.
</MESSAGE>

<MESSAGE id=0003 role=HELPDESK_ASSIGNEE>
Hello Shaun,
User jh2640 does not have mfa setup for the cluster, they need to follow the instructions found here: [MultiFactor Authentication (MFA) — CSD3 1.0 documentation](https://docs.hpc.cam.ac.uk/hpc/user-guide/mfa.html)
For user jra68, I’d need to know more information on how they are connecting. 
Please advise these users to raise their own support tickets so we can assist them directly.
Best regards,
Elisabeth
</MESSAGE>

<MESSAGE id=0004 role=TICKET_CREATOR>
Hi Elisabeth,
This is strange. I have just watched Josh login to the Web at login-web.hpc.cam.ac.uk with MFA enabled (he has his code in Microsoft Authenticator app). He can access the website properly, but the RCS is still giving an access denied message.
I’ll ask them both to open tickets directly.
Thanks
Kind Regards,
Shaun Cooke (he/him)
IT Service Manager
Department of Plant Sciences
University of Cambridge
Downing Street, Cambridge, CB2 3EA
Tel: 44 (0)1223 748962 | stc48@cam.ac.uk<[stc48@cam.ac.uk](mailto:stc48@cam.ac.uk)>
[https://www.plantsci.cam.ac.uk<https://www.plantsci.cam.ac.uk/](https://www.plantsci.cam.ac.uk%3Chttps://www.plantsci.cam.ac.uk/)>
This email (together with any files transmitted with it) is intended only for the use of the individual(s) to whom it is addressed. It may contain information which is confidential and/or legally privileged. If you have received this email in error, please notify the sender and delete the original message.
</MESSAGE>

<MESSAGE id=0005 role=HELPDESK_ASSIGNEE>
Hello Shaun,
There are two different MFA tokens, the one for the web interface is only for the web interface, Josh needs to follow the guidance in the user documentation for MFA to setup the TOTP required for the storage services (via ssh to the multi node)
Best regards,
Elisabeth
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-89914
[STATUS] RESOLVED
[CREATED] 2025-06-30T15:15:22.467+0100
[SUMMARY] SKA-SRC: error creating blazar lease in ska-src-science-validations tenancy

[INITIAL_DESCRIPTION]
We are having problems creating a GPU platform on the “ska-src-science-validations” tenancy on Azimuth (with OpenHPC v3).
I always seem to have the error:
error creating blazar lease - Not enough hosts available
and it doesn’t matter which flavour (standard or v2) to use for login and control nodes.
Does this mean that I’m doing something wrong in the setup, or is there an issue with blazar on that tenancy?
Thanks a lot,
Ed


[CONVERSATION]
<MESSAGE id=0001 role=OTHER>
Hello Edward,
Thank you for submitting a ticket, I will see if we can assist you.
If you have any further information, please let me know, otherwise I will get back to you soon,
Best regards,
Elisabeth Reeve
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=HELPDESK_ASSIGNEE>
Hi @Edward Polehampton no this doesn’t. Azimuth reports this once all available resources are consumed by other users.
</MESSAGE>

<MESSAGE id=0003 role=TICKET_CREATOR>
Thanks a lot. We realised this in the end, and have since managed to successfully create GPU workstations.
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-89749
[STATUS] RESOLVED
[CREATED] 2025-06-26T14:15:18.490+0100
[SUMMARY] HPC login TOTP

[INITIAL_DESCRIPTION]
Dear HPC support,
I use the university MS authenticator on my phone and I would like to 
set it up as my TOTP for HPC login
Is it possible and how do I do this?
I tried using the TOTP when I attempt to login but it does not seem to 
work.
Thank you!
Cheers, Claudio
– 
Claudio Castelnovo
Professor of Theoretical Physics and Fellow of Trinity College
/Theory of Condensed Matter Group/
Department of Physics, Cavendish Laboratory
University of Cambridge
19, J J Thomson Avenue, Cambridge CB3 0HE, UK
phone: +44 (0)1223 337433
fax: +44 (0)1223 337356
web: [http://www.tcm.phy.cam.ac.uk/profiles/cc726/](http://www.tcm.phy.cam.ac.uk/profiles/cc726/)


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Dear Claudio,
Thank you for your email. We have checked your account on our end and it seems that you do not currently have your MFA set up. To rectify this, please follow https://docs.hpc.cam.ac.uk/hpc/user-guide/mfa.html  and connect to 
```
ssh cc726@multi.hpc.cam.ac.uk
```

Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=TICKET_CREATOR>
I tried to login but my credentials are not accepted. I suspect that my 
password is incorrect or too old and has become inactive.
I thought it would be my raven password, which is working fine 
everywhere else...
I see no option to reset my password. Would you be able to advice on 
what I should do when I get to the web-login page:
[https://id.hpc.cam.ac.uk/auth/realms/CSD3/protocol/openid-connect/auth?response_type=code&scope=openid&client_id=login-web.hpc.cam.ac.uk&state=4rXmMKaP6OhQUPDQKDeN0rZKs9A&redirect_uri=https%3A%2F%2Flogin-web.hpc.cam.ac.uk%2Foidc&nonce=tbsuDdIJnR2HRFHuBzCtV5PgfmFHgB2BczcchKMBVnE](https://id.hpc.cam.ac.uk/auth/realms/CSD3/protocol/openid-connect/auth?response_type=code&scope=openid&client_id=login-web.hpc.cam.ac.uk&state=4rXmMKaP6OhQUPDQKDeN0rZKs9A&redirect_uri=https%3A%2F%2Flogin-web.hpc.cam.ac.uk%2Foidc&nonce=tbsuDdIJnR2HRFHuBzCtV5PgfmFHgB2BczcchKMBVnE)
?
Thank you!
Kind regards, Claudio
</MESSAGE>

<MESSAGE id=0003 role=HELPDESK_ASSIGNEE>
Hi Claudio,
Apologies- I overlooked the fact that you are not a CSD3 user. Please fill out an application form via [https://www.hpc.cam.ac.uk/rcs-application](https://www.hpc.cam.ac.uk/rcs-application). Once submitted we can then provision your user account.  
Best wishes, 
Henry
HPC Support
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-89520
[STATUS] RESOLVED
[CREATED] 2025-06-23T01:43:17.586+0100
[SUMMARY] [UKAEA] Request Machine Info

[INITIAL_DESCRIPTION]
Good morning, I am doing a benchmarking exercise on the ukaea-spr and ukaea-spr-hbm nodes.
I've managed to find most of the hardware info I need with some probing,
but for completeness I could do with some information as follows:
Network Interconnect
Network Topology
Storage Device Type (on the RDS filesystem) i.e. SSD/HDD/NVMe
Many Thanks in Advance,
Aleks


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Dear Aleks,
For the `ukaea-hbm` partitions, we operate with the following specifications: 
1. Network Interconnect
1. One Infiniband NDR 200  per node
2. Network Topology
1. Fat tree
3. Storage Device Type (on the RDS filesystem) i.e. SSD/HDD/NVMe
1. We operate a Lustre file system
Please let me know if you have any further questions. Thanks
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=HELPDESK_ASSIGNEE>
Hello,
I have not had any updates on this ticket so I will go ahead and close it for you. Please report to support@hpc.cam.ac.uk if you need further help or have any other questions and one of the active agents will be happy to assist. Alternatively, if this issue persists, please reply to this email with more information so that we can assist with its resolution. Many thanks.
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-89172
[STATUS] RESOLVED
[CREATED] 2025-06-16T14:50:21.581+0100
[SUMMARY] Citrix problem

[INITIAL_DESCRIPTION]
Hi,
I have been able to log onto the VPN but when I try to login to Citrix Workspace I just get the error message attached. Are you able to help?
Best,
Dan


[CONVERSATION]
<MESSAGE id=0001 role=TICKET_CREATOR>
[FILE ATTACHMENT]
</MESSAGE>

<MESSAGE id=0002 role=HELPDESK_ASSIGNEE>
Dear Daniel,
Thank you for reaching out to us. What do you see when you go to the following link [https://anywhere.cam.ac.uk/](https://anywhere.cam.ac.uk/) in browser and logging in (Raven credentials)? Do you see an SRCP virtual desktop? While connected to VPN, can you run the virtual desktop from web browser as it should automatically launch Citrix Desktop application?
Regards,
Muhammad Ahmed
HPC Services
</MESSAGE>

<MESSAGE id=0003 role=HELPDESK_ASSIGNEE>
Since we haven’t received a response, we’re going to go ahead and mark this ticket as resolved.
If you still need assistance, feel free to reopen the ticket or submit a new one.
Thank you! 
 
Regards,
Muhammad Ahmed
HPC Services
----------
Note: I am sending you this email/message now because it suits me; I respect your choice of when and how you work so I do not expect you to read, action or respond to this message outside your own working hours.
----------
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-89057
[STATUS] RESOLVED
[CREATED] 2025-06-12T12:26:21.799+0100
[SUMMARY] Add DiRAC project to account

[INITIAL_DESCRIPTION]
Dear Support Team,
I've recently added another DiRAC project (DP371) to my user account (rab200) via SAFE, but the resources are not showing up as available on CSD3/Wilkes. 'mybalance' doesn't show the project. I think the account code is probably "DIRAC-DP371-GPU" but I submissions with that account fail. Could help with this?
Cheers,
Richard
==========================================================
Dr. Richard Booth
Royal Society University Research Fellow & University Academic Fellow
School of Physics & Astronomy
W. H. Bragg Building
University of Leeds, UK
Email: r.a.booth@leeds.ac.uk<[r.a.booth@leeds.ac.uk](mailto:r.a.booth@leeds.ac.uk)>
My working hours may differ from yours
I do not expect a reply outside of your own working hours


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hello Richard,
Provisioning is not an automatic process, I can see this has been completed now.
Best regards,
Elisabeth Reeve
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=TICKET_CREATOR>
Great, thanks for looking into this for me.
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-88966
[STATUS] RESOLVED
[CREATED] 2025-06-10T17:04:18.649+0100
[SUMMARY] Long queue time

[INITIAL_DESCRIPTION]
Hello,
I hope this email finds you well!
I am working on CSD3 for some cpu jobs, particularly nodes cclake and Icelake. I submitted some jobs last week and I found the queueing time very long. I am wondering if you can give advice on this regarding if there is anything I did wrong causing the long wait. Some general info:
- Name: Hongyu Zhou
- Account/PI: N-LAWRENCE-SL3-CPU
- Working directory: /home/hz488/project/ai_ranking_report
- Task:
- Data: I work with bibliographic data on hundreds of millions of paper including their title, abstract, and citation relationships
- Task:
- I am trying to calculate the cooccurence frequency of concepts in papers (two concepts used in one paper), for which the concepts are extracted already in our current data (one paper associated with a list of paper).
- I am building these cooccurrence networks for using papers since 1990 to current and group them to a interval of 3 years
- I generate networks for every three years.
- Problem:
- The queueing time is quite long.
- Slurm Job_id=10784619 Name=build_cooccur_net Began, Queued time 17:19:49
- I tried to minimise the potential RAM usage by using smaller intervals, using smaller samples and use sql-like ducked to calculate the concurrences. But in the future, there will definitely be larger jobs I need to run considering the size of my data in nature, especially if we were use Node2Vec to embed the networks we obtained.
- Job submission script:
#!/bin/bash
#SBATCH -J build_cooccur_net
#SBATCH -A N-LAWRENCE-SL3-CPU
#SBATCH -p icelake
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=6
#SBATCH --mem=30G
#SBATCH --time=4:00:00
#SBATCH --output=1_build_net_duck_%j.out
#SBATCH --error=1_build_net_duck_%j.err
#SBATCH --mail-type=ALL
#SBATCH --mail-user=hz488@cam.ac.uk
set -euo pipefail
echo "[$(date '+%Y-%m-%d %T')] Job started"
module purge
module load python/3.8
source "$HOME/hzenv/bin/activate"
export OMP_NUM_THREADS=1
export MKL_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
TEMP_DIR="${SLURM_TMPDIR:-./temp_edges}"
mkdir -p "$TEMP_DIR"
python /home/hz488/project/ai_ranking_report/scripts/1_build_net_save_duckdb.py \
--input-dir /home/hz488/project/dimensions/publications/ \
--output-dir /home/hz488/project/data/ai_ranking_report/data/1_build_net \
--batch-size 200000 \
--batches-per-file 50 \
--sample-frac 1
echo "[$(date '+%Y-%m-%d %T')] Job finished”
Could you kindly advise me on this?
Best,
Hongyu


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Dear Hongyu Zhou,
There is nothing wrong with your account or jobs, except that they are at the non-paying service level and there is a lot of paying activity which has higher priority. 
Please bear in mind that each paying job can occupy its resources for 36 hours. Please be patient and don’t be tempted to cancel and resubmit - since all jobs steadily increase in priority the longer they wait, that would be counterproductive. 
Your jobs will run when resources become available.
Best regards,
Elisabeth Reeve
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=TICKET_CREATOR>
Thanks very much for your prompt response! It’s great to know.
Could you please point me to the pricing of SL2? Also is there any estimate on waiting time for SL2?
Hongyu
On 10 Jun 2025, at 17:11, Elisabeth Reeve <support@hpc.cam.ac.uk> wrote:
</MESSAGE>

<MESSAGE id=0003 role=HELPDESK_ASSIGNEE>
Hello Hongyu,
You can find information and instructions for obtaining SL2 projects here: [https://www.hpc.cam.ac.uk/charges](https://www.hpc.cam.ac.uk/charges)
Best regards,
Elisabeth
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-88843
[STATUS] RESOLVED
[CREATED] 2025-06-06T16:18:18.756+0100
[SUMMARY] Setting Up Local Conda Environment for Intel GPU Usage on DAWN Cluster

[INITIAL_DESCRIPTION]
Dear HPC Team,
I am currently using the DAWN cluster and would like to leverage the Intel GPUs for running my PyTorch code.
According to the documentation, the following setup works well:
module load intelpython-conda
conda activate pytorch-gpu
And in Python:
import torch
import intel_extension_for_pytorch as ipex
...
1. Enable GPU
model = model.to('xpu')
data = data.to('xpu')
model = ipex.optimize(model, dtype=torch.float32)
This setup functions as expected.
However, the pytorch-gpu environment appears to be a system-provided environment. For the purposes of my project, I would like to create and manage my own local Conda environment that is compatible with the Intel GPUs (i.e., includes PyTorch and the Intel Extension for PyTorch with xpu support).
I have attempted to clone the pytorch-gpu environment as well as install all of its modules manually, but I run into repeated HTTP 403 errors when trying to fetch packages from the Intel Conda channel. This seems to indicate restricted access or deprecation of some packages or channels.
Could you please advise on the recommended way to:
1.  Create a local Conda environment compatible with the Intel GPU setup used on DAWN,
2.  Ensure installation of all necessary packages without running into access issues?
If there is a supported method to export or replicate the pytorch-gpu environment into a user-managed Conda environment, that would be ideal.
Thank you very much for your assistance!
Best wishes,
Moritz


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hi Moritz,
We have guidance available here on Dawn and pytorch: https://docs.hpc.cam.ac.uk/hpc/user-guide/pvc.html#machine-learning-data-science-frameworks. 
- To begin, let’s check that everything works before installing additional packages. The procedure I propose is thus:
1. Make sure to run `conda deactivate` so none of your own venvs interfere
2. activate `pytorch-gpu` and run
```
python -c "import torch; import intel_extension_for_pytorch as ipex; print(torch.__version__); print(ipex.__version__); [print(f'[{i}]: {torch.xpu.get_device_properties(i)}') for i in range(torch.xpu.device_count())];"
```
This should return 2 replies, one for each tile on the GPU you have access to.
- If you need to install additional packages then you will need to use virtualenv so that the process is: activate our built in `pytorch-gpu` then activate your virtualenv. This is because you cannot modify the built in pytorch stack.
- If you would like to install your own custom venv, I suggest we match the versions that are already on the cluster (specifically this one https://pytorch-extension.intel.com/installation?platform=gpu&version=v2.3.110%2Bxpu&os=linux%2Fwsl2&package=conda: `intel-extension-for-pytorch=2.3.110 pytorch=2.3.1`) . Then we will proceed as follows:
1. Create a fresh conda venv
1. `conda create -n pvctest`
2. `conda activate pvctest`
2. Install the correct python version
1. `conda install 'python>3.10,<3.12'`
2. Install the packages `conda install intel-extension-for-pytorch=2.3.110 pytorch=2.3.1 -c https://software.repos.intel.com/python/conda -c conda-forge`
3. Launch an interactive job on PVC partition
1. Make sure no conflicting modules etc are active (may also require you to run `conda deactivate` a couple of times to make sure nothing is active)
2. Activate the venv we just created and run the test function
```
export OCL_ICD_VENDORS=/etc/OpenCL/vendors
export CCL_ROOT=${CONDA_PREFIX}
python -c "import torch; import intel_extension_for_pytorch as ipex; print(torch.__version__); print(ipex.__version__); [print(f'[{i}]: {torch.xpu.get_device_properties(i)}') for i in range(torch.xpu.device_count())];"
```
You will find that since we dropped back to a slightly earlier release of this software, we have python 3.11.11 which I think should be compatible with the other software you’d like to install on this venv. Note that step 3 will only work on the PVC nodes. This method will also align our install with the centrally available one on the cluster (i.e., there shouldn’t be any compatibility issue(s) ). 
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=HELPDESK_ASSIGNEE>
Hi Moritz, 
Just to summarise what I said: 
1. `pytorch-gpu` is our built in stack and thus cannot be modified. The solution is to use this in conjunction with a virtualenv. You will then need to activate both on your jobs.
2. You can alternatively create your own conda venv which matches our built in stack which you will be free to modify as needed.
All operations should be tested on the pvc/pvc9 partition. For my testing I used interactive jobs. 
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0003 role=HELPDESK_ASSIGNEE>
Hello,
I have not had any updates on this ticket so I will go ahead and close it for you. Please report to support@hpc.cam.ac.uk if you need further help or have any other questions and one of the active agents will be happy to assist. Alternatively, if this issue persists, please reply to this email with more information so that we can assist with its resolution. Many thanks.
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-88772
[STATUS] RESOLVED
[CREATED] 2025-06-05T09:06:20.877+0100
[SUMMARY] AIRR/Dawn Storage

[INITIAL_DESCRIPTION]
Hi
I am at a bit of a loss as to how access storage provided by AIRR/Dawn?
My storage name is airr-p12-storage
My user id is dn-stan1.
I have looked extensively in the support/help docs but must be looking straight past this information.
Thanks
Phill
–
Prof Phillip J. Stansfeld (he/him)
Co-Director of the Sir Howard Dalton Centre | Professor in Computational Biochemistry | School of Life Sciences & Department of Chemistry | University of Warwick
phillip.stansfeld@warwick.ac.uk<[phillip.stansfeld@warwick.ac.uk](mailto:phillip.stansfeld@warwick.ac.uk)>| External: +44 (0) 24 7652 3864 | Internal: x23864 | I can also be contacted through Microsoft Teams
Stansfeld Research Group<[https://stansfeldresearchgroup.wordpress.com/](https://stansfeldresearchgroup.wordpress.com/)> | Office IBR2.26 | School of Life Sciences | Gibbet Hill Road | Coventry | CV4 7AL | Find us on the interactive map<[https://campus.warwick.ac.uk/search/623c895c421e6f5928c0fa77?projectId=warwick](https://campus.warwick.ac.uk/search/623c895c421e6f5928c0fa77?projectId=warwick)>
[Logo  Description automatically generated][signature_104923545][signature_4232682299]


[CONVERSATION]
<MESSAGE id=0001 role=TICKET_CREATOR>
[FILE ATTACHMENT]
[FILE ATTACHMENT]
[FILE ATTACHMENT]
</MESSAGE>

<MESSAGE id=0002 role=HELPDESK_ASSIGNEE>
Dear Phil,
You will find your 10TB storage area at ~/rds/rds-airr-p12-c3IGbxCF9C4. This is a symbolic link to the true location but you can also it from the quota command.
Best regards
Stuart
</MESSAGE>

<MESSAGE id=0003 role=TICKET_CREATOR>
Thanks! I don’t think I would have found this without your help!
–
Prof Phillip J. Stansfeld (he/him)
Co-Director of the Sir Howard Dalton Centre | Professor in Computational Biochemistry | School of Life Sciences & Department of Chemistry | University of Warwick
phillip.stansfeld@warwick.ac.uk| External: +44 (0) 24 7652 3864 | Internal: x23864 | I can also be contacted through Microsoft Teams
Stansfeld Research Group<[https://stansfeldresearchgroup.wordpress.com/](https://stansfeldresearchgroup.wordpress.com/)> | Office IBR2.26 | School of Life Sciences | Gibbet Hill Road | Coventry | CV4 7AL | Find us on the interactive map<[http://campus-cms.warwick.ac.uk/share/c8b542ed05084d8953c68e7ab3d44144](http://campus-cms.warwick.ac.uk/share/c8b542ed05084d8953c68e7ab3d44144)>
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-87559
[STATUS] RESOLVED
[CREATED] 2025-05-06T11:09:18.462+0100
[SUMMARY] 'ReqNodeNotAvail, Reserved for maintenance'?

[INITIAL_DESCRIPTION]
Hi -
I’ve just sbatched a job on the HPC, using cclake, job 9082481_[1-2]. If I squeue -u has27 it tells me (under NODELIST) 'ReqNodeNotAvail, Reserved for maintenance’. But maintenance finished last week.
Can you tell me what (if anything) I’ve done wrong? Script below.
Thanks,
Hamish
#!/bin/bash
#SBATCH -A GLOVER-SL3-CPU
#SBATCH --nodes=1
#SBATCH --mail-type=NONE
#SBATCH -p cclake  # name of the partition to run job on
#SBATCH -o /home/has27/rds/hpc-work/f2reads/bowtie2/bowtie2%a.log
#SBATCH -c 8         # number of CPUs. Default: 1
#SBATCH --mem=27360M     # RAM memory.
#SBATCH -t 12:00:00  # time for the job HH:MM:SS. Default: 1 min
#SBATCH -a 1-2
source ~/.bashrc
1. activate conda environment
conda activate bowtie2
cd /home/has27/rds/hpc-work/f2reads/soapnuke/clean
1. List all files in the folder starting with A or B,
2. then get the relevant line
INDIV_ID=$(ls -d [AB]* | head -n ${SLURM_ARRAY_TASK_ID} | tail -n 1)
cd $INDIV_ID
READ1=$(ls *1.fq.gz)
READ2=$(ls *2.fq.gz)
cd /home/has27/rds/hpc-work/Genomes/LSRagtag
bowtie2 -p 8 -x LSRagtag -1 /home/has27/rds/hpc-work/f2reads/soapnuke/clean/$INDIV_ID/$READ1 -2 /home/has27/rds/hpc-work/f2reads/soapnuke/clean/$INDIV_ID/$READ2 | samtools sort > /home/has27/rds/hpc-work/f2reads/align-LSRagtag/$INDIV_ID.sorted.bam
—
Dr Hamish Symington
Junior Research Fellow, Queens’ College, Cambridge
Academic Skills Tutor and Bye-Fellow, Downing College, Cambridge
Postdoctoral Researcher in the Glover Lab, Department of Plant Sciences, University of Cambridge


[CONVERSATION]
<MESSAGE id=0001 role=OTHER>
1. `#SBATCH --mem=27360M     # RAM memory` is redundant, they should scale the number of `cpus-per-task` (which I see they already have, 8cpus gives 27GB of memory on cclake). They might find the job runs smoother in the queue if they delete the mem line.
2. This message is a generic slurm message and means nothing other than the job will run when the resources are available.
</MESSAGE>

<MESSAGE id=0002 role=HELPDESK_ASSIGNEE>
Dear Dr. Hamish,
Thank you for reaching out to us. I can see from `squeue -u has27 `command that your job has submitted successfully and is currently currently pending in a queue:
```
[ma2225@login-q-2 ~]$ squeue -u has27
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
     9084369_[1-2]    cclake parallel    has27 PD       0:00      1 (Priority)
```
I can see some details of your job:
```
JobId=9084369 ArrayJobId=9084369 ArrayTaskId=1-2 JobName=parallel_bowtie.sh
   UserId=has27(46661) GroupId=has27(46673) MCS_label=N/A
   Priority=111 Nice=0 Account=glover-sl3-cpu QOS=cpu2
   JobState=PENDING Reason=Priority Dependency=(null)
   Requeue=1 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:00:00 TimeLimit=12:00:00 TimeMin=N/A
   SubmitTime=2025-05-06T12:03:41 EligibleTime=2025-05-06T12:03:42
   AccrueTime=2025-05-06T12:03:42
   StartTime=Unknown EndTime=Unknown Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-05-06T19:53:24 Scheduler=Main
   Partition=cclake AllocNode:Sid=login-q-3:3811462
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=
   NumNodes=1-1 NumCPUs=8 NumTasks=1 CPUs/Task=8 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=8,mem=27360M,node=1,billing=8
   AllocTRES=(null)
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=9 MinMemoryNode=27360M MinTmpDiskNode=0
   Features=(null) DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/home/has27/rds/hpc-work/slurmscripts/parallel_bowtie.sh
   WorkDir=/rds/user/has27/hpc-work/slurmscripts
   StdErr=/home/has27/rds/hpc-work/f2reads/bowtie2/bowtie24294967294.log
   StdIn=/dev/null
   StdOut=/home/has27/rds/hpc-work/f2reads/bowtie2/bowtie24294967294.log
   Power=
   TresPerTask=cpu:8
```
For future submissions, `#SBATCH --mem=27360M # RAM memory` is redundant, you should scale the number of `cpus-per-task` (which I see they already have, 8 CPUs gives ~27GB of memory on cclake). You might find the job runs smoother in the queue if you delete the --mem directive.
Reference: https://docs.hpc.cam.ac.uk/hpc/user-guide/cclake.html 
Feel free to contact us if you require any further assistance.
Regards,
Muhammad Ahmed
HPC Services
</MESSAGE>

<MESSAGE id=0003 role=TICKET_CREATOR>
Thanks, Muhammad. I cancelled and resubmitted the job and it submitted ok.
The reason I was using the —mem option is because it is in the sample scripts at [https://cambiotraining.github.io/hpc-intro/setup.html](https://cambiotraining.github.io/hpc-intro/setup.html). I’ll talk to Qi about getting that updated.
Thanks,
Hamish
—
Dr Hamish Symington
Junior Research Fellow, Queens’ College, Cambridge
Academic Skills Tutor and Bye-Fellow, Downing College, Cambridge
Postdoctoral Researcher in the Glover Lab, Department of Plant Sciences, University of Cambridge
On 6 May 2025, at 20:05, Muhammad Ahmed <support@hpc.cam.ac.uk> wrote:
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-85932
[STATUS] RESOLVED
[CREATED] 2025-03-31T16:24:18.412+0100
[SUMMARY] Blank lines through QR code when trying to set up MFA

[INITIAL_DESCRIPTION]
Dear sir/madam,
I have been told to contact this email to ask for an MFA because I see the error: ‘When performing ssh to multi.hpc.cam.ac.uk the QR code is replaced either by garbage or is broken up by blank lines, making it unusable.’.
Thank you very much for sorting.
Many thanks,
James


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hi James, 
This is a known issue for Mac users. You can still activate your MFA by following the steps from https://docs.hpc.cam.ac.uk/hpc/user-guide/mfa.html : 
In your chosen authenticator app, you will want to create a new entry for your CSD3 SSH Login TOTP. In this walkthrough, we use Google Authenticator and Microsoft Authenticator as examples.
Both Google Authenticator or Microsoft Authenticator display a ‘+’ icon for adding a new account:
> - Google Authenticator then presents a choice of Scan a QR code or Enter a setup key, i.e. either point your phone camera at the displayed QR code, or type in the “secret key”, respectively.
> - Microsoft Authenticator presents a choice of new account type, choose Other account. This will activate the camera - point it at the displayed QR code.
Mac Users: You may find that the QR code appears distorted or broken comapred to the example found on this page. In most cases it should still scan as normal, however, you may need to enter the secret key manually as described above if the QR code does not scan.
The correct TOTP created in this way will appear in your mobile app under the account CSD3: SSH Login. Please note that a TOTP created for use with login-web appears as CSD3: your username. 
Best wishes, 
Henry
HPC Support
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-85626
[STATUS] RESOLVED
[CREATED] 2025-03-24T14:41:19.793+0000
[SUMMARY] Freesurfer 8 crashing

[INITIAL_DESCRIPTION]
Dear HPC team,
Good afternoon, I am contacting you since I am trying to run Freesurfer 8.0.0 on HPC but I am getting the following error:
FREESURFER: Undefined variable.
This makes me wonder if for some reason the path to freesurfer cannot be found. Since this is a new module can you please advise on the path where the application is so that I can use in my scripts? Has this been tested and was running as intended?
Needless to say I have loaded the module.
Best wishes,
Marialena


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Just caught this, 
```
[hc682@login-q-3 HPCSSUP-81719]$ module purge
[hc682@login-q-3 HPCSSUP-81719]$ module load freesurfer/8.0.0 
[hc682@login-q-3 HPCSSUP-81719]$ freesurfer

FreeSurfer is a set of tools for the analysis and visualization
of structural and functional brain imaging data. FreeSurfer
also refers to the structural imaging stream within the
FreeSurfer suite.

Users should consult the online documentation available at:

  http://surfer.nmr.mgh.harvard.edu

Alternatively, the 'recon-all' command help-text provides
adequate information to begin processing subject data, such
as the sample subject 'bert' found in the 'freesurfer/subjects'
directory.  Type 'recon-all --help' to view this help-text.

Direct comments and questions to:

  freesurfer@nmr.mgh.harvard.edu

You are running this version of FreeSurfer:

  freesurfer-linux-rocky8_x86_64-8.0.0-20250203-0f2bd3a

[hc682@login-q-3 HPCSSUP-81719]$ 

```
Works fine for me. 
Get them to show you the commands they were using EXACTLY as they appear on the screen, then try 
```
module purge
module load freesurfer/8.0.0
```
and then run
```
freesurfer 
```
Ask them to also show you their scripts. 

Need to know
1. any scripts they’re using
2. How they’re loading Freesurfer
3. If they’ve activated the license.txt
4. What they’re doing to get this error because I can’t replicate.
</MESSAGE>

<MESSAGE id=0002 role=HELPDESK_ASSIGNEE>
Dear Marialena,
Have you tried the command
```
module av freesurfer 
```
I recently built `freesurfer 8.0.0` which can be accessed with
```
module load freesurfer/8.0.0
```
Can you show me what happens when you do that? Maybe also run 
```
freesurfer --help
```
So we can see if it is added yo your path? How exactly does it crash? Can you explain how you are accessing it and if any error messages appear? Thanks 
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0003 role=TICKET_CREATOR>
Hi Henry,
Thank you for the reply.
So whenever I try to run recon-all for example with this command: recon-all -i BFC_T1w_MR_ED001_v2.nii -s test_FS8 -all -qcache
I get this:
FREESURFER: Undefined variable.
And this is after loading the module. So I suspect it does not recognise the Freesurfer path or something.
The freesurfer --help gives me this:
FreeSurfer is a set of tools for the analysis and visualization
of structural and functional brain imaging data. FreeSurfer
also refers to the structural imaging stream within the
FreeSurfer suite.
Users should consult the online documentation available at:
[http://surfer.nmr.mgh.harvard.edu](http://surfer.nmr.mgh.harvard.edu/)
Alternatively, the 'recon-all' command help-text provides
adequate information to begin processing subject data, such
as the sample subject 'bert' found in the 'freesurfer/subjects'
directory.  Type 'recon-all --help' to view this help-text.
Direct comments and questions to:
freesurfer@nmr.mgh.harvard.edu
You are running this version of FreeSurfer:
freesurfer-linux-rocky8_x86_64-8.0.0-20250203-0f2bd3a
Best wishes,
Marialena
</MESSAGE>

<MESSAGE id=0004 role=HELPDESK_ASSIGNEE>
Dear Marialena,
My apologies - I missed a step in the installation. I’ve ran your command and it seems to function as expected:
```
recon-all -i BFC_T1w_MR_ED001_v2.nii -s test_FS8 -all -qcache
Adding options -fix-ento-wm -transfer-base-bfs -fix-vsinus -fix-mca-dura -fix-ga -fix-acj -synthstrip -synthseg -synthmorph 
ERROR: cannot find BFC_T1w_MR_ED001_v2.nii
Linux login-q-1 4.18.0-553.34.1.el8_10.x86_64 #1 SMP Wed Jan 8 14:44:18 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux

recon-all -s  exited with ERRORS at Tue Mar 25 09:40:49 GMT 2025

For more details, see the log file 
To report a problem, see http://surfer.nmr.mgh.harvard.edu/fswiki/BugReporting
```
Naturally it will error for me since I can’t access the data but I think it now works. 
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0005 role=TICKET_CREATOR>
Dear Henry,
Thank you for checking, unfortunately the same error pops up. Looks like it cannot find FREESURFER_HOME or something like that.
Best wishes,
Marialena
</MESSAGE>

<MESSAGE id=0006 role=HELPDESK_ASSIGNEE>
Hi, 
Can you please try running 
```
module load freesurfer/8.0.0 
source $FREESURFER_HOME/SetUpFreeSurfer.sh 
```
And show me the output? Thanks.
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0007 role=TICKET_CREATOR>
Hi Henry,
This seems to have worked and Freesurfer is now running. Is there a way for this to be build up in the installation or should I just include this in all my scripts?
The output was this:
-------- freesurfer-linux-rocky8_x86_64-8.0.0-20250203-0f2bd3a --------
Setting up environment for FreeSurfer/FS-FAST (and FSL)
FREESURFER_HOME   /usr/local/software/freesurfer/8.0.0
FSFAST_HOME       /usr/local/software/freesurfer/8.0.0/fsfast
FSF_OUTPUT_FORMAT nii.gz
SUBJECTS_DIR      /usr/local/software/freesurfer/8.0.0/subjects
INFO: /home/med57/matlab/startup.m does not exist ... creating
MNI_DIR           /usr/local/software/freesurfer/8.0.0/mni
Best wishes,
Marialena
</MESSAGE>

<MESSAGE id=0008 role=HELPDESK_ASSIGNEE>
Hi Marialena,
Great - for now this will work but I’ll see about adding this to the build for you so you don’t have to keep sourcing the environment. Thanks  
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0009 role=TICKET_CREATOR>
Dear Henry,
Unfortunately it's not running. There is another missing step which has to do with the license for Freesurfer.
Part of the error I am getting is this
ERROR: FreeSurfer license file /usr/local/software/freesurfer/8.0.0/.license not found.
If you are outside the NMR-Martinos Center,
go to [http://surfer.nmr.mgh.harvard.edu/registration.html](http://surfer.nmr.mgh.harvard.edu/registration.html) to
get a valid license file (it's free).
If you are inside the NMR-Martinos Center,
make sure to source the standard environment.
A path to an alternative license file can also be
specified with the FS_LICENSE environmental variable.
Best wishes,
Marialena
</MESSAGE>

<MESSAGE id=0010 role=HELPDESK_ASSIGNEE>
Hi Marialena, 
This is to be expected since it’s the new version of freesurfer. Go ahead and fill out the form. It will then email you a license.txt file which you will need to copy. 
In this instance, you need to export FS_LICENSE to point at the licence file which is obtained by following the link in your error message. Let me know if this works. Thanks. 
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0011 role=TICKET_CREATOR>
Hi Henry,
For previous versions of Freesurfer we did not have to fill individual licenses. If I fill the form on my own then I get to download myself a license.txt file. But is this what you are proposing for me to do?
In any case I did it indicating I will be a single user which is not really the case but I don't have the permission to put the license here /usr/local/software/freesurfer/8.0.0/
Best wishes,
Marialena
</MESSAGE>

<MESSAGE id=0012 role=HELPDESK_ASSIGNEE>
Hi, 
Licences for Freesurfer are handled via environment variable so you can specify location of your by exporting path i.e.
export FS_LICENSE=/<path_to_licence_file>
in your terminal 
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0013 role=TICKET_CREATOR>
Hi Henry,
Suddenly now I am getting the following error and can't even load Freesurfer anymore
module load freesurfer/8.0.0
Loading freesurfer/8.0.0
Module ERROR: can't read "FREESURFER_HOME": no such variable
while executing
"-z $FREESURFER_HOME "
(file "/usr/local/software/freesurfer/8.0.0/SetUpFreeSurfer.sh" line 12)
invoked from within
"source /usr/local/software/freesurfer/8.0.0/SetUpFreeSurfer.sh "
(file "/usr/local/software/modulefiles/freesurfer/8.0.0" line 33)
Please contact <root@localhost>
Best wishes,
Marialena
</MESSAGE>

<MESSAGE id=0014 role=HELPDESK_ASSIGNEE>
Apologies, I was editing the module file. Please try now 
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0015 role=TICKET_CREATOR>
Dear Henry,
Thank you for your help, it now looks like everything is running smoothly.
Best wishes,
Marialena
</MESSAGE>

<MESSAGE id=0016 role=HELPDESK_ASSIGNEE>
Dear Marialena,
Great news - for the time being you will need to use the source command but we will investigate this further and see if it can be optimised.  
Best wishes, 
Henry
HPC Support
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-83106
[STATUS] RESOLVED
[CREATED] 2025-02-20T03:22:19.960+0000
[SUMMARY] SKA-SRC: Configuring an Azimuth instance with GPU and MPI compatibility

[INITIAL_DESCRIPTION]
Hi Support Team,
I’m working on some SRCNet related projects and am attempting to run a containerised workflow on Azimuth which requires both CUDA and MPI support. I have built the required software built into an Ubuntu container with specific CUDA and MPI versions, but these of course need to be compatible with what is possible to deploy on the instance itself.
Is there a guide to how to set these up correctly? Or some experience with running GPU and MPI codes on Azimuth that I can leverage so that we can progress the SRC work?
I’m happy to provide the Dockerfile so that you can see how things are being built, and information about the code I’m trying to run, if useful.
Kind regards,
Bradley Meyers
Support Scientist (Time Domain) | Australian SKA Regional Centre (AusSRC)
Research Fellow | Curtin Institute of Radio Astronomy (CIRA)
International Centre for Radio Astronomy Research (ICRAR)
Curtin University
Pronouns | he/him/his<[https://theconversation.com/what-are-gender-pronouns-and-why-is-it-important-to-use-the-right-ones-169025](https://theconversation.com/what-are-gender-pronouns-and-why-is-it-important-to-use-the-right-ones-169025)>
Tel | +61 8 9266 7569
Email | bradley.meyers@curtin.edu.au
Web | aussrc.org<[https://aussrc.org/](https://aussrc.org/)> | curtin.edu.au<[http://www.curtin.edu.au/](http://www.curtin.edu.au/)>
[B+wafnCZ37R4AAAAAElFTkSuQmCC]
CRICOS Provider Code 00301J
Curti​n would like to pay respect to the Aboriginal and Torres Strait Islander members
of our community by acknowledging the traditional owners of the land on which the
Perth campus is located, the Whadjuk people of the Nyungar Nation; and on our
Kalgoorlie campus, the Wongutha people of the North-Eastern Goldfields.


[CONVERSATION]
<MESSAGE id=0001 role=TICKET_CREATOR>
[FILE ATTACHMENT]
</MESSAGE>

<MESSAGE id=0002 role=OTHER>
Hi Bradley,
I’ve passed this ticket onto my colleagues in this department.  
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0003 role=TICKET_CREATOR>
Hi,
Thanks for that. Has there been any update on this?
Cheers,
Bradley
</MESSAGE>

<MESSAGE id=0004 role=HELPDESK_ASSIGNEE>
Hello Bradley,
You should be able to install the CUDA toolkit and Nvidia open-sourced driver into a GPU VM instance in the usual way, albeit I don’t believe any GPU capacity is currently free in the capacity available to Azimuth as it is being used.

Generally Singularity would be used instead of Docker, and Singularity has easy to use bindings to make host GPU resource available to the running container, e.g.

https://guiesbibtic.upf.edu/recerca/hpc/running-singularity-containers-with-gpu 

MPI runtime selection can be up to your choice as to whatever MPI you’d like to use and install in your container image
Thanks,
Paul Browne
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-82270
[STATUS] RESOLVED
[CREATED] 2025-02-04T10:25:18.793+0000
[SUMMARY] Activating Conda Environment in Jupyter Notebook (Login-Web Interface)

[INITIAL_DESCRIPTION]
Dear Sir/Madam,
I hope you are doing well.
I am writing to inquire about activating a Conda environment in Jupyter
Notebook within the Login-Web interface. I have already created a Conda
environment with ipykernel installed. However, when I start a Jupyter
Notebook session, I am unable to switch the kernel to my Conda environment.
Could you please provide guidance on how to properly activate and use my
Conda environment in Jupyter Notebook?
Thank you for your time and assistance.
Best regards,
Patrick


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hello Patrick,
Have you looked at our user documentation, I believe there is an entry to help with this but please let me know if this isn’t the case [Login-Web Interface — CSD3 1.0 documentation](https://docs.hpc.cam.ac.uk/hpc/user-guide/login-web.html#adding-virtual-environments)
Best regards,
Elisabeth Reeve
HPC Support
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-82248
[STATUS] RESOLVED
[CREATED] 2025-02-03T16:27:17.595+0000
[SUMMARY] Unable to install packages for R in Citrix Workspace

[INITIAL_DESCRIPTION]
Dear whom it may concern,
project id: pnk0p5ltryy
I hope this email finds you well. I am using RStudio as directed through RDS Farm. However, when I try to install packages(basic ones like dplyr and tidyverse),error occurs saying "error reading from connection". I tried to use web to access CRAN, but it seems I don't have internet connection on the virtual workspace. I would really appreciate your guidance, thank you very much.
Sincerely,
Yira


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hello Xinhe Zhang,
Thank you for submitting a ticket, for R package installations, we will need to complete this on your behalf due to the secure nature of SRCP. I will pass this over to the SRCP team.
If you have any further information, please let me know, otherwise I will get back to you soon,
Best regards,
Elisabeth Reeve 
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=OTHER>
Dear Yira,
Could you give us a list of the packages that you need, we will need to get them added to the platform ourselves. As the SRCP platform doesn’t have direct access to external repositories due to the security problems that introduces.
Regards
Leon
Research Computing Services
</MESSAGE>

<MESSAGE id=0003 role=OTHER>
Dear Yira,
A quick update to my earlier reply, you should have access to tidyverse and some of the more common packages already.
Could you try adding the local repo to your session, if it isn’t already present. R isn’t an application I use personally, but I believe this should work.
```
options(repos = "http://srcp-r-repo/")
available.packages()
```
If there are still missing packages from the updated list, please send the details across.
Regards
Leon
Research Computing Services
</MESSAGE>

<MESSAGE id=0004 role=HELPDESK_ASSIGNEE>
User created a new ticket about this: [[HPCSSUP-83368] Request for a few R packages - Jira](https://ucam-rcs.atlassian.net/browse/HPCSSUP-83368)
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-81680
[STATUS] RESOLVED
[CREATED] 2025-01-26T18:59:17.757+0000
[SUMMARY] Re: New Tier2 Account on CSD3 (jr908)

[INITIAL_DESCRIPTION]
Dear HPC support,
I am a PhD student with Pietro Lio project cs181 which has access to the Ampere node partition.
I have a need for some CPU only runs on the icelake nodes and was wondering if there's anyway to get this?
Many thanks
James Rowbottom - jr908
________________________________
From: support@hpc.cam.ac.uk <support@hpc.cam.ac.uk>
Sent: 09 December 2024 17:25
To: James Rowbottom <jr908@cam.ac.uk>
Subject: New Tier2 Account on CSD3 (jr908)
Welcome to the Cambridge Service for Data Driven Discovery (CSD3)
facility. CSD3 is comprised of distinct CPU and GPU systems:
CSD3-CPU      - Intel Cascade Lake, Ice Lake and Sapphire Rapids
HDR InfiniBand CPU clusters
Wilkes3-GPU   - NVIDIA A100/Mellanox HDR InfiniBand GPU cluster.
The O/S on CSD3 nodes is Rocky Linux 8, a rebuild of RHEL8,
where RHEL=Red Hat Enterprise Linux which is compatible
with CentOS, Scientific Linux and others but NOT Ubuntu.
For more information on the service please see:
docs.hpc.cam.ac.uk
Connecting
==========
Before you login for the first time, please use your SSH
public key to login via SSH to
multi.hpc.cam.ac.uk
to generate a TOTP MFA secret for your phone. multi.hpc has
the same host keys as the login nodes (see below). For more
information about MFA on CSD3 please see
[https://docs.hpc.cam.ac.uk/hpc/user-guide/mfa.html](https://docs.hpc.cam.ac.uk/hpc/user-guide/mfa.html) .
Once MFA is configured, please use your SSH public key to
login via SSH to
login.hpc.cam.ac.uk
This destination will take you to one of a set of login nodes which
may have either Cascade Lake or Ice Lake CPUs. If you prefer a
particular CPU type (e.g. because you are developing code to run on
that type) you may alternatively SSH to
login-cascadelake.hpc.cam.ac.uk or login-icelake.hpc.cam.ac.uk to
reach nodes of that type.
We allow unrestricted SSH access to the CSD3 login nodes,
but have protected them with Fail2Ban. This means that after
repeated failed login attempts from the same origin, that origin
will be blocked from further access for 20 minutes.
The SSH host keys used by all login nodes have the following
fingerprints (which of these hashes you see will depend on your
client):
RSA
MD5:fd:5c:6b:7d:49:95:2f:da:7f:5c:50:9a:bb:ef:3f:24
SHA256:2rl+MXd9rsrDzFZwEItmhhiHTlLTIqN0d3TSGLTgjTI
ED25519
MD5:eb:e3:a1:f0:64:68:cf:9c:63:da:84:db:2e:ee:15:83
SHA256:nFVSXK+VRGCaUupQEdhXzO6kp01m2fzzmbgPr0sc2so
As well as SSH login, connection is possible via x2go and VNC (the
latter needs to be tunnelled over SSH).
Storage
=======
Each user has a hard quota of 50GiB on their home directory. This is
provided over NFS and hourly/daily/weekly snapshots are made
automatically which can be searched by the user. E.g. if you delete a
file by accident look in the hidden .snapshot directory and browse the
best snapshot for the file (which can be copied back to your home
directory).
The scratch storage has been implemented as part of the Cambridge
Research Data Storage (RDS) service. Please look under ~/rds/ for your
project's scratch directory (rds-t2-cs181). Please note that
this is shared per project so each user will probably wish to create
their own subdirectory.
Data to be read by jobs (including software installations) and output
files from jobs should be placed in RDS areas, NOT the home
directory. This is because /home is NFS-based and lacks the
scalability of the lustre-based RDS. I/O to /home by jobs can create
global system issues.
User environment
================
CSD3 nodes currently run a common RHEL8-compatible operating system
but present additional development packages tuned to the node
hardware. We recommend that all optimised application binaries be
compiled on login nodes matching the target nodes as closely as
possible.
For development on cclake* partitions, the best choice is
login-cascadelake.hpc.cam.ac.uk .
On icelake* and sapphire* partitions, the best choice is
login-icelake.hpc.cam.ac.uk .
Note that the login-icelake nodes do not have GPUs and have a different
(Intel) CPU type to the (AMD) ampere GPU nodes, so ampere development may
require interactive use of a GPU node (see
[https://docs.hpc.cam.ac.uk/hpc/user-guide/interactive.html#sintr](https://docs.hpc.cam.ac.uk/hpc/user-guide/interactive.html#sintr)
).
Environment modules loading additional software packages are now
being generated by spack. There are different spack package trees
for each node hardware type.
The module names contain hashes uniquely identifying the build options
and dependencies but the modules can be searched and located using the
spack command. E.g. to search for modules providing HDF5 1.10.1
compiled using GCC, search for existing builds using
spack find -v hdf5@1.10.1%gcc
which will list matching builds and also show which configure options
were on :plus: or off (~) . Less version information will show more
choices, e.g. one might start off with just spack find hdf5%gcc.
Full details of any matching builds including dependencies (e.g. which
MPI was used) can be extracted with
spack find -dvl hdf5@1.10.1%gcc@5.4.0
Existing builds have modules which can be identified with a command
such as
spack module find hdf5@1.10.1+mpi %gcc@5.4.0 ^openmpi@1.10.7
which returns the name of the corresponding module
(hdf5-1.10.1-gcc-5.4.0-i52euam). Note that it is sometimes convenient
to search using the short hash form identifying each build (printed at
the start of line of output by the spack find -dvl command). E.g.
spack module find /i52euam
(notice the / introducing the hash).
Missing builds can be requested. (For more information about spack
see [https://eur03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fspack.readthedocs.io%2Fen%2Flatest%2Findex.html&data=05%7C02%7Cjr908%40universityofcambridgecloud.onmicrosoft.com%7Cb2a72e3346134cb8757b08dd187683f7%7C49a50445bdfa4b79ade3547b4f3986e9%7C1%7C0%7C638693619533696586%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&sdata=GUPkCeyukD4EZY8jc2oXOIpFpIpHahjHvOyx2dOSqx4%3D&reserved=0.)<http://spack.readthedocs.io/en/latest/index.html](https://eur03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fspack.readthedocs.io%2Fen%2Flatest%2Findex.html&data=05%7C02%7Cjr908%40universityofcambridgecloud.onmicrosoft.com%7Cb2a72e3346134cb8757b08dd187683f7%7C49a50445bdfa4b79ade3547b4f3986e9%7C1%7C0%7C638693619533696586%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&sdata=GUPkCeyukD4EZY8jc2oXOIpFpIpHahjHvOyx2dOSqx4%3D&reserved=0.)%3Chttp://spack.readthedocs.io/en/latest/index.html)>
Submitting jobs
===============
CSD3 uses Slurm for job scheduling. Please use the command
mybalance
to show your project, your current usage and the remaining balance in
compute unit hours.
On CSD3 the type of unit hour represented in mybalance output depends
on whether the project controls resources on a CPU partition (-CPU
projects) or a GPU partition (-GPU projects), i.e.
- projects ending in -CPU use CPU core hours
- projects ending in -GPU use GPU hours
The project listed by mybalance is the project you should specify in
Slurm submissions either through
#SBATCH -A t2-cs181-XXX
in the job submission script or equivalently on the command line with
sbatch -A t2-cs181-XXX ...
Cascade Lake
------------
Cascade Lake jobs require the partitions cclake or cclake-himem, i.e.
#SBATCH -p cclake
or
#SBATCH -p cclake-himem
and will be allocated the number of cpus required for the number of
tasks requested and a corresponding amount of memory. By default, the
cclake partition provides 1 cpu and 3410MiB of RAM per task, and the
cclake-himem partition provides 1 cpu and 6840MiB per task.
Requesting more cpus per task, or more memory per task, may both
increase the number of cpus allocated (and hence the charge). It is
more cost efficient to submit jobs requiring more than 3410MiB per task
to the -himem partition since more memory per cpu is available
there. Hyperthreading is disabled on the CPU nodes so there is no
distinction between cpus and cores - each node has 56 cores in total.
Ice Lake and Sapphire Rapids
----------------------------
Ice Lake and Sapphire Rapids partitions work in a similar way with the
following differences:
The icelake partition provides 1 cpu and 3370MiB per task by default.
The icelake-himem partition provides 1 cpu and 6760MiB per task by default.
Each node has 76 cpus.
The sapphire partition provides 1 cpu and 4580MiB per task by default.
Each node has 112 cpus.
Wilkes3-GPU
-----------
GPU jobs require the partition ampere (#SBATCH -p ampere) and may
request any number of GPUs per node from the range 1 to 4, which is
done via the directive
#SBATCH --gres=gpu:N
where 1 <=  N <= 4.
Each GPU node contains 4 NVIDIA A100-SXM-80GB GPUs, with 1000GiB RAM and
two AMD EPYC 7763 64-Core processors.
Any jobs requesting more than one node must request 4 GPUs per
node. Jobs less than one node in size will be prevented from
requesting more than 32 CPUs per GPU. The enforcement is performed by
a job submission filter which will produce an explanatory message if
it rejects a job outright.
The service levels defined for DiRAC jobs are currently:
4256 CPU cores per user maximum for a maximum of 36 hours of wallclock time per job
64 GPUs per user maximum for a maximum of 36 hours of wallclock time per job
In addition it is possible to submit low priority jobs of no more than
12 hours duration to a special project project-sl4-type (where
type=cpu or gpu) which allows a limited number of jobs to run when the
alternative is leaving nodes idle.
Please email support@hpc.cam.ac.uk if any problems are encountered.
Kind regards,
Research Computing Services


[CONVERSATION]
<MESSAGE id=0001 role=OTHER>
Hi @Stuart Rankin I can see that they have  SCHONLIEB-SL3-CPU? Can they not use that? Otherwise it’ll need to be a SAFE ticket?
</MESSAGE>

<MESSAGE id=0002 role=HELPDESK_ASSIGNEE>
Hi James,
As a Cambridge user (as well as a Tier2 user) you also have access to the non-paying CPU service level (SL3) by submitting jobs to SCHONLIEB-SL3-CPU - you should see this in the output of mybalance:
User           Usage |        Account     Usage | Account Limit Available (hours)
---------- --------- + -------------- --------- + ------------- ---------
jr908              0 | SCHONLIEB-SL3-CPU    15,681 |       212,971   197,290
jr908            131 |   T2-CS181-GPU     1,215 |        25,000    23,785
If you need larger/longer jobs than will fit into SL3 you will need to ask your local group leader for access to SL2 resources.
Best regards
Stuart
</MESSAGE>

<MESSAGE id=0003 role=TICKET_CREATOR>
Thanks Stuart 🙂
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-81206
[STATUS] RESOLVED
[CREATED] 2025-01-16T10:47:18.070+0000
[SUMMARY] Can't compile code: error: icc: warning #10352: The directory '/tmp' is full.  Please check disk space.

[INITIAL_DESCRIPTION]
Dear Sir or Madame,
CRSID: leh50
Account: CIA-DAMTP-SL2-CPU
Location:
/home/leh50/PLUTOSTUFF_CSD3/PLUTO_v4pt4Patch2_MonJun282021Download/PLUTO/RESEARCH_PROJECTS/08BrokenDiskProject/03BrokenDiskQuasi2DSims_Re4687/VSTRHYDRO2DRes32Re4687BrokenDiskForcedBreak22a0pt05Displace8HzBCReflectiveLx60H_2DHDIsoth_1920x0p008x768_ZBReflective_NonIdealNoMassSourceTermICDifferentVelocityPerts
Code I'm trying to compile: C using mpicc
Error:
When I try to compile the code I get the following error
icc: warning #10352: The directory '/tmp' is full.  Please check disk space.
I didn't have any issues trying to compile the code a few days ago. According to "quota":
Filesystem/Project    GB        quota     limit          grace           files    quota    limit   grace User/Grp/Proj
/home                 11.8       50.0      55.0                                    -    ------- No File Quotas  -------     U:leh50
/rds-d7                0.0     1099.5    1209.5                                 -        1  1048576  1048576             - P:45565
/rds-d2                0.0        0.0       0.0                                           -        1        0        0       - G:rds
rds-xg257ahCixg    19271.6    20000.0   20000.0           -  1096248 10240000 10240000   - P:92227
I don't know what the /tmp folder is. As far as I know I haven't stored anything there. I would greatly appreciate your help with this.
Best,
Dr Loren E. Held
Postdoctoral Researcher
Astrophysical Fluid Dynamics Group
Department of Applied Mathematics and Theoretical Physics (DAMTP)
University of Cambridge


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hi Loren, 
Can you let me know please which node this has happened on? Thanks.  
Best wishes, 
Henry
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=TICKET_CREATOR>
Hi Henry,
Thanks for getting back to me so quickly.
Can you let me know please which node this has happened on? Thanks.
It's on one of the front nodes. My prompt reads: (base) [leh50@login-q-3
So I guess it's node number 3.
Best,
Loren
Dr Loren E. Held
Postdoctoral Researcher
Astrophysical Fluid Dynamics Group
Department of Applied Mathematics and Theoretical Physics (DAMTP)
University of Cambridge
</MESSAGE>

<MESSAGE id=0003 role=TICKET_CREATOR>
Dear Henry,
Update: I have tried compiling the code on login node 4 and it worked without an issue. So the issue might be to do with log in node 3.
Best,
Loren
Dr Loren E. Held
Postdoctoral Researcher
Astrophysical Fluid Dynamics Group
Department of Applied Mathematics and Theoretical Physics (DAMTP)
University of Cambridge
</MESSAGE>

<MESSAGE id=0004 role=HELPDESK_ASSIGNEE>
There have been no further reported issues on any of our nodes so I will go ahead and mark this as closed for you. If you require support, please contact support@hpc.cam.ac.uk
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-81010
[STATUS] RESOLVED
[CREATED] 2025-01-13T11:37:17.846+0000
[SUMMARY] Assistance Required: Trouble Logging into Dirac

[INITIAL_DESCRIPTION]
Hi ,
I am writing to seek your assistance with logging into the Dirac machine. I encountered a similar issue before.
I have completed all the initial setup steps and obtained the QR code from the web portal token some time ago. However, it has been a while since I last logged into the machine. While I can still access the safe account, I am unable to log in to the web portal( ( Link<[https://id.hpc.cam.ac.uk/auth/realms/CSD3/protocol/openid-connect/auth?response_type=code&scope=openid&client_id=login-web.hpc.cam.ac.uk&state=D0OAg-WHtN1N7fTXG-9dpjl1oOY&redirect_uri=https%3A%2F%2Flogin-web.hpc.cam.ac.uk%2Foidc&nonce=equ0MBTPKf0h82CBRborxJ-OMzVTwl-UTQPZ2TuGe4s](https://id.hpc.cam.ac.uk/auth/realms/CSD3/protocol/openid-connect/auth?response_type=code&scope=openid&client_id=login-web.hpc.cam.ac.uk&state=D0OAg-WHtN1N7fTXG-9dpjl1oOY&redirect_uri=https%3A%2F%2Flogin-web.hpc.cam.ac.uk%2Foidc&nonce=equ0MBTPKf0h82CBRborxJ-OMzVTwl-UTQPZ2TuGe4s)> ).
Could you please help me resolve this issue?
Thank you for your support.
Best regards,
Karthika


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Hello Karthika,
Can you please provide me with your userid.
Best regards,
Elisabeth Reeve
HPC Support
</MESSAGE>

<MESSAGE id=0002 role=TICKET_CREATOR>
Hi Elisabeth,
Thanks for your reply. My user ID is dc-bhuv1
Best,
Karthika
Get Outlook for Android<[https://aka.ms/AAb9ysg](https://aka.ms/AAb9ysg)>
</MESSAGE>

<MESSAGE id=0003 role=TICKET_CREATOR>
Hi ,
Apologies for bothering you, but I wanted to kindly remind you about the login issue. This is a case of emergency, and I would greatly appreciate your assistance at the earliest convenience.
Thanks for your understanding.
Best regards,
Karthika
</MESSAGE>

<MESSAGE id=0004 role=HELPDESK_ASSIGNEE>
Hello Karthika,
Please make sure you are using the password provided in SAFE and the TOTP labelled “CSD3:dc-bhuv1” to log into the web interface.
Best regards,
Elisabeth
</MESSAGE>

<MESSAGE id=0005 role=TICKET_CREATOR>
Hi,
Thanks for your information.
I have attempted to log in multiple times through the web interface using the username dc-bhuv1 and the password provided in the SAFE account. However, I have not been prompted to use the TOTP during these attempts. The only time I recall using the TOTP was during the initial setup a few weeks ago.
Could you please advise on how to proceed?
Best,
Karthika
</MESSAGE>

<MESSAGE id=0006 role=HELPDESK_ASSIGNEE>
Hello Karthika,
Please request a new password through SAFE, hopefully that will help resolve the login issue.
Best regards,
Elisabeth
</MESSAGE>

<MESSAGE id=0007 role=TICKET_CREATOR>
Sorry, I am attaching the screenshot for your kind reference. Please find it
Karthika
[FILE ATTACHMENT]
</MESSAGE>

<MESSAGE id=0008 role=TICKET_CREATOR>
Hi,
Sure. I have just requested now.
Thanks,
Karthika
</MESSAGE>

<MESSAGE id=0009 role=TICKET_CREATOR>
Hi ,
I can now log in successfully. However, I’m unsure why I couldn’t do so earlier, as I was following the same steps.
Thank you for your help!
Best regards,
Karthika
</MESSAGE>

<END_TICKET>

----------

<BEGIN_TICKET>
[TICKET_KEY] HPCSSUP-65611
[STATUS] RESOLVED
[CREATED] 2024-01-18T13:52:04.308+0000
[SUMMARY] Using Checkpointing on SLURM (AlphaFold)

[INITIAL_DESCRIPTION]
Dear HPC Support team,
could I receive advice on using checkpoints when running a slurm script for AlphaFold 2.3.2?
I have found the following documentation useful:[https://cluster.hpcc.ucr.edu/~jhayes/slurm/16.05.4/checkpoint_blcr.html](https://cluster.hpcc.ucr.edu/~jhayes/slurm/16.05.4/checkpoint_blcr.html)
sbatch
Several options have been added to support checkpoint restart:
- --checkpoint: Specifies the interval between periodic checkpoint of a batch job. By default, the job will have no checkpoints created. Acceptable time formats include "minutes", "minutes:seconds", "hours:minutes:seconds", "days-hours", "days-hours:minutes" and "days-hours:minutes:seconds".
- --checkpoint-dir:Specify the directory when the checkpoint image files of a batch job will be stored. The default value is the current working directory. Checkpoint files will be of the form "<job_id>.ckpt" for jobs and "<job_id>.<step_id>.ckpt" for job steps.
Environment variables are available for all of these options:
SLURM_CHECKPOINT is equivalent to --checkpoint:
- SLURM_CHECKPOINT_DIR is equivalent to --checkpoint-dir
however, the --checkpoint command does not work from a script of from terminal. According to the slurm-rest-23.02 update log (which I believe is the current version of slurm on HPC):
"* The checkpoint plugin interface and all associated API calls have been removed."
Does this mean it is not possible to use checkpoints on HPC?
Thank you for your help,
Lisa


[CONVERSATION]
<MESSAGE id=0001 role=HELPDESK_ASSIGNEE>
Dear Lisa,
Implementation of Slurm on the cluster does not have native checkpointing capabilities unfortunately and it is up to users to implement this in their code. We do have a tool called dmtcp available as a module however I am not sure if this will work with Alphafold so you would need to investigate this further.

Kind regards,
Greg
RCS Team
</MESSAGE>

<MESSAGE id=0002 role=TICKET_CREATOR>
Thank you Greg, I am looking into implementing checkpoints.

In the mean time, do you have any suggestions with dealing with the Error “RuntimeError: jaxlib/gpu/solver_kernels.cc:45: operation gpusolverDnCreate(&handle) failed: cuSolver internal error”
From what I have been able to find out, it’s related to gpu use. Is there any way to overcome this without using only cpu?
</MESSAGE>

<MESSAGE id=0003 role=HELPDESK_ASSIGNEE>
Dear Lisa,
As this is a separate issue please submit new ticket by creating new email to support@hpc.cam.ac.uk making sure to give as much information as possible and one of the active agents will try to assist.
Kind regards,
Greg
RCS Team
</MESSAGE>

<END_TICKET>

----------

